{"categories":[{"title":"Devops","uri":"https://gggggravel.com/categories/devops/"},{"title":"Java基础","uri":"https://gggggravel.com/categories/java%E5%9F%BA%E7%A1%80/"},{"title":"Python","uri":"https://gggggravel.com/categories/python/"},{"title":"刷机","uri":"https://gggggravel.com/categories/%E5%88%B7%E6%9C%BA/"},{"title":"博客","uri":"https://gggggravel.com/categories/%E5%8D%9A%E5%AE%A2/"},{"title":"微服务","uri":"https://gggggravel.com/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"title":"数据库","uri":"https://gggggravel.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"数据结构与算法","uri":"https://gggggravel.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"title":"硬件","uri":"https://gggggravel.com/categories/%E7%A1%AC%E4%BB%B6/"},{"title":"缓存","uri":"https://gggggravel.com/categories/%E7%BC%93%E5%AD%98/"},{"title":"设计模式","uri":"https://gggggravel.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"posts":[{"content":"Zabbix 是由 Alexei Vladishev 开发的一种网络监视、管理系统，基于 Server-Client 架构。可用于监视各种网络服务、服务器和网络机器等状态。这里我简单写一下自己在使用 docker 部署 zabbix 中遇到的坑。\n官网的例子比较复杂，包含多种代理，以及一些不需要用到的景象，我在官网的 docker-compose.yml 文件基础上，做出了一些修改。官网的例子是把 zabbix agent 和 server 端放在一起的。但是在平时应用中，这种情况应该比较少，所以本文的示例，是将他们分开部署的。\n网桥创建 由于本机测试需要在多个容器间通信，所以这里我建立一个虚拟网桥来共享网络。使用如下命令：\ndocker network create zabbix  创建了名为 zabbix 的网桥：\ndocker network ls  即可查看所有的网桥.\ntips  查看使用本网桥的容器：  docker network inspect zabbix  docker-compose文件编写 这里的服务包含三个：\n zabbix-db：用于存储 zabbix 必须的后台数据。 zabbix-server-mysql：zabbix 服务端，用于管理各种监控，是 zabbix 的核心。 zabbix-web-nginx-mysql：提供一个可视化的 web 界面来调试以及配置各项监控指标。  # cat docker-compose.yml version: \u0026quot;3\u0026quot; services: zabbix-db: image: mysql:5.7 container_name: zabbix-db environment: - MYSQL_DATABASE=zabbix - MYSQL_USER=zabbix - MYSQL_PASSWORD=zabbix - MYSQL_ROOT_PASSWORD=12345678 volumes: - \u0026quot;${PWD}/mysql:/var/lib/mysql\u0026quot; zabbix-server-mysql: image: zabbix/zabbix-server-mysql:latest container_name: zabbix-server-mysql environment: - DB_SERVER_HOST=mysql - MYSQL_DATABASE=zabbix - MYSQL_USER=zabbix - MYSQL_PASSWORD=zabbix - MYSQL_ROOT_PASSWORD=12345678 ports: - \u0026quot;10051:10051\u0026quot; links: - zabbix-db:mysql depends_on: - zabbix-db zabbix-web-nginx-mysql: image: zabbix/zabbix-web-nginx-mysql:latest container_name: zabbix-web-nginx-mysql environment: - DB_SERVER_HOST=mysql - MYSQL_DATABASE=zabbix - MYSQL_USER=zabbix - MYSQL_PASSWORD=zabbix - MYSQL_ROOT_PASSWORD=12345678 - TZ=Asia/Shanghai ports: - \u0026quot;8081:80\u0026quot; links: - zabbix-db:mysql - zabbix-server-mysql:zabbix-server depends_on: - zabbix-server-mysql networks: default: external: name: zabbix  这一步，有三点需要注意：\n  docker-compose 的 links ：\nlinks: - zabbix-db:mysql  如果给 links 中的service设置了别名，那么在环境变量中使用的时候，也应该使用别名，不然无法识别。\n  网桥设置\n由于我们这里需要需要单独给 zabbix 设置网络，所以配置了 networks。\nnetworks: default: external: name: zabbix  上述配置的意思是，当前 docker-compose 所属的 service 都默认使用外部网桥 zabbix。\n  Zabbix 的 mysql 容器，必须指定为数据库为 zabbix，因为 zabbix 初始化的时候，有很多配置都是在这个里面完成的。\n  然后docker-compose up -d 启动即可。\nzabbix-agent 配置 agent 是属于 zabbix 的一个监控单元，一个 zabbix server 可以对应多个监控 agent ，每个 agent 都可以在 web 界面上，配置多个监控模板。这里主要说明一下如何用 docker 启动。\n首先需要查询 zabbix-server 的容器ip：\ndocker exec -it zabbix-server-mysql ip addr  output：\n1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: tunl0@NONE: \u0026lt;NOARP\u0026gt; mtu 1480 qdisc noop state DOWN qlen 1000 link/ipip 0.0.0.0 brd 0.0.0.0 3: ip6tnl0@NONE: \u0026lt;NOARP\u0026gt; mtu 1452 qdisc noop state DOWN qlen 1000 link/tunnel6 00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00 brd 00:00:00:00:00:00:00:00:00:00:00:00:00:00:00:00 453: eth0@if454: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u0026gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:15:00:03 brd ff:ff:ff:ff:ff:ff inet 172.21.0.3/16 brd 172.21.255.255 scope global eth0 valid_lft forever preferred_lft forever  172.21.0.3 即是 zabbix-server 的容器内部 ip 地址。\n启动 zabbix-agent：\ndocker run --name zabbix-agent-a -p 10050:10050 --network zabbix -e ZBX_SERVER_HOST=172.21.0.3 -e ZBX_SERVER_PORT=10051 -d zabbix/zabbix-agent   \u0026ndash;network zabbix 的意思是将这个容器加入之前的 docker-compose 的同个网段中。 ZBX_SERVER_HOST,对应 zabbix-server 的服务器ip，由于我是本机测试，所以这里写刚才的172.21.0.3。 ZBX_SERVER_PORT=10051 是 server 的端口。  结语  如果需要在多台机器上创建 zabbix-agent，使用上述命令即可，不过 zabbix server ip 需要修改为服务端所在的服务器的 ip，而且也不再需要网桥的设置了。\n zabbix的按照方式有很多种，我这里的docker-compose 文件并未展现zabbix的所有功能，详细的功能插件以及如何使用zabbix去监控各项指标，还请查看官方文档。\n","id":0,"section":"posts","summary":"\u003cp\u003eZabbix 是由 Alexei Vladishev 开发的一种网络监视、管理系统，基于 Server-Client 架构。可用于监视各种网络服务、服务器和网络机器等状态。这里我简单写一下自己在使用 docker 部署 zabbix 中遇到的坑。\u003c/p\u003e","tags":["docker","docker-compose","zabbix"],"title":"Docker部署zabbix填坑指南","uri":"https://gggggravel.com/post/zabbix-docker/","year":"2020"},{"content":"昨天跨年夜给自己的老破旧刷机，双清之前忘记退出 Google 账号，导致无法正常跳过开机向导。这里简单记录一下解决方案。\n根据以往的经验：\n  拔掉 sim 卡，关闭 wifi 功能，然后发现 Android9.0 似乎不能这么操作了。此条作废。\n  使用另外一个手机，科学上网，开热点。然后本机连接热点。不知道为什么也不行。推测热点没法直接转发科学上网的流量。此条作废。\n  同上，使用另外的手机科学上网，不过使用了另外的网络转发软件 netshare ，这个软件可以做到转发科学上网的流量，不过需要在连接热点的时候设置代理，很奇怪的是，我的手机竟然设置不了手动代理。此条放弃，不过我感觉这种方式应该是可行的。\n  电脑开代理，分享热点，也不行。\n  Google 了好久，看到有提到安卓开机向导是由 /system/build.prop 中的参数控制的。应该是可以通过修改这个文件的参数，解决这个问题。\n  进入 recovery ，我的是TWRP\n  进入mount选项，挂载上system\n  进入 命令行操作\n  cd / vi /system/build.prop    然后在这个文件中添加\n  ro.setupwizard.mode=DISABLED  然后重启系统，搞定\n","id":1,"section":"posts","summary":"\u003cp\u003e昨天跨年夜给自己的老破旧刷机，双清之前忘记退出 Google 账号，导致无法正常跳过开机向导。这里简单记录一下解决方案。\u003c/p\u003e","tags":["刷机","Andorid"],"title":"安卓 9.0 刷机跳过开机验证","uri":"https://gggggravel.com/post/android-setup/","year":"2020"},{"content":"Idea 切换maven仓库之后，重新构建老是卡住。。如图所示。\n按照 https://intellij-support.jetbrains.com/hc/en-us/community/posts/360000027164-Refreshing-files-takes-way-tool-long-often-before-building-\n的操作提示，File\u0026quot; -\u0026gt; \u0026ldquo;Invalidate Caches and Restart\u0026rdquo; 重启之后，得到解决。\n","id":2,"section":"posts","summary":"Idea 切换maven仓库之后，重新构建老是卡住。。如图所示。 按照 https://intellij-support.jetbrains.com/hc/en-us/community/posts/360000027164-Refreshing-files-takes-way-tool-long-often-before-building- 的操作提示，File\u0026quot; -\u0026gt; \u0026ldquo;Invalidate Caches and Restart\u0026rdquo; 重启之后，得到解决。","tags":["idea","问题笔记"],"title":"idea Refreshing files 卡顿","uri":"https://gggggravel.com/post/idea-refreshing-files/","year":"2019"},{"content":"最近在项目中使用了Guava缓存，使用方式是用Spring提供的 @Cacheable 注解的方式，在使用的过程中，遇到了缓存不生效的情况。\nSpring 使用@Cacheable添加缓存是基于面向切面的思想做的，实际上就是使用Java动态代理，创建实例的时候注入的是代理对象，在代理对象里调用实际的对象，这样就可以在实际的方法执行前，处理一下缓存的逻辑：没有找到缓存就往下执行，执行完把结果加入到缓存中；找到缓存则直接返回缓存的结果，不调用执行实际的方法。\n解决方案\n  不使用注解的方式，直接取 Ehcache 的 CacheManger 对象，把需要缓存的数据放到里面，类似于使用 Map，缓存的逻辑自己控制；或者可以使用redis的缓存方式去添加缓存；\n  把方法A和方法B放到两个不同的类里面，例如：如果两个方法都在同一个service接口里，把方法B放到另一个service里面，\n  在guava缓存配置类上，加上@EnableAspectJAutoProxy(exposeproxy = true)，这个注解的作用是可以允许同类中的方法互相切入。然后通过AOP切入同类调用方法-AopContext.currentProxy()，即可通过代理调用@Cacheable 注解的方法。这样就能走代理了\n  ","id":3,"section":"posts","summary":"最近在项目中使用了Guava缓存，使用方式是用Spring提供的 @Cacheable 注解的方式，在使用的过程中，遇到了缓存不生效的情况。 Spring 使用@Cacheab","tags":["springboot","guava","cache"],"title":"Springboot@Cacheable 不生效","uri":"https://gggggravel.com/post/springbootcacheable-%E4%B8%8D%E7%94%9F%E6%95%88/","year":"2019"},{"content":"azkaban 是linkin开源的一套简单的任务调度服务系统。如果需要配置任务的状态回调，那么需要加入以下配置：\ntype=command job.notification.started.1.url = http://10.20.115.20:9527/index/callback?message=started\u0026amp;server=?{server}\u0026amp;project=?{project}\u0026amp;flow=?{flow}\u0026amp;executionId=?{executionId}\u0026amp;job=?{job}\u0026amp;status=?{status} job.notification.success.1.url = http://10.20.115.20:9527/index/callback?message=success\u0026amp;server=?{server}\u0026amp;project=?{project}\u0026amp;flow=?{flow}\u0026amp;executionId=?{executionId}\u0026amp;job=?{job}\u0026amp;status=?{status} job.notification.failure.1.url = http://10.20.115.20:9527/index/callback?message=failure\u0026amp;server=?{server}\u0026amp;project=?{project}\u0026amp;flow=?{flow}\u0026amp;executionId=?{executionId}\u0026amp;job=?{job}\u0026amp;status=?{status} job.notification.completed.1.url = http://10.20.115.20:9527/index/callback?message=completed\u0026amp;server=?{server}\u0026amp;project=?{project}\u0026amp;flow=?{flow}\u0026amp;executionId=?{executionId}\u0026amp;job=?{job}\u0026amp;status=?{status} command=exit -1 dependencies=callback  其中主要配置是job.notification.xxxxx.1.url。\n","id":4,"section":"posts","summary":"azkaban 是linkin开源的一套简单的任务调度服务系统。如果需要配置任务的状态回调，那么需要加入以下配置： type=command job.notification.started.1.url = http://10.20.115.20:9527/index/callback?message=started\u0026amp;server=?{server}\u0026amp;project=?{project}\u0026amp;flow=?{flow}\u0026amp;executionId=?{executionId}\u0026amp;job=?{job}\u0026amp;status=?{status} job.notification.success.1.url = http://10.20.115.20:9527/index/callback?message=success\u0026amp;server=?{server}\u0026amp;project=?{project}\u0026amp;flow=?{flow}\u0026amp;executionId=?{executionId}\u0026amp;job=?{job}\u0026amp;status=?{status} job.notification.failure.1.url = http://10.20.115.20:9527/index/callback?message=failure\u0026amp;server=?{server}\u0026amp;project=?{project}\u0026amp;flow=?{flow}\u0026amp;executionId=?{executionId}\u0026amp;job=?{job}\u0026amp;status=?{status} job.notification.completed.1.url = http://10.20.115.20:9527/index/callback?message=completed\u0026amp;server=?{server}\u0026amp;project=?{project}\u0026amp;flow=?{flow}\u0026amp;executionId=?{executionId}\u0026amp;job=?{job}\u0026amp;status=?{status} command=exit -1 dependencies=callback 其中主要","tags":["java","调度","azkaban"],"title":"azkaban回调配置","uri":"https://gggggravel.com/post/azkaban%E5%9B%9E%E8%B0%83%E9%85%8D%E7%BD%AE/","year":"2019"},{"content":"今天在使用implala 连接 hive 数据库的时候，出现了一个错误。\nimplala 各种依赖安装好之后，测试连接时，报了以下错误：\nTypeError: can't concat str to bytes  定位到问题，位于thrift_sasl这个包的init.py第93行：\nheader = struct.pack(\u0026quot;\u0026gt;BI\u0026quot;, status, len(body)) self._trans.write(header + body)  这里的body可能是str类型，所以抛出了这个异常。然后我去github上搜索了一下源码。发现作者竟然已经放弃维护了。于是只好自己动手，很简单，在94行加入以下代码：\nheader = struct.pack(\u0026quot;\u0026gt;BI\u0026quot;, status, len(body)) if(type(body) is str): body = body.encode() self._trans.write(header + body)  有需求的话，可以自己下载源码编译。点这里。\n","id":5,"section":"posts","summary":"\u003cp\u003e今天在使用\u003ccode\u003eimplala\u003c/code\u003e 连接 \u003ccode\u003ehive\u003c/code\u003e 数据库的时候，出现了一个错误。\u003c/p\u003e","tags":["Python","问题笔记"],"title":"使用implala连接hive报错","uri":"https://gggggravel.com/post/%E4%BD%BF%E7%94%A8implala%E8%BF%9E%E6%8E%A5hive%E6%8A%A5%E9%94%99/","year":"2019"},{"content":"pandas 对指定列做fillna df.fillna({'code':'code', 'date':'date'}) df.[[\u0026quot;code\u0026quot;, \u0026quot;date\u0026quot;]].fillna(\u0026quot;\u0026quot;)  pandas 指定列重命名 df.rename(columns={\u0026quot;amount\u0026quot;: \u0026quot;total_amount\u0026quot;}, inplace=True)  DataFrame 按直接列left join合并 df = pd.merge(df_1, df_2, on=[\u0026quot;code\u0026quot;, \u0026quot;date\u0026quot;], how='left')  DataFrame 两列相加相减 df[\u0026quot;amount\u0026quot;] = df[\u0026quot;total_amount\u0026quot;] - df[\u0026quot;amount\u0026quot;] df[\u0026quot;amount\u0026quot;] = df[\u0026quot;total_amount\u0026quot;] + df[\u0026quot;amount\u0026quot;]  ","id":6,"section":"posts","summary":"pandas 对指定列做fillna df.fillna({'code':'code', 'date':'date'}) df.[[\u0026quot;code\u0026quot;, \u0026quot;date\u0026quot;]].fillna(\u0026quot;\u0026quot;) pandas 指定列重命名 df.rename(columns={\u0026quot;amount\u0026quot;: \u0026quot;total_amount\u0026quot;}, inplace=True) DataFrame 按直接列left join合并 df = pd.merge(df_1, df_2, on=[\u0026quot;code\u0026quot;, \u0026quot;date\u0026quot;], how='left') DataFrame 两列相加相减 df[\u0026quot;amount\u0026quot;] = df[\u0026quot;total_amount\u0026quot;] - df[\u0026quot;amount\u0026quot;] df[\u0026quot;amount\u0026quot;] = df[\u0026quot;total_amount\u0026quot;] + df[\u0026quot;amount\u0026quot;]","tags":["python","数据分析"],"title":"pandas 使用技巧总结（持续更新）","uri":"https://gggggravel.com/post/pandas-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93/","year":"2019"},{"content":"目录结构为：\n├── dataprocess │ ├── config │ ├── ├──dbconfig.py // 具体代码. │ ├── test.py  需要在test.py脚本中引用dbconfig.py中的方法，直接引用相对路径，会提示找不到对应的module。python判断一个目录是否为Module主要是通过 __init__.py，如果要在让python识别到这个目录需要通过系统的环境变量 sys.path。\n所以解决方法是，在test.py引用dbconfig.py的方法时，将config静态目录加入到文件中。\nimport sys currentUrl = os.path.dirname(__file__) sys.path.append(currentUrl) from config import getdb getdb()  大功告成！\n","id":7,"section":"posts","summary":"目录结构为： ├── dataprocess │ ├── config │ ├── ├──dbconfig.py // 具体代码. │ ├── test.py 需要在test.py脚本中引用dbconfig.py","tags":["python","问题笔记"],"title":"python脚本引用同级文件夹中的方法","uri":"https://gggggravel.com/post/python%E8%84%9A%E6%9C%AC%E5%BC%95%E7%94%A8%E5%90%8C%E7%BA%A7%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95/","year":"2019"},{"content":"在日常开发中，常常会遇到自己正在开发某个feature的时候，需要切到另外的分支去处理bug。于是先将未完成的功能commit到本地。处理完bug之后，再切回来开发，这种做法有一个坏处是，仓库commit的历史会很凌乱。不利于追踪排查历史问题。\n以上为前提条件，这种情况可以使用 git rebase 来处理，合并多个本地的commit，今天以这边文章的提交历史，来做个示范。\n 注意，这种合并方式，只对未push到远端的commit有效\n 首先查看下这个仓库的提交历史记录：\ngit log  输出如下图：\n使用 rebase将多个commit合并成一个。\ngit rebase -i HEAD~[number_of_commits]  可以看到，我们这里有三条commit记录，只需要修改末尾的number_of_commits参数。\ngit rebase -i HEAD~3  终端输出如下图：\n第一列是rebase具体执行的操作，其中操作可以选择，其中含义如下：\n  pick，git会应用这个补丁，以同样的提交信息（commit message）保存提交\n  reword，git会应用这个补丁，但需要重新编辑提交信息\n  edit，git会应用这个补丁，但会因为amending而终止\n  squash，git会应用这个补丁，但会与之前的提交合并\n  fixup，git会应用这个补丁，但会丢掉提交日志\n  exec，git会在shell中运行这个命令\n  这里我们将第一个提交保留，将第二第三个提交合并到第一个提交里面去，将第二个和第三个commit前的pick改成s，然后保存退出。输出如下图：\n修改commit信息，保存，并退出。然后使用git log 查看commit记录:\n可以看到，刚刚的三条记录已经被合并了。接下来只需要push到远端仓库就行了。\n","id":8,"section":"posts","summary":"\u003cp\u003e在日常开发中，常常会遇到自己正在开发某个\u003ccode\u003efeature\u003c/code\u003e的时候，需要切到另外的分支去处理\u003ccode\u003ebug\u003c/code\u003e。于是先将未完成的功能\u003ccode\u003ecommit\u003c/code\u003e到本地。处理完\u003ccode\u003ebug\u003c/code\u003e之后，再切回来开发，这种做法有一个坏处是，仓库\u003ccode\u003ecommit\u003c/code\u003e的历史会很凌乱。不利于追踪排查历史问题。\u003c/p\u003e","tags":["git"],"title":"使用git rebase合并多个commit提交","uri":"https://gggggravel.com/post/%E4%BD%BF%E7%94%A8gitrebase%E5%90%88%E5%B9%B6%E5%A4%9A%E4%B8%AAcommit%E6%8F%90%E4%BA%A4/","year":"2019"},{"content":"刚开始在项目中使用docker的时候，使用的是centos作为基础镜像。centos的官方镜像有70M左右。加上jdk、tomcat，一个完整的业务系统，可能有450M左右。在项目组同学去试用部署的时候，所以的应用包加上服务包，有点过于大了。而且以centos作为基础镜像，可能包含很多我们并不需要的功能。所以，决定转用alpine。\nalpine介绍 在alpine的官网上写着：\nAlpine Linux is a security-oriented, lightweight Linux distribution based on musl libc and busybox.//Alpine Linux 是一个社区开发的面向安全应用的轻量级 Linux 发行版。  最令人吃惊的是，他的官方docker镜像，只有5M。所以在2016年的时候，docker官方已经将推荐基础镜像，从Ubuntu转为alpine。\n编写基础镜像的Dockerfile alpine优点是安全，体积小，但同时，他肯定也缺少一些本地化的东西。\n我尝试过直接将alpine作为基础镜像去运行一个tomcat应用，发现在解压war包的时候，里面的中文文件无法被识别。另外无法直接将时区设置为东八区。\n在结合网上资料整理之后发现，alpine主要也是这两个问题困扰着使用中文的程序员。所以我们需要定制化自己的alpine基础镜像。结合Dockerfile来说吧。\nFROM alpine:3.6 MAINTAINER leongravel \u0026quot;leebroncc@gmail.com\u0026quot; ## 设置默认语言环境 ENV LANG=C.UTF-8 # 安装 GNU libc (aka glibc)和C.UTF-8 locale的依赖 以及设置时区 # 下面这么长一串，主要是通过apk安装glibc的依赖，他的作用主要是本地化支持，和字符集的切换。 RUN ALPINE_GLIBC_BASE_URL=\u0026quot;https://github.com/sgerrand/alpine-pkg-glibc/releases/download\u0026quot; \u0026amp;\u0026amp; \\ ALPINE_GLIBC_PACKAGE_VERSION=\u0026quot;2.27-r0\u0026quot; \u0026amp;\u0026amp; \\ ALPINE_GLIBC_BASE_PACKAGE_FILENAME=\u0026quot;glibc-$ALPINE_GLIBC_PACKAGE_VERSION.apk\u0026quot; \u0026amp;\u0026amp; \\ ALPINE_GLIBC_BIN_PACKAGE_FILENAME=\u0026quot;glibc-bin-$ALPINE_GLIBC_PACKAGE_VERSION.apk\u0026quot; \u0026amp;\u0026amp; \\ ALPINE_GLIBC_I18N_PACKAGE_FILENAME=\u0026quot;glibc-i18n-$ALPINE_GLIBC_PACKAGE_VERSION.apk\u0026quot; \u0026amp;\u0026amp; \\ apk add --no-cache --virtual=.build-dependencies wget ca-certificates \u0026amp;\u0026amp; \\ echo \\ \u0026quot;-----BEGIN PUBLIC KEY-----\\ MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEApZ2u1KJKUu/fW4A25y9m\\ y70AGEa/J3Wi5ibNVGNn1gT1r0VfgeWd0pUybS4UmcHdiNzxJPgoWQhV2SSW1JYu\\ tOqKZF5QSN6X937PTUpNBjUvLtTQ1ve1fp39uf/lEXPpFpOPL88LKnDBgbh7wkCp\\ m2KzLVGChf83MS0ShL6G9EQIAUxLm99VpgRjwqTQ/KfzGtpke1wqws4au0Ab4qPY\\ KXvMLSPLUp7cfulWvhmZSegr5AdhNw5KNizPqCJT8ZrGvgHypXyiFvvAH5YRtSsc\\ Zvo9GI2e2MaZyo9/lvb+LbLEJZKEQckqRj4P26gmASrZEPStwc+yqy1ShHLA0j6m\\ 1QIDAQAB\\ -----END PUBLIC KEY-----\u0026quot; | sed 's/ */\\n/g' \u0026gt; \u0026quot;/etc/apk/keys/sgerrand.rsa.pub\u0026quot; \u0026amp;\u0026amp; \\ wget \\ \u0026quot;$ALPINE_GLIBC_BASE_URL/$ALPINE_GLIBC_PACKAGE_VERSION/$ALPINE_GLIBC_BASE_PACKAGE_FILENAME\u0026quot; \\ \u0026quot;$ALPINE_GLIBC_BASE_URL/$ALPINE_GLIBC_PACKAGE_VERSION/$ALPINE_GLIBC_BIN_PACKAGE_FILENAME\u0026quot; \\ \u0026quot;$ALPINE_GLIBC_BASE_URL/$ALPINE_GLIBC_PACKAGE_VERSION/$ALPINE_GLIBC_I18N_PACKAGE_FILENAME\u0026quot; \u0026amp;\u0026amp; \\ apk add --no-cache \\ \u0026quot;$ALPINE_GLIBC_BASE_PACKAGE_FILENAME\u0026quot; \\ \u0026quot;$ALPINE_GLIBC_BIN_PACKAGE_FILENAME\u0026quot; \\ \u0026quot;$ALPINE_GLIBC_I18N_PACKAGE_FILENAME\u0026quot; \u0026amp;\u0026amp; \\ \\ rm \u0026quot;/etc/apk/keys/sgerrand.rsa.pub\u0026quot; \u0026amp;\u0026amp; \\ /usr/glibc-compat/bin/localedef --force --inputfile POSIX --charmap UTF-8 \u0026quot;$LANG\u0026quot; || true \u0026amp;\u0026amp; \\ echo \u0026quot;export LANG=$LANG\u0026quot; \u0026gt; /etc/profile.d/locale.sh \u0026amp;\u0026amp; \\ \\ apk del glibc-i18n \u0026amp;\u0026amp; \\ \\ rm \u0026quot;/root/.wget-hsts\u0026quot; \u0026amp;\u0026amp; \\ apk del .build-dependencies \u0026amp;\u0026amp; \\ rm \\ \u0026quot;$ALPINE_GLIBC_BASE_PACKAGE_FILENAME\u0026quot; \\ \u0026quot;$ALPINE_GLIBC_BIN_PACKAGE_FILENAME\u0026quot; \\ \u0026quot;$ALPINE_GLIBC_I18N_PACKAGE_FILENAME\u0026quot; \u0026amp;\u0026amp; \\ echo 'http://mirrors.ustc.edu.cn/alpine/v3.6/main' \u0026gt; /etc/apk/repositories \\ \u0026amp;\u0026amp; echo 'http://mirrors.ustc.edu.cn/alpine/v3.6/community' \u0026gt;\u0026gt;/etc/apk/repositories \\ \u0026amp;\u0026amp; apk update \u0026amp;\u0026amp; apk add tzdata \\ \u0026amp;\u0026amp; ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026amp;\u0026amp; echo \u0026quot;Asia/Shanghai\u0026quot; \u0026gt; /etc/timezone ## 上面这三行代码，是通过apk添加tzdata支持，将时区设置为东八区，也就是中国区的时间。  构建docker镜像\ndocker build -t base-alpine . // 构建镜像  通过以上这个命令，我们就完成了基础镜像的构建。这个镜像只比最纯净的alpine官方镜像大2M。\n通过基础镜像构建其他应用 完成以上的基础镜像之后，其实大部分工作都已经完成了。下面也通过Dockerfile来讲个例子。\n jdk8的镜像构建  FROM cdjd/ci/base-alpine MAINTAINER leongravel \u0026quot;leebroncc@gmail.com\u0026quot; ENV JAVA_VERSION=8 \\ JAVA_UPDATE=192 \\ JAVA_BUILD=12 \\ JAVA_PATH=750e1c8617c5452694857ad95c3ee230 \\ JAVA_HOME=\u0026quot;/usr/lib/jvm/default-jvm\u0026quot; RUN apk add --no-cache --virtual=build-dependencies wget ca-certificates unzip \u0026amp;\u0026amp; \\ cd \u0026quot;/tmp\u0026quot; \u0026amp;\u0026amp; \\ wget --header \u0026quot;Cookie: oraclelicense=accept-securebackup-cookie;\u0026quot; \\ \u0026quot;http://download.oracle.com/otn-pub/java/jdk/${JAVA_VERSION}u${JAVA_UPDATE}-b${JAVA_BUILD}/${JAVA_PATH}/jdk-${JAVA_VERSION}u${JAVA_UPDATE}-linux-x64.tar.gz\u0026quot; \u0026amp;\u0026amp; \\ tar -xzf \u0026quot;jdk-${JAVA_VERSION}u${JAVA_UPDATE}-linux-x64.tar.gz\u0026quot; \u0026amp;\u0026amp; \\ mkdir -p \u0026quot;/usr/lib/jvm\u0026quot; \u0026amp;\u0026amp; \\ mv \u0026quot;/tmp/jdk1.${JAVA_VERSION}.0_${JAVA_UPDATE}\u0026quot; \u0026quot;/usr/lib/jvm/java-${JAVA_VERSION}-oracle\u0026quot; \u0026amp;\u0026amp; \\ ln -s \u0026quot;java-${JAVA_VERSION}-oracle\u0026quot; \u0026quot;$JAVA_HOME\u0026quot; \u0026amp;\u0026amp; \\ ln -s \u0026quot;$JAVA_HOME/bin/\u0026quot;* \u0026quot;/usr/bin/\u0026quot; \u0026amp;\u0026amp; \\ rm -rf \u0026quot;$JAVA_HOME/\u0026quot;*src.zip \u0026amp;\u0026amp; \\ wget --header \u0026quot;Cookie: oraclelicense=accept-securebackup-cookie;\u0026quot; \\ \u0026quot;http://download.oracle.com/otn-pub/java/jce/${JAVA_VERSION}/jce_policy-${JAVA_VERSION}.zip\u0026quot; \u0026amp;\u0026amp; \\ unzip -jo -d \u0026quot;${JAVA_HOME}/jre/lib/security\u0026quot; \u0026quot;jce_policy-${JAVA_VERSION}.zip\u0026quot; \u0026amp;\u0026amp; \\ rm \u0026quot;${JAVA_HOME}/jre/lib/security/README.txt\u0026quot; \u0026amp;\u0026amp; \\ apk del build-dependencies \u0026amp;\u0026amp; \\ rm \u0026quot;/tmp/\u0026quot;*  这个dockerfile比上面的那个要好理解一点，首先基于我们已经构建好的cdjd/ci/base-alpine，从oracle官网上，通过wget下载JDK8，然后解压。将解压后的文件移动到定义好的java-home,然后同ln软连接，配置java环境变量。然后下载jce_policy补丁包，放入/jre/lib/security文件夹。 删除一些不必要文件。\n然后：\ndocker build -t jdk1.8 . // 构建镜像  完成JDK8环境的构建。我们可以通过这个镜像，去运行一些springboot的项目。\n接下来说下tomcat镜像，tomcat我这里选用的是tomcat7，Dockerfile如下：\n# 版本信息 FROM jdk1.8 MAINTAINER leongravel \u0026quot;leebroncc@gmail.com\u0026quot; # add tomcat COPY tomcat /opt/tomcat #设置环境变量 ENV TOMCAT_HOME /opt/tomcat \\ PATH ${PATH}:${TOMCAT_HOME}/bin #开启内部服务端口 EXPOSE 8080 ENTRYPOINT [\u0026quot;/opt/tomcat/bin/catalina.sh\u0026quot;, \u0026quot;run\u0026quot;]  这里我是把已经解压好的tomcat copy进镜像构建，然后设置tomcat环境变量。\nDockerfile相关问题解释 我们知道镜像都是由一层一层的layer构成的，而这一层一层的layer就是我们所写的dockerfile里面的命令所定义的，比如:\nRUN mkdir -p /opt/thunisoft RUN cd /opt/thunisoft  这就会生成两个layer，所以我们再编写dockerfile时候，应该尽可能的将所有的命令，都通过各种方式合并起来，这样构建的镜像会比两条命令，小很多。\nRUN mkdir -p /opt/thunisoft \u0026amp;\u0026amp; \\ cd /opt/thunisoft  以上是正确示范。\n另外，如果需要在dockerfile里面下载外部资源，最好下载到tmp目录里面，使用完成之后，再将这个目录统一删除。\n","id":9,"section":"posts","summary":"\u003cp\u003e刚开始在项目中使用docker的时候，使用的是centos作为基础镜像。centos的官方镜像有70M左右。加上jdk、tomcat，一个完整的业务系统，可能有450M左右。在项目组同学去试用部署的时候，所以的应用包加上服务包，有点过于大了。而且以centos作为基础镜像，可能包含很多我们并不需要的功能。所以，决定转用alpine。\u003c/p\u003e","tags":["docker","linux","alpine"],"title":"基于Alpine的基础镜像构建","uri":"https://gggggravel.com/post/%E5%9F%BA%E4%BA%8Ealpine%E7%9A%84%E5%9F%BA%E7%A1%80%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA/","year":"2019"},{"content":"网上关于docker镜像的导出导入的文章已经很多了，无非是save、export 、load、import 这几个命令，我这里只是简单记录一下今天遇到的一个特殊情况。\n使用docker save命令导出镜像文件的时候，看到的大小是没有压缩过的。我在google查到，如果给命令加上gzip，那么就会用gzip的格式打包镜像。命令如下：\ndocker save myimages:6 | gzip -c \u0026gt; myimages-6.tar.gz  这么压缩导出的镜像文件会小很多。不过奇怪的是，docker官网上并没有介绍这种方式。于是我给docker官方文档提了一个PR。\n - What I did\nAdd a gzip usage guide for docker save.\ndocker save \u0026lt;myimage\u0026gt;:\u0026lt;tag\u0026gt; | gzip \u0026gt; \u0026lt;myimage\u0026gt;_\u0026lt;tag\u0026gt;.tar.gz  This command can make the image file smaller.\n- Description for the changelog\nI found that this was not mentioned in the official guide, so I added it.\n","id":10,"section":"posts","summary":"\u003cp\u003e网上关于\u003ccode\u003edocker\u003c/code\u003e镜像的导出导入的文章已经很多了，无非是\u003ccode\u003esave\u003c/code\u003e、\u003ccode\u003eexport\u003c/code\u003e 、\u003ccode\u003eload\u003c/code\u003e、\u003ccode\u003eimport\u003c/code\u003e 这几个命令，我这里只是简单记录一下今天遇到的一个特殊情况。\u003c/p\u003e","tags":["docker","github"],"title":"docker导出镜像压缩包","uri":"https://gggggravel.com/post/docker%E5%AF%BC%E5%87%BA%E9%95%9C%E5%83%8F%E5%8E%8B%E7%BC%A9%E5%8C%85/","year":"2019"},{"content":"今天在查应用日志的时候，发现日志收集分析的应用，收到很多ip发来的同一系统的日志。经分析发现，这么多ip都是出自三台机器，由于过年期间有些机器有过断电重启的情况，所以 docker 给这个应用重新赋予了ip，导致了以上的情况出现，日志分析应用，无法知道这个日志的准确来源。\n在处理这个问题之前，首先要知道的是，docker有三种网络类型。\n bridge：桥接网络  默认情况下启动的Docker容器，都是使用 bridge，Docker安装时创建的桥接网络，每次Docker容器重启时，会按照顺序获取对应的IP地址，这个就导致重启下，Docker的IP地址就变了\n none：无指定网络  使用 --network=none ，docker 容器就不会分配局域网的IP\n host： 主机网络  使用 --network=host，此时，Docker 容器的网络会附属在主机上，两者是互通的。\n例如，在容器中运行一个Web服务，监听8080端口，则主机的8080端口就会自动映射到容器中。\n由上述可知，我的应用是使用第一种的默认情况。在应用重启，或者docker重启之后，ip会发生变化。此应用是由docker-compose部署启动的，所以这里我只说明一下docker-compose的解决方案。\n在docker-compose.yml文件里面，按照如下格式调整：\nversion: '3' services: app: image: myapp networks: app_net: ipv4_address: 172.16.238.10 ipv6_address: 2001:3984:3989::10 networks: app_net: driver: bridge ipam: driver: default config: - subnet: 172.16.238.0/24 ","id":11,"section":"posts","summary":"\u003cp\u003e今天在查应用日志的时候，发现日志收集分析的应用，收到很多\u003ccode\u003eip\u003c/code\u003e发来的同一系统的日志。经分析发现，这么多ip都是出自三台机器，由于过年期间有些机器有过断电重启的情况，所以 \u003ccode\u003edocker\u003c/code\u003e 给这个应用重新赋予了\u003ccode\u003eip\u003c/code\u003e，导致了以上的情况出现，日志分析应用，无法知道这个日志的准确来源。\u003c/p\u003e","tags":["docker","docker-compose"],"title":"给Docker容器设置固定ip","uri":"https://gggggravel.com/post/%E7%BB%99docker%E5%AE%B9%E5%99%A8%E8%AE%BE%E7%BD%AE%E5%9B%BA%E5%AE%9Aip/","year":"2019"},{"content":"整理一下自己在工作中踩过的关于gitlab-CI的坑。\ngitlab提交代码触发构建报错 主要日志如下：\nunable to access 'http://gitlab-ci-token:xxxxxxxxxxxxxxxxxxxx@gitlab.xxx.com/jd/XXX.git/': Could not resolve host: gitlab.xxx.com  我的第一反应是token可能失效了，然后我重新注册了一个runner与此项目进行关联。 重试之后发现问题仍然存在。联想到最近虚拟机曾经异常关闭过，重启之后，可能防火墙又重新打开了。\n于是：\nsystemctl status firewalld  查看防火墙状态，果然处于开启状态。猜想应该是防火墙的原因导致runner所产生的容器中，无法直接获取到gitlab的项目。\nsystemctl stop firewalld  关闭防火墙，重启docker，然后再次触发，问题得到解决。\n","id":12,"section":"posts","summary":"\u003cp\u003e整理一下自己在工作中踩过的关于\u003ccode\u003egitlab-CI\u003c/code\u003e的坑。\u003c/p\u003e","tags":["gitlab","CI","问题笔记"],"title":"gitlab-CI常见问题整理","uri":"https://gggggravel.com/post/gitlab-ci%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86/","year":"2019"},{"content":"今天在构建oraclejdk7 镜像的时候，为了方便自己以后能够随时编译 jdk 镜像，于是将 oracle-jdk-7 的 tar.gz 包上传到了 minio 服务器上，可以直接使用 wget 命令随时下载。\n在实际操作的时候，发现 minio 分享文件，最多支持分享七天，这显然和我的需求有冲突。查看了 minio 的文档，发现 minio 的功能远比我想象的强大，他提供了一个客户端工具。可以直接对 minio server 进行配置。下面我具体说下 minio 客户端是怎么设置永久下载链接的。\n安装客户端 首先，当然是安装客户端，我最开始的时候，使用的 Docker 安装，但我发现 docker 还需要配置数据卷这些，命令很长，用起来有点麻烦。正好服务器上有 Go 的环境，于是直接用 Go 命令获取 minio 客户端二进制安装文件进行下载了。\ngo get -d github.com/minio/mc  然后编译\ncd ${GOPATH}/src/github.com/minio/mc make  设置权限\nchmod +x mc  设置自定义命令\nalias mc=\u0026quot;${GOPATH}/src/github.com/minio/mc/./mc\u0026quot;  至此，我们的 minio client 就安装完成了。\n添加minio host 使用 minio client 将我自己的 minio server 添加到 mc 的配置管理：\nmc config host add minio http://142.4.xxx.198:9000 minio password S3v4  这样我们才能直接管理这个 minio server 端。\n配置下载策略 mc policy public minio/base  这个命令的作用是将 server 端的 base 文件设置为开放管理，可以直接通过 url 进行下载。\n类似于以下 http://142.4.211.198:9000/base/jdk-7u80-linux-x64.tar.gz 。\n大致的操作流程就是这样，具体可查看官网文档 。\n","id":13,"section":"posts","summary":"\u003cp\u003e今天在构建\u003ca href=\"https://hub.docker.com/r/leebroncc/alpine-oraclejdk7\"\u003e \u003ccode\u003eoraclejdk7\u003c/code\u003e 镜像\u003c/a\u003e的时候，为了方便自己以后能够随时编译 \u003ccode\u003ejdk\u003c/code\u003e 镜像，于是将 \u003ccode\u003eoracle-jdk-7\u003c/code\u003e 的 \u003ccode\u003etar.gz\u003c/code\u003e 包上传到了 \u003ccode\u003eminio\u003c/code\u003e 服务器上，可以直接使用 \u003ccode\u003ewget\u003c/code\u003e 命令随时下载。\u003c/p\u003e","tags":["docker","minio"],"title":"minio设置永久下载链接","uri":"https://gggggravel.com/post/minio%E8%AE%BE%E7%BD%AE%E6%B0%B8%E4%B9%85%E4%B8%8B%E8%BD%BD%E9%93%BE%E6%8E%A5/","year":"2018"},{"content":"之前在项目中做过CI的技术选型，基本成熟之后，现在来总结一下两者的优劣。\nJenkins Jenkins 是一个广泛用于持续构建的可视化 web 工具，jenkins 可以很好的支持各种语言的项目构建，也完全兼容ant、maven、gradle等多种第三方构建工具，同时跟svn、git能无缝集成，也支持直接与知名源代码托管网站，比如github、bitbucket直接集成，而且插件众多，在这么多年的技术积累之后，在国内大部分公司都有使用Jenkins。\ngitlab-CI gitlab-CI是gitlab8.0之后自带的一个持续集成系统，中心思想是当每一次push到gitlab的时候，都会触发一次脚本执行，然后脚本的内容包括了测试，编译，部署等一系列自定义的内容。\ngitlab-CI的脚本执行，需要自定义安装对应gitlab-runner来执行，代码push之后，webhook检测到代码变化，就会触发gitlab-CI，分配到各个Runner来运行相应的脚本script。这些脚本有的是测试项目用的，有的是部署用的。\njenkins VS gitlab-runner gitlab-CI优势   轻量级，不需要复杂的安装手段。\n  配置简单，与gitlab可直接适配。\n  实时构建日志十分清晰，UI交互体验很好\n  使用 YAML 进行配置，任何人都可以很方便的使用。\n  gitlab-CI劣势  没有统一的管理界面，无法统筹管理所有项目 配置依赖于代码仓库，耦合度没有Jenkins低  Jenkins优势  编译服务和代码仓库分离，耦合度低 插件丰富，支持语言众多。 有统一的web管理界面  Jenkins劣势  插件以及自身安装较为复杂 对docker插件支持不是很友好 体量较大，不是很适合小型团队  最后我选择了gitlab-CI，因为我们团队使用的gitlab，和gitlab-CI无缝连接，由于我们使用了docker，所以在选型jenkins的时候，感觉插件有点难用。\n总结 我认为选择工具本身就是一个“持续迭代”的过程，这个过程中根据自己团队的特点和规模，选择最合适目前的工具就好了。等到工具已经没法满足团队需求了，再选择更加合适的。\n","id":14,"section":"posts","summary":"\u003cp\u003e之前在项目中做过CI的技术选型，基本成熟之后，现在来总结一下两者的优劣。\u003c/p\u003e","tags":["Jenkins","gitlab-CI"],"title":"gitlab CI vs jenkins 如何选择","uri":"https://gggggravel.com/post/gitlab-ci-vs-jenkins-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9/","year":"2018"},{"content":"首先确认是否已经关闭防火墙； 请顺序运行以下命令：\nnmcli connection modify docker0 connection.zone trusted systemctl stop NetworkManager.service firewall-cmd --permanent --zone=trusted --change-interface=docker0 systemctl start NetworkManager.service nmcli connection modify docker0 connection.zone trusted systemctl restart docker.service ","id":15,"section":"posts","summary":"\u003cp\u003e首先确认是否已经关闭防火墙； 请顺序运行以下命令：\u003c/p\u003e","tags":["docker","问题笔记"],"title":"解决docker 容器内访问宿主机“No route to host”的问题","uri":"https://gggggravel.com/post/%E8%A7%A3%E5%86%B3docker-%E5%AE%B9%E5%99%A8%E5%86%85%E8%AE%BF%E9%97%AE%E5%AE%BF%E4%B8%BB%E6%9C%BAno-route-to-host%E7%9A%84%E9%97%AE%E9%A2%98/","year":"2018"},{"content":"今天遇到一个问题，如何给一个gitlab的仓库瘦身。在我们日常开发中，由于不规范或者不小心，误提交了一些大文件，导致git的仓库变得很大，这是你直接删除大文件也无济于事，因为git commit log里面，会记录你每一次的提交详情。一般来说，给git瘦身有两种方式，一种是官方提供的git-filter-branch,这种命令用起来极为繁琐。另一种是本文将要说到的BFG.\nBFG介绍 在gitlab的帮助页面中也推荐了这个工具。官网说是比git-filter-branch工具快10-720倍。这里根据我的使用，介绍一下这个工具。\n这个工具的官网：https://rtyley.github.io/bfg-repo-cleaner/\n使用步骤  下载官网的程序包。重命名为bfg.jar clone自己的git repo，使用\u0026ndash;mirror参数。(注意这里一定要加--mirror 参数，mirror 可以保证本地仓库和远端完全一致)  git clone --mirror git@github.com:repo.git  将bfg.jar放到和repo.git同级的目录  java -jar bfg.jar --strip-blobs-bigger-than 1M repo.git  这一步的目的是，删除commit历史中，文件大小大于1M的二进制文件。\n使用git gc清理不需要的数据  cd repo.git git reflog expire --expire=now --all \u0026amp;\u0026amp; git gc --prune=now --aggressive  提交更改  git push ","id":16,"section":"posts","summary":"\u003cp\u003e今天遇到一个问题，如何给一个gitlab的仓库瘦身。在我们日常开发中，由于不规范或者不小心，误提交了一些大文件，导致git的仓库变得很大，这是你直接删除大文件也无济于事，因为git commit log里面，会记录你每一次的提交详情。一般来说，给git瘦身有两种方式，一种是官方提供的\u003ccode\u003egit-filter-branch\u003c/code\u003e,这种命令用起来极为繁琐。另一种是本文将要说到的BFG.\u003c/p\u003e","tags":["git","bfg"],"title":"使用BFG给git仓库瘦身","uri":"https://gggggravel.com/post/%E4%BD%BF%E7%94%A8bfg%E7%BB%99git%E4%BB%93%E5%BA%93%E7%98%A6%E8%BA%AB/","year":"2018"},{"content":"问题描述 在构建jdk镜像的时候，由于无法直接从oracle上获取到jdk的压缩包，所以我把压缩包放到minio上，通过wget下载（实际上是多此一举，可以直接ADD进去）。但是我在用wget下载minio的数据的时候，直接报错了。\nAccess to files denied  解决办法 在启动minio容器的时候，指定PUBLIC_URL， 具体命令如下：\ndocker run -d -p 9000:9000 --name minio \\ -e \u0026quot;MINIO_ACCESS_KEY=minio\u0026quot; \\ -e \u0026quot;MINIO_SECRET_KEY=123456@minio\u0026quot; \\ -e \u0026quot;PUBLIC_URL=95.555.9.60\u0026quot; \\ -v /mnt/data:/data \\ -v /mnt/config:/root/.minio \\ minio/minio server /data ","id":17,"section":"posts","summary":"\u003ch3 id=\"问题描述\"\u003e问题描述\u003c/h3\u003e\n\u003cp\u003e在构建jdk镜像的时候，由于无法直接从oracle上获取到jdk的压缩包，所以我把压缩包放到minio上，通过wget下载（实际上是多此一举，可以直接ADD进去）。但是我在用wget下载minio的数据的时候，直接报错了。\u003c/p\u003e","tags":["docker","minio"],"title":"使用wget下载minio中的内容报错","uri":"https://gggggravel.com/post/minio%E4%B8%8B%E8%BD%BD%E6%8A%A5%E9%94%99/","year":"2018"},{"content":"docker默认安装路径是var/lib/docker这个目录下面的，如果这个目录挂载的空间不大的话，那么在实际使用中，可能会导致docker空间不足的情况，我们需要将这个默认目录迁移到比较大的空间下面去。\n基础环境  centos 7 docker 1.18  执行步骤  停止docker  systemctl stop docker   创建新的docker安装目录，我的机器上，home目录空间比较大，所以我选择了这个目录  mkdir -p /home/lib/docker   将现有安装目录，辅助到刚刚创建的目录  cp -R /var/lib/docker/* /home/lib/docker/   修改docker配置（/etc/systemd/system/docker.service.d/devicemapper.conf），如果没有此目录或者文件，需要自己重新创建。我的机器没有，所以：  mkdir -p /etc/systemd/system/docker.service.d/; vi devicemapper.conf  在文件末尾，写入以下内容：\n[Service] ExecStart= ExecStart=/usr/bin/dockerd --insecure-registry=私服地址 --graph=/home/lib/docker  注意：如果没有私服地址的话就可以去掉”--insecure-registry=私服地址”。\n 然后重启docker  systemctl daemon-reload //重载进程 systemctl restart docker // 重启docker   然后docker info 检查以下是否已经修改完成。  Docker Root Dir: /home/lib/docker/ ","id":18,"section":"posts","summary":"\u003cp\u003e\u003ccode\u003edocker\u003c/code\u003e默认安装路径是\u003ccode\u003evar/lib/docker\u003c/code\u003e这个目录下面的，如果这个目录挂载的空间不大的话，那么在实际使用中，可能会导致\u003ccode\u003edocker\u003c/code\u003e空间不足的情况，我们需要将这个默认目录迁移到比较大的空间下面去。\u003c/p\u003e","tags":["docker"],"title":"docker安装目录迁移","uri":"https://gggggravel.com/post/docker%E5%AE%89%E8%A3%85%E7%9B%AE%E5%BD%95%E8%BF%81%E7%A7%BB/","year":"2018"},{"content":"嗯，最近在搭建flink的环境，用普通的 docker 命令构建的时候，老是遇到各种的问题。于是转为用 docker-compose 试试。\ndocker-compose 介绍 docker-compose 是一个用来把 docker 自动化的东西。 有了 docker-compose 你可以把所有繁复的 docker 操作全都一条命令，自动化的完成。 用通俗的语言来说，我们平时操作 docker 还是很原始的一系列动作，你手动使用 docker 的动作可以拆分成：\n  找到一个系统镜像 // docker search 安装好 vm 或者 virtual box // apt-get install docker 在 vm 中安装镜像 // docker run -d -it 你的镜像   这是最小的动作， 如果你要映射硬盘，设置 nat 网络或者桥接网络，等等…你就要做更多的 docker 操作， 这显然是非常没有效率的。\n但是我们写在 docker-compose.yaml 里面就很好了。 你只需要写好后 只运行一句 docker-compose up -d 就可以启动了。\n安装docker-compse 下载最新版的 docker-compose文件:\nudo curl -L https://github.com/docker/compose/releases/download/1.16.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose  添加可执行权限\nsudo chmod +x /usr/local/bin/docker-compose  测试安装结果\ndocker-compose --version  安装flink  在指定目录下，新建 docker-compose.yml 文件如下：  version: \u0026quot;2.1\u0026quot; services: jobmanager: image: ${FLINK_DOCKER_IMAGE_NAME:-flink} expose: - \u0026quot;6123\u0026quot; ports: - \u0026quot;8081:8081\u0026quot; command: jobmanager environment: - JOB_MANAGER_RPC_ADDRESS=jobmanager taskmanager: image: ${FLINK_DOCKER_IMAGE_NAME:-flink} expose: - \u0026quot;6121\u0026quot; - \u0026quot;6122\u0026quot; depends_on: - jobmanager command: taskmanager links: - \u0026quot;jobmanager:jobmanager\u0026quot; environment: - JOB_MANAGER_RPC_ADDRESS=jobmanager  文件的意思是，先基于 flink 镜像，启动一个 jobmanager，然后再基于 jobmanager 和 flink 镜像，启动一个taskmanager。\n新建完成之后，在当前目录docker-compose up.然后访问localhost:8080查看结果，如果 taskmanager 页面有配置数据。说明 flink 已经部署成功。\n","id":19,"section":"posts","summary":"\u003cp\u003e嗯，最近在搭建flink的环境，用普通的 \u003ccode\u003edocker\u003c/code\u003e 命令构建的时候，老是遇到各种的问题。于是转为用 \u003ccode\u003edocker-compose\u003c/code\u003e 试试。\u003c/p\u003e","tags":["docker","docker-compose"],"title":"docker-compose搭建flink环境","uri":"https://gggggravel.com/post/docker-compose%E6%90%AD%E5%BB%BAflink%E7%8E%AF%E5%A2%83/","year":"2018"},{"content":"今天遇到一个问题，flink 的 job manager 分块，把容器的空间占满了，导致无法上传新的 job。所以需要容器扩容。简单查了一下，做下记录。\nDocker 默认空间大小分为两个，一个是池空间大小，另一个是容器空间大小。\n池空间大小默认为：100G\n容器空间大小默认为是：10G\n所以修改空间大小也分为两个。\n首先关闭 docker :\nsystemctl stop docker  然后删除 docker 数据：\nrm -rf /var/lib/docker  创建新的 docker 数据池:\nmkdir -p /var/lib/docker/devicemapper/devicemapper dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/data bs=1G count=0 seek=1000 dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/metadata bs=1G count=0 seek=10  上面的1000为1TB大小，即为数据池空间大小为1TB，而10则为 Metadata 的空间大小，10GB\n重启容器即可完成扩容：\nsystemctl restart docker ","id":20,"section":"posts","summary":"\u003cp\u003e今天遇到一个问题，\u003ccode\u003eflink\u003c/code\u003e 的 \u003ccode\u003ejob manager\u003c/code\u003e 分块，把容器的空间占满了，导致无法上传新的 \u003ccode\u003ejob\u003c/code\u003e。所以需要容器扩容。简单查了一下，做下记录。\u003c/p\u003e","tags":["docker","bugfix"],"title":"Docker容器扩容","uri":"https://gggggravel.com/post/docker-%E5%AE%B9%E5%99%A8%E6%89%A9%E5%AE%B9/","year":"2018"},{"content":"问题症状 修改了git密码之后，拉取项目代码出错：\ngit remote: HTTP Basic: Access denied  原因 远程服务端的用户名和密码与当前系统中git保存的用户名和密码有冲突\n解决方案 git config --system --unset credential.helper.  ","id":21,"section":"posts","summary":"问题症状 修改了git密码之后，拉取项目代码出错： git remote: HTTP Basic: Access denied 原因 远程服务端的用户名和密码与当前系统中git保存的用户名和密码有冲突 解决方案 git","tags":["git","bugfix","问题笔记"],"title":"git错误 HTTP Basic Access denied","uri":"https://gggggravel.com/post/git%E9%94%99%E8%AF%AF-http-basic-access-denied/","year":"2018"},{"content":"今天在部署的时候，发现服务提供者启动成功，但是消费者没法拿到服务。查了下发现是服务提供者没注册成功。\n问题分析 当docker容器部署dubbo提供者和常规部署应用混合使用一套zookeeper时，将出现Docker容器中的dubbo提供者向zookeeper注册容器IP导致常规部署应用无法访问容器IP而失败。\n解决方案 在github上查的时候，发现有人提出了这个问题，官方回复是将在2.5.7的版本中解决。 Dubbo在启动阶段提供两对系统属性，用于设置外部通信的IP和端口地址。\n DUBBO_IP_TO_REGISTRY \u0026mdash; 注册到注册中心的IP地址 DUBBO_PORT_TO_REGISTRY \u0026mdash; 注册到注册中心的端口 DUBBO_IP_TO_BIND \u0026mdash; 监听IP地址 DUBBO_PORT_TO_BIND \u0026mdash; 监听端口  我将启动命令改为如下格式：\ndocker run -d \\ --name \u0026lt;containerName\u0026gt; \\ --net dubbo \\ -e DUBBO_IP_TO_REGISTRY=\u0026lt;ip\u0026gt; \\ -e DUBBO_PORT_TO_REGISTRY=\u0026lt;port\u0026gt; \\ -p \u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;:\u0026lt;port\u0026gt; \\ -v dubbo:/log \\ --restart=always \\ \u0026lt;imageName\u0026gt;  问题得到解决！\n","id":22,"section":"posts","summary":"\u003cp\u003e今天在部署的时候，发现服务提供者启动成功，但是消费者没法拿到服务。查了下发现是服务提供者没注册成功。\u003c/p\u003e","tags":["docker","dubbo","问题笔记"],"title":"Dubbo在Docker中的服务注册","uri":"https://gggggravel.com/post/dubbo%E5%9C%A8docker%E4%B8%AD%E7%9A%84%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C/","year":"2018"},{"content":"查找需要拷贝的目的地容器\ndocker ps -a  找出我们想要的容器名字全称 查找容器长ID\ndocker inspect -f '{{.ID}}' 容器名字  然后通过容器ID拷贝\ndocker cp 本地路径 容器长ID:容器路径 docker cp /var/gravel/config.properties 38ef22f922704b32cf2650407e16b146bf61c221e6b8ef679989486d6ad9e856:/root/web/config.properties ","id":23,"section":"posts","summary":"\u003cp\u003e查找需要拷贝的目的地容器\u003c/p\u003e","tags":["docker"],"title":"拷贝文件到Docker容器中","uri":"https://gggggravel.com/post/%E6%8B%B7%E8%B4%9D%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E5%88%B0docker%E5%AE%B9%E5%99%A8/","year":"2018"},{"content":"问题描述 当docker在 “-d”守护态运行tomcat容器的时候，，docker attach 容器id 就会一直卡着。 因为此时容器运行的进程是ssh，而不是/bin/bash 也没有虚拟终端（-it）参数，所以是进入不到的。\n解决方案 放弃attach，使用docker exec进入Docker容器\nsudo docker exec -it {容器id} /bin/bash  使用这条命令即可进入运行的容器。\n","id":24,"section":"posts","summary":"\u003ch3 id=\"问题描述\"\u003e问题描述\u003c/h3\u003e\n\u003cp\u003e当docker在 “-d”守护态运行tomcat容器的时候，，docker attach 容器id 就会一直卡着。\n因为此时容器运行的进程是ssh，而不是/bin/bash 也没有虚拟终端（-it）参数，所以是进入不到的。\u003c/p\u003e","tags":["docker","tomcat","问题笔记"],"title":"Docker 如何进入运行的tomcat容器","uri":"https://gggggravel.com/post/%E5%A6%82%E4%BD%95%E8%BF%9B%E5%85%A5%E8%BF%90%E8%A1%8C%E7%9A%84tomcat%E5%AE%B9%E5%99%A8/","year":"2018"},{"content":"Java 的 String 类几乎是 Java 中最常使用到的对象类型，关于 String 的一些基础知识对开发者来说显得尤为重要。下面就对 String 相关的一些知识点进行列举和归纳，希望能够加深对 String 对象的认识。\n字符串常量池 JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化。为了减少在JVM中创建的字符串的数量，字符串类维护了一个字符串池，每当代码创建字符串常量时，JVM会首先检查字符串常量池。如果字符串已经存在池中，就返回池中的实例引用。如果字符串不在池中，就会实例化一个字符串并放到池中。Java能够进行这样的优化是因为字符串是不可变的，可以不用担心数据冲突进行共享。\n另外需要注意通过new操作符创建的字符串对象不指向字符串池中的任何对象，但是可以通过使用字符串的intern()方法来指向其中的某一个。\nString.itern()的基本原理和作用 String.intern()是一个Native方法，底层调用C++的 StringTable::intern 方法，源码注释：当调用 intern 方法时，如果常量池中已经该字符串，则返回池中的字符串；否则将此字符串添加到常量池中，并返回字符串的引用。\n所以明面上，它有两大好处，一是重复的字符串，会用同一个引用代替；二是字符串比较，不再需要逐个字符的equals()比较，而用==对比引用是否相同即可。\nString s = new String(“abc”)语句创建了几个对象？ 首先括号里的\u0026quot;abc\u0026quot;先到String pool里看有没\u0026quot;abc\u0026quot;这个对象，没有则在pool里创建这个对象。此时在pool创建了一个\u0026quot;abc\u0026quot;对象。然后通过new语句又创建了一个\u0026quot;abc\u0026quot;对象，而这个对象是放在内存的堆里，这里的s指向堆里的对象。\n故创建常量池和堆内存中两个对象，两个对象的地址值不一样，返回的是堆内存的地址。\nString 的 ==、equals 以及 hashcode 先来看一段代码：\npublic static void main(String[] args) { String a = \u0026quot;hello\u0026quot;; String b = \u0026quot;hello\u0026quot;; String c = new String(\u0026quot;hello\u0026quot;); String d = new String(\u0026quot;hello\u0026quot;); System.out.println(a.hashCode() == b.hashCode()); //true， String重写了hashcode方法，只跟String的value[]有关 System.out.println(a.hashCode() == c.hashCode()); //true 同上 System.out.println(a.equals(b)); //true，String也重写了equals方法，只跟value[]有关 System.out.println(a.equals(c)); //true，同上 System.out.println(a == b); //true,因为a和b都在常量池中， System.out.println(a == c); //false，a在常量池中，c在堆中 System.out.println(c == d); //false，c和d都在堆中，但是为不同的对象 String hello = \u0026quot;Hello\u0026quot;, lo = \u0026quot;lo\u0026quot;; System.out.println((hello == (\u0026quot;Hel\u0026quot;+\u0026quot;lo\u0026quot;))); //true,\u0026quot;Hel\u0026quot;+\u0026quot;lo\u0026quot;在编译时进行计算，被当做常量 System.out.println((hello == (\u0026quot;Hel\u0026quot;+lo))); //false，在运行时通过连接计算出的字符串是新创建的，因此是堆中创建的新对象 System.out.println(hello == (\u0026quot;Hel\u0026quot;+lo).intern()); //true，通过使用字符串的intern()方法来指向字符串池中的对象 }  再来看看 String 重写的 hashcode 及 equals 方法\npublic int hashCode() { int h = hash; if (h == 0 \u0026amp;\u0026amp; value.length \u0026gt; 0) { char val[] = value; for (int i = 0; i \u0026lt; value.length; i++) { h = 31 * h + val[i]; } hash = h; } return h; } public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; }  结论：\n String的hashCode之和value有关 equals比较的也只是value（指向同一个对象时value也必然相同，换句话就是a==b ||（a.length=b.length \u0026amp;\u0026amp; {a[i]=b[i]}）） a==b比较的是ref hashSet中比较是否重复的依据是a.hasCode()=b.hasCode() \u0026amp;\u0026amp; a.equals(b) 因此两个不同ref的String对象在hashSet中会被认为是同一个元素 两个String的hashCode相同并不代表着equals比较时会相等，即不同的String可能会产生相同的hash值，例如Aa和BB的hashcode都是2112  hashcode 方法的作用 Java的Object类中定义了public native int hashCode()方法，也就是说每一个java类都会继承这个方法（有的类会重写此方法），那这个方法到底有什么用，为什么这么重要？\n在Java中，hashCode方法的主要作用是为了配合基于散列的集合一起正常运行，这样的散列集合包括HashSet、HashMap以及HashTable。\n举个例子：当向集合中插入对象时，如何判别在集合中是否已经存在该对象了？（注意：集合中不允许重复的元素存在）。\n很容易想到的方法是调用equals方法来逐个进行比较，这个方法确实可行，但是如果集合中已经存在一万条数据或者更多的数据，如果采用equals方法去逐一比较，效率必然是一个问题。\nJDK中实现的方法是：当集合要添加新的对象时，先调用这个对象的hashCode方法，得到对应的hashcode值，实际上在HashMap的具体实现中会用一个table保存已经存进去的对象的hashcode值（hashcode值一般都会被缓存），如果table中没有该hashcode值，它就可以直接存进去，不用再进行任何比较了；如果存在该hashcode值， 就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址。这样一来实际调用equals方法的次数就大大降低了。\n总结一句话就是：可以根据hashcode值判断两个对象是否不等，这样效率更高！\n可以直接根据hashcode值判断两个对象是否相等吗？ 不可以！前面也演示了不同的对象可能会生成相同的hashcode值。虽然不能根据hashcode值判断两个对象是否相等，但是可以直接根据hashcode值判断两个对象不等，如果两个对象的hashcode值不等，则必定是两个不同的对象。\n 两个对象调用equals方法得到的结果为true，则两个对象的hashcode值必定相等； 如果equals方法得到的结果为false，则两个对象的hashcode值不一定不同 如果两个对象的hashcode值不等，则equals方法得到的结果必定为false； 如果两个对象的hashcode值相等，则equals方法得到的结果未知。  在重写equals方法的同时，必须重写hashCode方法。为什么这么说？ 重写 equals 方法后必须重写 hashCode 是为了让 Java 中所有使用到 Hash 算法的数据结构能够正常运行。\n举个例子：假如 a 和 b 是两个对象，你重写了 equals() 方法，a.equals(b)结果为true。\n然后创建一个 HashMap，执行 map.put(a,c); map 中插入了一条数据，键是 a 值是 c，调用 map.get(a) 可以返回对象 c，但是调用 map.get(b) 却不能返回对象 c， 但是 a 和 b 两个对象是相等的，相等的对象却得不到相同的结果，就不符合逻辑了。因为 HashMap 是根据键对象的 HashCode 来进行快速查找的，所以你必须保证 a 和 b 这两个相同对象的 HashCode 也相同，因此你需要重写 hashCode() 方法。另外，如果你要用到 HashSet，在这个例子中 a 和 b 可以同时插入到 HashSet 中，然而这两个对象在逻辑上有时相等的，这不符合 HashSet 的定义。\n另外这也是hashcode方法的要求，在Object的hashcode方法注释中明确做了如下说明：\n If two objects are equal according to the equals(Object) method, then calling the hashCode() method on each of the two objects must produce the same integer result.\n hashcode 是对象的内存地址吗 首先String就不是，因为它重写了hashcode方法。这个问题问的应该是object中的hashcode的native方法。因为不同JVM的实现不一样，可能有JVM这样实现，但大多时候并不是这样，只能说可能存储地址有一定关联。\nString, StringBuffer，StringBuilder的区别？  String 是字符串常量，是不可变的，而 StringBuffer 及 StringBuilder 可变 在做字符串拼接时，直接操作 String 比较耗资源，因为它的不可变性，会导致创建多个中间对象 String、StringBuffer 是线程安全的，StringBuilder 线程不安全  三者之间的关系看这张图：\n看源码会发现 StringBuffer 和 StringBuilder 继承了同样的接口和抽象类，其中的方法和实现也几乎都一样，唯一的区别就是在 StringBuffer 中很多方法都加了 synchronized 修饰符 从而达到线程安全的目的。\nString是不可变的有什么好处？  由于String是不可变类，所以在多线程中使用是安全的，我们不需要做任何其他同步操作。 不同的字符串变量可以引用池中的相同的字符串，节省大量内存空间。  Java 能不能自己创建一个 java.lang.String 的对象 先说结论，下面会详细解释。可以创建，但是不能正常的加载。首先 JVM 类加载的双亲委托机制使得所有的类都优先从父类或者启动类加载，导致同名自定义的类没有机会加载；其次即使定义了一个父类找不到的类名从而轮到自定义的类加载器加载，也会因为 JVM 限制包名以 java.* 开头的类加载，会抛出一个安全异常。\n其实这个问题和 String 没什么关系，所有 rt.jar 包下的类都同理。这里主要涉及到 Java 的类加载机制，以及类加载的一些特殊限制（处于安全考虑）。下面对类加载相关的知识进行简单总结。\nJava 类加载有一个称为双亲委托的机制：某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。\n使用双亲委派模型的好处在于 Java 类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存在在 rt.jar 中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的 Bootstrap ClassLoader 进行加载，因此 Object 类在程序的各种类加载器环境中都是同一个类。\njdk 自带了3种类加载器，分别是启动类加载器（Bootstrap ClassLoader），扩展类加载器（Extension ClassLoader），应用程序类加载器（Application ClassLoader）。启动类加载器由native实现（HotSpot虚拟机中由c++实现），后两种加载器是继承自抽象类 java.lang.ClassLoader。\n在 rt.jar 包中的 java.lang.ClassLoader 类中，我们可以查看类加载实现过程的代码如下：\nprotected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class\u0026lt;?\u0026gt; c = findLoadedClass(name); //首先检查该类是否已经加载过 if (c == null) { //没加载过的话按照以下步骤加载 long t0 = System.nanoTime(); try { if (parent != null) { //1. 有父加载器时递归调用父加载器加载 c = parent.loadClass(name, false); } else { //2. 没有父加载器时调用启动加载器加载 c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } //3. 前面几步都没有加载的情况下调用加载器实现类自定义的findClass方法自定义加载 if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } }  如果需要自定义类加载器，方法注释中可以看到 Subclasses of ClassLoader are encouraged to override findClass(String) rather than this method. 也就是说一般子类只需要重写这个方法即可，而不是重写整个 loadClass() 方法。\n","id":25,"section":"posts","summary":"\u003cp\u003eJava 的 String 类几乎是 Java 中最常使用到的对象类型，关于 String 的一些基础知识对开发者来说显得尤为重要。下面就对 String 相关的一些知识点进行列举和归纳，希望能够加深对 String 对象的认识。\u003c/p\u003e","tags":["字符串","Java"],"title":"java-String知识点汇总","uri":"https://gggggravel.com/post/%E5%85%B3%E4%BA%8Ejava-string%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/","year":"2018"},{"content":"tomcat 启动报错\nClassCastException: org.apache.tomcat.websocket.server.WsServerContainer cannot be cast to javax.websocket.server.ServerContainer  问题原因 出现这个问题的原因是，apache的websocket包和javax-servlet包冲突了。\n解决方案 在pom文件中，排除javax.websocket\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.websocket\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.websocket-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; ","id":26,"section":"posts","summary":"\u003cp\u003etomcat 启动报错\u003c/p\u003e","tags":["java","tomcat","问题笔记"],"title":"tomcat启动报错","uri":"https://gggggravel.com/post/tomcat%E5%90%AF%E5%8A%A8%E6%8A%A5%E9%94%99/","year":"2018"},{"content":"我这里安装的是redis:4.0\n拉取镜像 首先从镜像仓库拉取Redis的镜像\ndocker pull redis:4.0  创建挂载目录以及配置文件 在root用户下：\nmkdir -p /redis/data  然后从redis官网下载和版本对应的redis.conf文件，根据自己的需求修改其中的内容，需要注意的是，一定要把daemonize yes给注释掉。 不然启动可能会失败。原因是：\n Redis 进程被幽灵化(后台化)后,启动Redis的那个进程,也就是Docker执行进程无事可做, 因此Docker执行进程退出。\n 启动 使用如下命令启动\n docker run -p 6379:6379 -v /root/redis/redis.conf:/etc/redis/redis.conf -v /root/redis/data:/data -d redis:4.0 redis-server /etc/redis/redis.conf  这里直接指定我们刚才创建的宿主机挂载目录。 如果需要使用rdb或aof恢复数据或者初始化数据，请一定要在配置文件中指定你说需要的方式，不然会失败。\n常用命令 这里说一下在docker中怎么使用redis的常用命令 首先，我们需要进入redis容器：\n docker exec -it 650 redis-cli  其中，650为你的redis容器的id。 输入认证：\nauth 123456  这一步的目的是用密码进入redis。如果顺利的话，你就已经可以在docker容器中使用redis相关的命令了。\n","id":27,"section":"posts","summary":"\u003cp\u003e我这里安装的是\u003ccode\u003eredis:4.0\u003c/code\u003e\u003c/p\u003e","tags":["docker","redis"],"title":"docker安装redis并使用外部配置和数据初始化","uri":"https://gggggravel.com/post/docker%E5%AE%89%E8%A3%85redis%E5%B9%B6%E4%BD%BF%E7%94%A8%E5%A4%96%E9%83%A8%E9%85%8D%E7%BD%AE%E5%92%8C%E6%95%B0%E6%8D%AE%E5%88%9D%E5%A7%8B%E5%8C%96/","year":"2018"},{"content":"Dubbo是一款高性能Java RPC框架，目前 dubbo 重启开源社区维护了，捐献给了 apache，所以在项目建设初期，我们团队也使用了Dubbo。\n为什么要使用Dubbo 因为整个平台系统在设计之初就显得过于庞大，所以必须进行服务应用拆分，不然开发、测试、维护成本巨大。目前我们公司是将各业务口细化成具体的业务系统，然后将可以通用的部分抽象成服务供各个系统使用。类似消息、存储等应用。所以Dubbo对我们来说是一个不错的选择。\n说一下的 dubbo 的工作原理 在Dubbo的架构设计中，分为了十层，我可以从这十层简单说下，\n 第一层是service层，服务提供者和消费者，定义自己的接口和实现。 第二层是config层，ServiceConfig等，主要是给消费者或者提供者配置自己的基本信息，类似接口名字，注册中心地址等。 第三层是proxy服务代理层，无论是 consumer 还是 provider，dubbo 都会给你生成代理，代理之间进行网络通信 第四层是registry 注册中心层，主要是封装服务的注册和发现。,我们可以通过这个这一层的各个类，RegistryService、以及RegistryFactory等，实现自己的自定义注册等。 第五层是cluster 路由层，封装多个提供者的路由及负载均衡，并桥接注册中心，以 Invoker 为中心，扩展接口为 Cluster, Directory, Router, LoadBalance。 第六层：monitor 层，监控层，对 rpc 接口的调用次数和调用时间进行监控 第七层：protocal 层，远程调用层，封装 rpc 调用 第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步 第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口 第十层：serialize 层，数据序列化层  首先，服务提供者定义自己的服务，然后去注册中心注册， 消费者去注册中心订阅，注册中心再通知消费者。 然后消费者调用服务提供者，并且二者异步通知监控中心，自己调用了服务，或者提供了服务。\n","id":28,"section":"posts","summary":"\u003cp\u003e\u003ccode\u003eDubbo\u003c/code\u003e是一款高性能\u003ccode\u003eJava RPC\u003c/code\u003e框架，目前 \u003ccode\u003edubbo\u003c/code\u003e 重启开源社区维护了，捐献给了 \u003ccode\u003eapache\u003c/code\u003e，所以在项目建设初期，我们团队也使用了\u003ccode\u003eDubbo\u003c/code\u003e。\u003c/p\u003e","tags":["dubbo"],"title":"Dubbo的工作原理简析","uri":"https://gggggravel.com/post/dubbo%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E7%AE%80%E6%9E%90/","year":"2018"},{"content":"最开始的时候，我尝试Jenkins+docker，可是Jenkins的docker依赖和插件，实在太过麻烦，配置项等等，太重。所以我转为使用gitlab runner来实现自动构建并打包镜像。\n准备工作  安装docker 在docker同一个机器上安装gitlab runner 配置.gitlab-ci.yml  安装Docker 参考官方文档，唯一需要注意的是，需要将镜像仓库地址修改为私有的地址。可以通过配置Deamon.json实现。具体配置如下。 registry-mirrors代表私有仓库地址，insecure-registries的作用是，push指向的地址。\n Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，所以这里最好直接指定仓库地址，不然push的时候会报错。\n { \u0026quot;registry-mirrors\u0026quot;: [ \u0026quot;http://registry.******.com:5000\u0026quot; ], \u0026quot;insecure-registries\u0026quot;: [ \u0026quot;registry.******.com:5000\u0026quot; ], \u0026quot;debug\u0026quot;: true, \u0026quot;experimental\u0026quot;: false }  安装gitlab runner 服务器是centos 7,以下的步骤都是基于centos 7\n下载二进制安装文件 curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh | sudo bash  安装 sudo yum install gitlab-runner  注册Runner sudo gitlab-runner register   填入填入私有gitlab的url  Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com ) https://gitlab.******.com  输入项目的gitlab token  Please enter the gitlab-ci token for this runner xxx  添加runner描述  Please enter the gitlab-ci description for this runner jiedu-ci  添加描述标签，若添加多个需用逗号隔开  Please enter the gitlab-ci tags for this runner (comma separated): ci,shws,jiedu  选择runner 运行模式 这里我选择的Docker，因为我们要使用docker 镜像以及一些其他的镜像   其他的我也不是很了解\n Please enter the executor: ssh, docker+machine, docker-ssh+machine, kubernetes, docker, parallels, virtualbox, docker-ssh, shell: docker  设置基础镜像  Please enter the Docker image (eg. ruby:2.1): registry.******.com:5000/dzjz/ci/maven  配置gitlab runner vi /etc/gitlab-runner/config.toml  写入\nconcurrent = 1 check_interval = 0 environment = [\u0026quot;MAVEN_HOME=/path/to/maven\u0026quot;] [[runners]] name = \u0026quot;shws-ci\u0026quot; url = \u0026quot;http://gitlab.******.com\u0026quot; token = \u0026quot;234234*******************\u0026quot; executor = \u0026quot;docker\u0026quot; output_limit = 208192 [runners.docker] tls_verify = false image = \u0026quot;registry.******.com:5000/dzjz/ci/maven\u0026quot; privileged = true cache_dir = \u0026quot;cache\u0026quot; disable_cache = false volumes = [\u0026quot;/var/run/docker.sock:/var/run/docker.sock\u0026quot;, \u0026quot;/cache\u0026quot;,\u0026quot;/root/.m2:/root/.m2\u0026quot;] shm_size = 0 pull_policy = \u0026quot;if-not-present\u0026quot; [runners.cache]  当然这个部分后期会进一步完善修改，目前只是一个示例。\n配置.gitlab-ci.yml 这一部分，具体可以参考官方文档以及这篇，项目的配置如下：\n# 定义stages stages: - build - push # 构建各个依赖组件的jar包，并复制Dockerfile对应位置等待构建. build-job: # image: registry.******.com:5000/dzjz/ci/maven stage: build only: - feature/20180428-1.0.0.0script1-第二版 script: - mkdir -p jd-ci/shws/kf - cd shws/ \u0026amp;\u0026amp; pwd - mvn clean install -U - echo '准备发布生活卫生镜像到私有镜像仓库！' - rm -rf src/dockerfile/*.war - cd .. \u0026amp;\u0026amp; pwd - cp -r shws/target/shws.war shws/src/dockerfile/Dockerfile jd-ci/shws/kf - cd jd-ci/shws/kf/ \u0026amp;\u0026amp; ls ## 下面这个配置的作用是在不同的job间传递共享war包以及Dockerfile artifacts: name: \u0026quot;${CI_REGISTRY_IMAGE}:${CI_COMMIT_REF_SLUG}\u0026quot; paths: - jd-ci/shws/kf/* expire_in: 1 day push-job: stage: push only: - feature/20180428-1.0.0.0script1-第二版 image: registry.******.com:5000/docker:latest services: - registry.******.com:5000/docker:dind before_script: - docker info script: - echo '准备构建镜像并push到私有仓库' #- cd ./jd/shws/kf/ \u0026amp;\u0026amp; ls - docker stop shws-kf || true - docker rm -f shws-kf || true - docker rmi registry.******.com:5000/cdjd/shws-kf || true - docker build -t registry.******.com:5000/cdjd/shws-kf ./jd-ci/shws/kf/ - docker push registry.******.com:5000/cdjd/shws-kf - rm -rf jd-ci/shws/kf  这个配置文件中，only部分代表你的分支，script部分代表对应的脚本。其他业务系统需要替换的东西（比如构建镜像的名字，缓存的名称，这些可以自定义）。\n结束 以上就是gitlab runner + docker实现自动构建打包镜像并上传的简单教程。\n","id":29,"section":"posts","summary":"\u003cp\u003e最开始的时候，我尝试\u003ccode\u003eJenkins\u003c/code\u003e+\u003ccode\u003edocker\u003c/code\u003e，可是\u003ccode\u003eJenkins\u003c/code\u003e的\u003ccode\u003edocker\u003c/code\u003e依赖和插件，实在太过麻烦，配置项等等，太重。所以我转为使用\u003ccode\u003egitlab runner\u003c/code\u003e来实现自动构建并打包镜像。\u003c/p\u003e","tags":["docker","gitlab-CI"],"title":"gitlab runner + docker 自动构建","uri":"https://gggggravel.com/post/gitlabrunner-docker%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%89%93%E5%8C%85%E9%95%9C%E5%83%8Fpush%E5%88%B0%E5%85%AC%E5%8F%B8%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/","year":"2018"},{"content":"使用minikube单机部署 minikube是一个用go语言开发的可以在本地运行kubernetes的利器。首先，我们需要安装它：\ncurl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \u0026amp;\u0026amp; chmod +x minikube \u0026amp;\u0026amp; sudo cp minikube /usr/local/bin/ \u0026amp;\u0026amp; rm minikube  然后检查一下\nminikube version  如果失败，则重复上一步 然后启动minikube：\nminikube start  安装Virtualbox 如果你的机子没有安装virtualBox，会报错。Error starting host: Error creating. Error with pre-create check: \u0026quot;VBoxManage not found. Make sure VirtualBox is installed and VBoxManage is in the path\u0026quot; 我的机子是centos:\ncd /etc/yum.repos.d wget http://download.virtualbox.org/virtualbox/rpm/rhel/virtualbox.repo ## 更新缓存 yum clean all yum makecache ## 安装virtualbox yum install VirtualBox-5.1  安装完成之后，再次启动； 如果出现这种错误\nminikube start Starting local Kubernetes cluster... E0727 06:41:54.512097 3933 start.go:78] Error starting host: Error creating. Error with pre-create check: \u0026quot;We support Virtualbox starting with version 5. Your VirtualBox install is \\\u0026quot;WARNING: The vboxdrv kernel module is not loaded. Either there is no module\\\\n available for the current kernel (3.10.0-327.22.2.el7.x86_64) or it failed to\\\\n load. Please recompile the kernel module and install it by\\\\n\\\\n sudo /sbin/vboxconfig\\\\n\\\\n You will not be able to start VMs until this problem is fixed.\\\\n5.1.2r108956\\\u0026quot;. Please upgrade at https://www.virtualbox.org\u0026quot;  执行一下脚本，启动Virtualbox的Service\n/usr/lib/virtualbox/vboxdrv.sh setup  启动\n","id":30,"section":"posts","summary":"\u003ch3 id=\"使用minikube单机部署\"\u003e使用minikube单机部署\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/kubernetes/minikube\"\u003eminikube\u003c/a\u003e是一个用go语言开发的可以在本地运行kubernetes的利器。首先，我们需要安装它：\u003c/p\u003e","tags":["docker","k8s"],"title":"k8s集群搭建","uri":"https://gggggravel.com/post/k8s%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","year":"2018"},{"content":"今天在公司将自己的镜像上传到公司仓库的时候，出现了错误：\nGet https://xxx.xxxxxx.xxxx:5000/v2/ http: server gave HTTP response to HTTPS client  问题原因 出现这问题的原因是：Docker自从1.3.X之后docker registry交互默认使用的是HTTPS，但是搭建私有镜像默认使用的是HTTP服务，所以与私有镜像交时出现以上错误。\n解决方法 因为公司电脑是用的windows，所以打开settings\u0026gt;Daemon，将Advanced现象打开，在下方的json格式的文件里，将你的私服地址，填写在insecure-registries对应的地方。\n \u0026quot;insecure-registries\u0026quot;: [ \u0026quot;xxx.xxxxxx.xxxx:5000\u0026quot; ],  结束 不得不说，windows下面玩Docker，坑还是有点多的\n","id":31,"section":"posts","summary":"\u003cp\u003e今天在公司将自己的镜像上传到公司仓库的时候，出现了错误：\u003c/p\u003e","tags":["docker","问题笔记"],"title":"Docker上传镜像到私服出错","uri":"https://gggggravel.com/post/docker%E5%87%BA%E9%94%99/","year":"2018"},{"content":"今天用ali maven重新导入的spring-cloud-starter-openfeign\n我用的aliyuMaven仓库，发现spring-cloud-starter-openfeign与spring官方仓库的pom配置不一样。 下面是ali 重新切回官方镜像仓库之后，这个问题得到解决。\n","id":32,"section":"posts","summary":"\u003cp\u003e今天用ali maven重新导入的spring-cloud-starter-openfeign\u003c/p\u003e","tags":["java","springcloud"],"title":"引入spring-cloud-starter-openfeign后有些类找不到","uri":"https://gggggravel.com/post/springcloud-%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98/","year":"2018"},{"content":"在做一个上传组件的时候，需要把前端传过来的 Base64 的字符串转为 CommonsMultipartFile，然后解析保存。\n这里我直接使用的 apache 的 Base64 类进行转码：\n public static byte[] base64ToData(String base64) { return Base64.decodeBase64(base64.substring(\u0026quot;data:image/png;base64,\u0026quot;.length())); }  这里需要注意的是，解码之前需要将 data 的格式说明截去。\n然后将 Byte 数组转为 InputStream：\nInputStream in = new ByteArrayInputStream(is);  然后将 InputStream 的数据，复制到临时的 temp 文件。\nFile temp = new File(.....); FileUtils.copyInputStreamToFile(in, temp);  生成 FileItem ：FileItem fileitem = createFileItem(file.getName());\n private FileItem createFileItem(String filePath) { FileItemFactory factory = new DiskFileItemFactory(16, null); FileItem item = factory.createItem(\u0026quot;file\u0026quot;, \u0026quot;image/png\u0026quot;, true, filePath); File newfile = new File(filePath); int bytesRead = 0; byte[] buffer = new byte[8192]; try ( FileInputStream fis = new FileInputStream(newfile); OutputStream os = item.getOutputStream();){ while ((bytesRead = fis.read(buffer, 0, 8192)) != -1) { os.write(buffer, 0, bytesRead); } } catch (IOException e) { e.printStackTrace(); } return item; }  CommonsMultipartFile 的构造函数可以直接通过 FileItem 生成 CommonsMultipartFile：\n CommonsMultipartFile multipartFile = new CommonsMultipartFile(fileitem);  这样，就可以了。\n","id":33,"section":"posts","summary":"\u003cp\u003e在做一个上传组件的时候，需要把前端传过来的 \u003ccode\u003eBase64\u003c/code\u003e 的字符串转为 \u003ccode\u003eCommonsMultipartFile\u003c/code\u003e，然后解析保存。\u003c/p\u003e","tags":["java","Base64"],"title":"Base64转CommonsMultipartFile","uri":"https://gggggravel.com/post/base64/","year":"2018"},{"content":"Redis是什么 Redis是由意大利人[Salvatore Sanfilippo][1]（网名：antirez）开发的一款内存高速缓存数据库。Redis全称为：Remote Dictionary Server（远程数据服务），该软件使用C语言编写，Redis是一个key-value存储系统，它支持丰富的数据类型，如：string、list、set、zset(sorted set)、hash。\nRedis数据结构 redis是一种高级的key:value存储系统，其中value支持五种数据类型：\n1.字符串（string） 2.列表（list） 3.集合（set） 4.有序集合（sorted set） 5.哈希（hashes）\nString String是Redis值的最基础的类型。Redis中使用的字符串是通过包装的，基于c语言字符数组实现的简单动态字符串(simple dynamic string, SDS)一个抽象数据结构。在大多数情况下，redis不能对string类型有什么进一步的操作。其基本操作命令有set、get、strlen、getrange、append：\nSET key value GET key STRLEN key GETRANGE key start end APPEND key value  在大多数情况之外，就是string中存储的为纯数字的情况，redis可以将字符串当做数字进行进一步操作，这些操作包括decr、decrby、incr、incrby和incrbyfloat。\nList Redis的List类型其实就是每一个元素都是String类型的双向链表。使用list时,可以像对待栈一样使用pop和push操作，但是这个栈两端都能进行操作；也可以像对待数组一样使用一个index参数来操作。list的操作命令略杂，主要分为两类：L开头的和R开头的，L代表LEFT或者LIST，进行一些从列表左端进行的操作，或者一些与端无关的操作；R代表RIGHT，进行一些从列表右端进行的操作。常用命令有：\n  lpush——在key对应的list的头部添加一个元素。\n  lrange——获取key对应的list的指定下标范围的元素，-1表示获取所有元素。\n  lpop——从key对应的list的尾部删除一个元素，并返回该元素。\n  rpush——在key对应的list的尾部添加一个元素。\n  rpop——从key对应的list的尾部删除一个元素，并返回该元素。\n  Set set用于存储一组不重复的值，类似List的一个列表，与List不同的是Set不能有重复的数据。基本操作有sadd和sismember：\nSADD key member [member ...] SISMEMBER key member  关于集合的操作有这些：\nSINTER key [key ...] --取交集 SUNION key [key ...] --取并集 SDIFF key [key ...] --求差  sorted set SortSet顾名思义，是一个排好序的Set，它在Set的基础上增加了一个顺序属性score，这个属性在添加修改元素时可以指定，每次指定后，SortSet会自动重新按新的值排序。基本操作有zadd、zcount、zrank：\nZADD key score member [score member ...] ZCOUNT key min max ZRANK key member  hash 最后要给大家介绍的是hashes，即哈希。哈希是从redis-2.0.0版本之后才有的数据结构。Hash是一个String类型的field和value之间的映射表，即redis的Hash数据类型的key（hash表名称）对应的value实际的内部存储结构为一个HashMap，因此Hash特别适合存储对象。相对于把一个对象的每个属性存储为String类型，将整个对象存储在Hash类型中会占用更少内存。常用命令有：\n  hset——设置key对应的HashMap中的field的value\n  hget——获取key对应的HashMap中的field的value\n  hgetall\u0026ndash;获取key对应的hashMap中的所有属性\n  redis持久化 redis提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。\nRDB 简而言之，就是在不同的时间点，将redis存储的数据生成快照并存储到磁盘等介质上；RDB，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。\nredis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。\n对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。\n如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。\n缺点 如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。\nAOF 则是换了一个角度来实现持久化，那就是将redis执行过的所有写指令记录下来，在下次redis重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。\n其实RDB和AOF两种方式也可以同时使用，在这种情况下，如果redis重启的话，则会优先采用AOF方式来进行数据恢复，这是因为AOF方式的数据恢复完整度更高。\n如果你没有数据持久化的需求，也完全可以关闭RDB和AOF方式，这样的话，redis将变成一个纯内存数据库，就像memcache一样。 我们通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。\n默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。 因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。\n缺点 在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。\n应用场景 排行榜应用，取TOP N操作 比如微信的跳一跳，根据得分你通常想要得到：\n 列出前50名高分选手   列出某用户当前的全国排名  这些操作对于Redis来说应该很简单，在每次用户产生新的分数时：\nZADD topScore \u0026lt;score\u0026gt; \u0026lt;username\u0026gt;  得到前50名高分用户：\nZREVRANGE topScore 0 49  用户的全球排名也相似，只需要：\nZRANK topScore \u0026lt;username\u0026gt;  简单实例展示 打开你的idea\n","id":34,"section":"posts","summary":"\u003ch2 id=\"redis是什么\"\u003eRedis是什么\u003c/h2\u003e\n\u003cp\u003eRedis是由意大利人[Salvatore Sanfilippo][1]（网名：antirez）开发的一款内存高速缓存数据库。Redis全称为：Remote Dictionary Server（远程数据服务），该软件使用C语言编写，Redis是一个key-value存储系统，它支持丰富的数据类型，如：string、list、set、zset(sorted set)、hash。\u003c/p\u003e","tags":["redis"],"title":"Redis简单讲解","uri":"https://gggggravel.com/post/redis%E7%AE%80%E5%8D%95%E8%AE%B2%E8%A7%A3/","year":"2018"},{"content":"@Conditional 注解是 Spring 4 提供的基于条件的 Bean 的创建方式，Spring Boot 大量利用了这个特定来实现自动配置。比如，当某一个 jar 包在一个类路径下时，自动配置一个或者多个 Bean；或者只有一个 Bean 创建时，才会创建另一个 Bean。总的来说，就是根据特定条件来控制 Bean 的创建行为，这样就可以利用这个特性进行一些自动配置。\n自定义 Condition 实例 下面的示例将以不同的操作系统作为条件，通过实现 Condition 接口，并重写其 matches 方法来构造判断条件，获取在不同操作系统下的操作命令。如在 Windows 系统下运行程序调用获取文件列表命名的方法则输出 dir，如果在 Linux 下则输出 ls。\n通过实现 Spring 提供的 Condition 接口创建两个 Condition 类 自定义 Condition 需要实现 org.springframework.context.annotation.Condition 接口中的 boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) 方法，我们的条件判断逻辑则应该放在此方法中。\npublic class WindowsCondition implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { System.out.println(\u0026quot;os.name:\u0026quot; + context.getEnvironment().getProperty(\u0026quot;os.name\u0026quot;)); return context.getEnvironment().getProperty(\u0026quot;os.name\u0026quot;).contains(\u0026quot;Windows\u0026quot;); } } public class LinuxCondition implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { System.out.println(\u0026quot;os.name:\u0026quot; + context.getEnvironment().getProperty(\u0026quot;os.name\u0026quot;)); return context.getEnvironment().getProperty(\u0026quot;os.name\u0026quot;).contains(\u0026quot;Linux\u0026quot;); } }  创建获取命令的接口并分别创建 Linux 和 Windows 下的实现 public interface CmdService { String getListCmd();\t} public class WindowsCmdServiceImpl implements CmdService { @Override public String getListCmd() { return \u0026quot;dir\u0026quot;; } } public class LinuxCmdServiceImpl implements CmdService { @Override public String getListCmd() { return \u0026quot;ls\u0026quot;; } }  创建配置类并使用 @Conditional 注解将 Bean 定义为条件创建 @Configuration public class SpringConditionalConf { @Bean @Conditional(WindowsCondition.class) //WindowsCondition 条件成立时创建此 Bean public CmdService windowsCmdService(){ return new WindowsCmdServiceImpl(); } @Bean @Conditional(LinuxCondition.class) //LinuxCondition 条件成立时创建此 Bean public CmdService linuxCmdService(){ return new LinuxCmdServiceImpl(); } }  测试类 @RunWith(SpringRunner.class) @SpringBootTest(classes = HelloSpringBoot.class) public class SpringConditionalDemoTest { @Autowired private CmdService cmdService; @Test public void testConditional(){ System.out.println(cmdService.getListCmd()); } }  在 windows 主机上运行测试得到输出 dir，说明只有 WindowsCmdServiceImpl 实例被创建并且得到了正确的指令。\n@Conditional 常见使用方法 在上例中 @Conditional 注解标注到 @Bean 的方法上；除此之外还可以作为类级别的注解放在注标识有@Component（包含@Configuration）的类上，这时所有标识了 @Bean 的方法和 @Import 注解导入的相关类将遵从这些条件；最后还可以作为一个 meta-annotation，组成自定义注解。\nSpring 内置 Conditional 除了类似上例的自定义 Condition 之外，Spring 还内置了一些 Condition 给我们使用：\n @ConditionalOnBean 仅仅在当前上下文中存在某个对象时，才会实例化一个 Bean @ConditionalOnClass 某个 class 位于类路径上，才会实例化一个 Bean @ConditionalOnExpression 当表达式为 true 的时候，才会实例化一个 Bean @ConditionalOnMissingBean 仅仅在当前上下文中不存在某个对象时，才会实例化一个 Bean @ConditionalOnMissingClass 某个 class 类路径上不存在的时候，才会实例化一个 Bean @ConditionalOnNotWebApplication 不是 web 应用时才会实例化一个 Bean  @Conditional 与 @Profile  区别 Spring 3.1 推出的 @Profiles 注解功能与 @Conditional 注解类似，都是提供一种 “If-Then-Else” 能力，即条件配置功能。但是更早出现的 @Profiles 主要是用来根据不同的运行环境加载不同的应用配置；@Conditional 注解是一种更高层次的实现，他没有 @Profile 注解的一些限制，是 @profile 的一种更加通用的版本，其主要被用作 Bean 的条件加载。\n@Profile 注解使用举例\n@Profile(\u0026quot;Development\u0026quot;) @Configuration public class DevDatabaseConfig implements DatabaseConfig { @Override @Bean public DataSource createDataSource() { System.out.println(\u0026quot;Creating DEV database\u0026quot;); DriverManagerDataSource dataSource = new DriverManagerDataSource(); /* * Set MySQL specific properties for Development Environment */ return dataSource; } } @Profile(\u0026quot;Production\u0026quot;) @Configuration public class ProductionDatabaseConfig implements DatabaseConfig { @Override @Bean public DataSource createDataSource() { System.out.println(\u0026quot;Creating Production database\u0026quot;); DriverManagerDataSource dataSource = new DriverManagerDataSource(); /* * Set ORACLE specific properties for Production environment */ return dataSource; } }  以上两个配置类都实现了 DatabaseConfig 接口，特殊的地方在于它们都用 @Profile 标注，被 @Profile 标注的组件只有当指定 profile 值匹配时才生效。可以通过以下方式设置 profile 值：\n 设置 spring.profiles.active 属性（通过 JVM 参数、环境变量或者 web.xml 中的 Servlet context 参数） ApplicationContext.getEnvironment().setActiveProfiles(“ProfileName”)  在 Spring 3.x 里 @Profiles 注解只能用在类级别，但是在 Spring 4.0 以后则既可以用在类级别也可以用在方法级别，主要是因为在 4.0 中 Spring 使用 @Conditional 对其做了重构：\n@Retention(RetentionPolicy.RUNTIME) @Target({ElementType.TYPE, ElementType.METHOD}) @Documented @Conditional(ProfileCondition.class) // 使用 @Conditional 实现 @Profile public @interface Profile { String[] value(); }  @Conditional 注解使用场景 我们知道在 Spring Boot 中大量使用了 @Conditional 注解，我们在平时的开发中如果遇到以下一些场景则可以考虑使用该注解:\n Condition whether a property is available or not using Environment variables, irrespective of its value. Like Profiles, Condition whether a property value is available or not using Environment variables. Conditions based on a Bean definition are present in Spring Application context. Conditions based on a Bean object are present in Spring Application context. Conditions based on some or all Bean properties values. Conditions based on some Resources are present in current Spring Application Context or not. Conditions based on Bean’s Annotations Conditions Bean’s Method’s Annotations. Conditions based on Bean’s Annotation’s parameter values Conditions based on Bean’s Method’s Annotation’s parameter values.  参考  Spring @Conditional Annotation Spring4.0系列5-@Conditional  ","id":35,"section":"posts","summary":"@Conditional 注解是 Spring 4 提供的基于条件的 Bean 的创建方式，Spring Boot 大量利用了这个特定来实现自动配置。比如，当某一个 jar 包在一个类路径下时，自动配置一个或","tags":["java","spring"],"title":"spring-conditional","uri":"https://gggggravel.com/post/spring-conditional/","year":"2018"},{"content":"抽象类和接口的比较 相同点：\n都不能被实例化 都包含抽象方法，这些抽象方法用于描述系统能提供哪些服务，而这些服务是由子类来提供实现的\n在系统设计上，两者都代表系统的抽象层，当一个系统使用一棵继承树上的类时，应该尽量把引用变量声明为继承树的上层抽象类型，这样可以提高两个系统之间的松耦合 不同点：\n在抽象类中可以为部分方法提供默认的实现，从而避免在子类中重复实现它们；但是抽象类不支持多继承。接口不能提供任何方法的实现，但是支持多继承。\n接口代表了接口定义者和接口实现者的一种契约；而抽象类和具体类一般而言是一种继承的关系，即两者在概念本质上是不同。\n内部类 1.内部类可以很好的实现隐藏，一般的非内部类，是不允许有 private 与protected权限的，但内部类可以\n2.内部类拥有外围类的所有元素的访问权限\n3.可实现多重继承\n静态内部类 静态内部类，定义在类中，任何方法外，用static定义；静态内部类只能访问外部类的静态成员。 生成（new）一个静态内部类不需要外部类成员：这是静态内部类和成员内部类的区别。静态内部类的对象可以直接生成：Outer.Inner in=new Outer.Inner()；而不需要通过生成外部类对象来生成。这样实际上使静态内部类成为了一个顶级类。可以定义私有静态内部类。\n静态内部类与非静态的内部类区别 是否可以创建静态的成员方法与成员变量(静态内部类可以创建静态的成员而非静态的内部类不可以)、对于访问外部类的成员的限制(静态内部类只可以访问外部类中的静态成员变量与成员方法而非静态的内部类即可以访问静态的也可以访问非静态的外部类成员方法与成员变量)。这两个差异是静态内部类与非静态外部类最大的差异，也是静态内部类之所以存在的原因\n子类为什么不能重写父类的静态方法 重写\u0026quot;只能适用于实例方法.不能用于静态方法.对于静态方法,只能隐藏（形式上被重写了，但是不符合的多态的特性），“重写”是用来实现多态性的，只有实例方法是可以实现多态，而静态方法无法实现多态\n自动装箱(autoboxing)与拆箱(unboxing) 自动装箱是 Java 编译器在基本数据类型和对应的对象包装类型之间做的一个转化。 比如：把 int 转化成 Integer，double 转化成 Double等,反之就是自动拆箱。 Integer a=1;//这就是一个自动装箱，如果没有自动装箱的话，需要这样Integer a=new Integer(1)\nint b=a;//这就是一个自动拆箱，如果没有自动拆箱的话，需要这样：int b=a.intValue()\n这样就能看出自动装箱和自动拆箱是简化了基本数据类型和相对应对象的转化步骤\nJava中的自动装箱与拆箱\nJava 异常的体系结构 Java把异常当作对象来处理，并定义一个基类java.lang.Throwable作为所有异常的超类。\n在Java API中已经定义了许多异常类，这些异常类分为两大类，错误Error和异常Exception。\nError：Error类对象由 Java 虚拟机生成并抛出，Error表示编译时和系统错误，通常不能预期和恢复，比如硬件故障、JVM崩溃、内存不足等 。例如，Java虚拟机运行错误（Virtual MachineError），当JVM不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止；还有发生在虚拟机试图执行应用时，如类定义错误（NoClassDefFoundError）、链接错误（LinkageError）。这些错误是不可查的，因为它们在应用程序的控制和处理能力之 外，而且绝大多数是程序运行时不允许出现的状况。对于设计合理的应用程序来说，即使确实发生了错误，本质上也不应该试图去处理它所引起的异常状况。在Java中，错误通常是使用Error的子类描述。\nException：在Exception分支中有一个重要的子类RuntimeException（运行时异常），该类型的异常自动为你所编写的程序定义ArrayIndexOutOfBoundsException（数组下标越界）、NullPointerException（空指针异常）、ArithmeticException（算术异常）、MissingResourceException（丢失资源）、ClassNotFoundException（找不到类）等异常，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生；而RuntimeException之外的异常我们统称为非运行时异常，类型上属于Exception类及其子类，从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。\nthrow和throws区别 throw：（针对对象的做法） 抛出一个异常，可以是系统定义的，也可以是自己定义的\npublic void yichang(){ NumberFormatException e = new NumberFormatException(); throw e; }  throws：（针对一个方法抛出的异常） 抛出一个异常，可以是系统定义的，也可以是自己定义的。\npublic void yichang() throws NumberFormatException{ int a = Integer.parseInt(\u0026quot;10L\u0026quot;); }   throws出现在方法函数头；而throw出现在函数体。 throws表示出现异常的一种可能性，并不一定会发生这些异常；throw则是抛出了异常，执行throw则一定抛出了某种异常。 两者都是消极处理异常的方式（这里的消极并不是说这种方式不好），只是抛出或者可能抛出异常，但是不会由函数去处理异常，真正的处理异常由函数的上层调用处理。  Java中为什么要为基本类型提供封装类呢？ 一是为了在各种类型间转化，通过各种方法的调用。否则你无法直接通过变量转化。\n比如，现在int要转为String int a=0; String result=Integer.toString(a); 二是比如我现在要用泛型\nListnums;\n这里\u0026lt;\u0026gt;需要类。如果你用int。它会报错的\nJava 创建对象的几种方式 (1) 用 new 语句创建对象，这是最常见的创建对象的方法\n(2) 运用反射手段,调用 java.lang.Class 或者 java.lang.reflect.Constructor 类的 newInstance() 实例方法\n(3) 调用对象的 clone() 方法\n(4) 运用反序列化手段，调用 java.io.ObjectInputStream 对象的 readObject() 方法\n(1)和(2)都会明确的显式的调用构造函数；(3)是在内存上对已有对象的影印，所以不会调用构造函数 (4)是从文件中还原类的对象，也不会调用构造函数。\n序列化(Serializable )与反序列化(Deserialize) 对象序列化(Serializable)是指将对象转换为字节序列的过程，而反序列化则是根据字节序列恢复对象的过程。 序列化一般用于以下场景：\n1.永久性保存对象，保存对象的字节序列到本地文件中；\n2.通过序列化对象在网络中传递对象； 3.通过序列化在进程间传递对象。\n只有实现了Serializable和Externalizable接口的类的对象才能被序列化，\njava.io.ObjectOutputStream代表对象输出流，它的writeObject(Objectobj)方法可对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中。 java.io.ObjectInputStream代表对象输入流，它的readObject()方法从一个源输入流中读取字节序列，再把它们反序列化为一个对象，并将其返回。\n覆盖 (Override) 和重载 (Overload) Java 中的方法重载发生在同一个类里面两个或者是多个方法的方法名相同但是参数不同的情况；\n方法覆盖是说子类重新定义了父类的方法，方法覆盖必须有相同的方法名，参数列表和返回类型。\n内存中的栈（stack）、堆(heap)和静态存储区的用法 通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用内存中的栈空间；而通过new关键字和构造器创建的对象放在堆空间；程序中的字面量（literal）如直接书写的100、“hello”和常量都是放在静态存储区中。栈空间操作最快但是也很小，通常大量的对象都是放在堆空间，整个内存包括硬盘上的虚拟内存都可以被当成堆空间来使用。\nString str = new String(“hello”);  上面的语句中 str 放在栈上，用 new 创建出来的字符串对象放在堆上，而“hello”这个字面量放在静态存储区。\nJava垃圾回收机制 在C++中，对象所占的内存在程序结束运行之前一直被占用，在明确释放之前不能分配给其它对象；而在Java中，当没有对象引用指向原先分配给某个对象的内存时，该内存便成为垃圾。JVM的一个系统级线程会自动释放该内存块。垃圾收集意味着程序不再需要的对象是\u0026quot;无用信息\u0026quot;，这些信息将被丢弃。当一个对象不再被引用的时候，内存回收它占领的空间，以便空间被后来的新对象使用。事实上，除了释放没用的对象，垃圾收集也可以清除内存记录碎片。由于创建对象和垃圾收集器释放丢弃对象所占的内存空间，内存会出现碎片。碎片是分配给对象的内存块之间的空闲内存洞。碎片整理将所占用的堆内存移到堆的一端，JVM将整理出的内存分配给新的对象。\n垃圾收集能自动释放内存空间，减轻编程的负担。这使Java虚拟机具有一些优点。首先，它能使编程效率提高。在没有垃圾收集机制的时候，可能要花许多时间来解决一个难懂的存储器问题。在用Java语言编程的时候，靠垃圾收集机制可大大缩短时间。其次是它保护程序的完整性， 垃圾收集是Java语言安全性策略的一个重要部份。垃圾收集的一个潜在的缺点是它的开销影响程序性能。Java虚拟机必须追踪运行程序中有用的对象，而且最终释放没用的对象。这一个过程需要花费处理器的时间。其次垃圾收集算法的不完备性，早先采用的某些垃圾收集算法就不能保证100%收集到所有的废弃内存。当然随着垃圾收集算法的不断改进以及软硬件运行效率的不断提升，这些问题都可以迎刃而解。\n一般来说，Java开发人员可以不重视JVM中堆内存的分配和垃圾处理收集，但是，充分理解Java的这一特性可以让我们更有效地利用资源。同时要注意finalize()方法是Java的缺省机制，有时为确保对象资源的明确释放，可以编写自己的finalize方法。(引用自百度)\nJava 垃圾收集机制\nList,Map,Set 由Collection接口派生的两个接口是List和Set； Vector非常类似ArrayList，但是Vector是同步的；\nStack继承自Vector，实现一个后进先出的堆栈，push和pop，还有peek方法得到栈顶的元素\nSet是一种不包含重复的元素的Collection\nMap没有继承Collection接口，Map提供key到value的映射，一个Map中不能包含相同的key，每个key只能映射一个 value 集合大家族\n集合类之Vector和ArrayList 1，vector是线程同步的，所以它也是线程安全的，而arraylist是线程异步的，是不安全的。如果不考虑到线程的安全因素，一般用arraylist效率比较高。\n2，如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%,而arraylist增长率为目前数组长度的50%.如过在集合中使用数据量比较大的数据，用vector有一定的优势。\n3，如果查找一个指定位置的数据，vector和arraylist使用的时间是相同的，都是0(1),这个时候使用vector和arraylist都可以\n集合类之Hashtable 添加数据使用put(key, value)，取出数据使用get(key)，这两个基本操作的时间开销为常数。\nHashtable通过initial capacity和load factor两个参数调整性能。通常缺省的load factor 0.75较好地实现了时间和空间的均衡。增大load factor可以节省空间但相应的查找时间将增大，这会影响像get和put这样的操作。\n集合类之HashMap和Hashtable HashMap Hashtable区别HashMap是Hashtable的轻量级实现（非线程安全的实现），效率上可能高于Hashtable。他们都完成了Map接口。HashMap允许null值作为key和value，而Hashtable不可以。\n最大的不同是，Hashtable的方法是Synchronize的，而HashMap不是，在多个线程访问Hashtable时，不需要自己为它的方法实现同步，而HashMap 就必须为之提供外同步(Collections.synchronizedMap)。\n迭代HashMap采用快速失败机制（不是迭代完成后才告诉你出错了），而Hashtable不是。迭代器的快速失败机制会抛出一个并发修改异常 （ConcurrentModificationException） ，应该仅用于检测程序错误。\nHashMap之快速失败机制 我们知道java.util.HashMap不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了map，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。这一策略在源码中的实现是通过modCount域，modCount顾名思义就是修改次数，对HashMap内容的修改都将增加这个值，那么在迭代器初始化过程中会将这个值赋给迭代器的expectedModCount。在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map。modCount声明为volatile，保证线程之间修改的可见性。\nhashcode的作用 Java中的hashCode方法就是根据一定的规则将与对象相关的信息（比如对象的存储地址，对象的字段等）映射成一个数值，这个数值称作为散列值。 如果集合中已经存在一万条数据或者更多的数据，如果采用equals方法去逐一比较，效率必然是一个问题。此时hashCode方法的作用就体现出来了，当集合要添加新的对象时，先调用这个对象的hashCode方法，得到对应的hashcode值，实际上在HashMap的具体实现中会用一个table保存已经存进去的对象的hashcode值，如果table中没有该hashcode值，它就可以直接存进去，不用再进行任何比较了；如果存在该hashcode值，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址，所以这里存在一个冲突解决的问题，这样一来实际调用equals方法的次数就大大降低了。\nhashcode方法的作用\nHashCode和equal方法 1、hashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的；\n2、如果两个对象相同，就是适用于equals(java.lang.Object) 方法，那么这两个对象的hashCode一定要相同；\n3、如果对象的equals方法被重写，那么对象的hashCode也尽量重写，并且产生hashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点；\n4、两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object)方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里”。\nHashCode和equal方法\n什么是值传递和引用传递 值传递\npublic class TempTest { private void test1(int a) { a = 5; System.out.println(\u0026quot;test1方法中的a=\u0026quot; + a); } public static void main(String[] args) { TempTest t = new TempTest(); int a = 3; t.test1(11); System.out.println(\u0026quot;main方法中a=\u0026quot; + a); } }  test1方法中的a=5 main方法中a=3 值传递：传递的是值的拷贝，传递后就互不相关了 引用传递：传递的是变量所对应的内存空间的地址\npublic class TempTest { private void test1(A a) { a.age = 20; System.out.println(\u0026quot;test1方法中a=\u0026quot; + a.age); } public static void main(String[] args) { TempTest t = new TempTest(); A a = new A(); a.age = 10; t.test1(a); System.out.println(\u0026quot;main方法中a=\u0026quot; + a.age); } } class A { public int age = 0; }  test1方法中a=20 main方法中a=20 传递前和传递后都指向同一个引用（同一个内存空间） 如果不互相影响，方法是在test1方法里面新new一个实例就可以了\n用户线程(User Thread)与守护线程(Daemon Thread) 守护线程，是指用户程序在运行的时候后台提供的一种通用服务的线程。只要当前JVM实例中尚存在任何一个用户线程没有结束，守护线程就全部工作；只有当最后一个用户线程结束时，守护线程随着 JVM 一同结束工作。 守护线程最典型的应用就是 GC (垃圾回收器)。 JAVA并发编程——守护线程(Daemon Thread)\n进程和线程的区别 一个进程对应一个程序的执行，而一个线程则是进程执行过程中的一个单独的执行序列，一个进程可以包含多个线程。线程有时候也被称为轻量级进程。 一个Java虚拟机的实例运行在一个单独的进程中，不同的线程共享Java虚拟机进程所属的堆内存。这也是为什么不同的线程可以访问同一个对象。线程彼此共享堆内存并保有他们自己独自的栈空间。这也是为什么当一个线程调用一个方法时，他的局部变量可以保证线程安全。但堆内存并不是线程安全的，必须通过显示的声明同步来确保线程安全。\n如何在Java中实现线程？ 　在语言层面有两种方式。java.lang.Thread 类的实例就是一个线程但是它需要调用java.lang.Runnable接口来执行，由于线程类本身就是调用的Runnable接口所以你可以继承java.lang.Thread 类或者直接调用Runnable接口来重写run()方法实现线程。\nThread 类中的start() 和 run() 方法有什么区别？ 　start()方法被用来启动新创建的线程，而且start()内部调用了run()方法，这和直接调用run()方法的效果不一样。当你调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动，start()方法才会启动新线程。更多讨论请点击这里\nJava中Runnable和Callable有什么不同？ 　Runnable和Callable都代表那些要在不同的线程中执行的任务。Runnable从JDK1.0开始就有了，Callable是在JDK1.5增加的。它们的主要区别是Callable的 call() 方法可以返回值和抛出异常，而Runnable的run()方法没有这些功能。Callable可以返回装载有计算结果的Future对象。\n","id":36,"section":"posts","summary":"\u003ch3 id=\"抽象类和接口的比较\"\u003e抽象类和接口的比较\u003c/h3\u003e\n\u003cp\u003e相同点：\u003cbr\u003e\n都不能被实例化 \u003cbr\u003e\n都包含抽象方法，这些抽象方法用于描述系统能提供哪些服务，而这些服务是由子类来提供实现的\u003cbr\u003e\n在系统设计上，两者都代表系统的抽象层，当一个系统使用一棵继承树上的类时，应该尽量把引用变量声明为继承树的上层抽象类型，这样可以提高两个系统之间的松耦合 \u003cbr\u003e\n不同点：\u003c/p\u003e\n\u003cp\u003e在抽象类中可以为部分方法提供默认的实现，从而避免在子类中重复实现它们；但是抽象类不支持多继承。接口不能提供任何方法的实现，但是支持多继承。\u003cbr\u003e\n接口代表了接口定义者和接口实现者的一种契约；而抽象类和具体类一般而言是一种继承的关系，即两者在概念本质上是不同。\u003c/p\u003e","tags":["java"],"title":"java基础以及进阶知识点总结","uri":"https://gggggravel.com/post/java%E5%9F%BA%E7%A1%80%E4%BB%A5%E5%8F%8A%E8%BF%9B%E9%98%B6%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/","year":"2018"},{"content":"在《设计模式》这本书里，GoF定义了23种设计模式，个人能力有限，在实际使用或者业余编码过程中，并没有完全接触完全。这里我罗列一下在java中几种常用的设计模式。\nGoF将设计模式分为了三大类：\n 创建型模式 结构型模式 行为型模式  创建型模式 创建型模式就是创建对象的模式，抽象了实例化的过程。它帮助一个系统独立于如何创建、组合和表示它的那些对象。关注的是对象的创建，创建型模式将创建对象的过程进行了抽象，也可以理解为将创建对象的过程进行了封装，作为客户程序仅仅需要去使用对象，而不再关心创建对象过程中的逻辑。 常用的创建型模式有以下几种：\n 工厂模式 单例模式 建造者模式  工厂模式 定义一个用于创建对象的接口，让子类决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。 Product为抽象产品类负责定义产品的共性，实现对事物最抽象的定义； Creator为抽象创建类，也就是抽象工厂，具体如何创建产品类是由具体的实现工厂ConcreteCreator完成的。 java代码实现如下：\npublic class ConcreteCreator extends Creator { public \u0026lt;T extends Product\u0026gt; T createProduct(Class\u0026lt;T\u0026gt; c){ Product product=null; try { product = (Product)Class.forName(c.getName()).newInstance(); } catch (Exception e) { //异常处理 } return (T)product; } }  可以用以下的方法实例化各种产品：\nConcreteCreator factory = new ConcreteCreator(); ProductA productA =factory.createProduct(ProductA.class); ProductB productB =factory.createProduct(ProductB.class);  单例模式 确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。\n/** * @author gravel * 中国的历史上一般都是一个朝代一个皇帝 * @date 2018-07-15 */ public class Emperor { private static final Emperor emperor =new Emperor(); //初始化一个皇帝 private Emperor(){ //这里限制只产生一个皇帝 //世俗和道德约束你，目的就是不希望产生第二个皇帝 } public static Emperor getInstance(){ return emperor; } //皇帝发话了 public static void say(){ System.out.println(\u0026quot;我就是皇帝某某某....\u0026quot;);\t} }  单例模式主要分两种，一种是类加载时实例，一种是使用时实例。 另外在实际场景中Spring中创建的Bean实例默认都是单例模式存在的。\n建造者模式 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 在建造者模式中，有如下四个角色：\n Product产品类：通常是实现了模板方法模式，也就是有模板方法和基本方法。 Builder抽象建造者：规范产品的组建，一般是由子类实现。 ConcreteBuilder具体建造者：实现抽象类定义的所有方法，并且返回一个组件好的对象。 Director导演：负责安排已有模块的顺序，然后告诉Builder开始建造。  这个模式我初次接触到的时候感觉有点抽象，我看到有大佬提到java的StringBuilder也是使用的建造者模式。\nStringBuilder把构建者的角色交给了其的父类AbstractStringBuilder\npublic final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence { 。。。。。。 }  以append方法为例，最终调用的是父类的append（）：\n public StringBuilder append(String str) { super.append(str); return this; }  父类AbstractStringBuilder的实现代码：\n public AbstractStringBuilder append(String str) { if (str == null) str = \u0026quot;null\u0026quot;; int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this;//返回构建对象 }  结构型模式 在解决了对象的创建问题之后，对象的组成以及对象之间的依赖关系就成了开发人员关注的焦点，因为如何设计对象的结构、继承和依赖关系会影响到后续程序的维护性、代码的健壮性、耦合性等。对象结构的设计很容易体现出设计人员水平的高低，常用的几种结构型模式有：\n 适配器模式 代理模式 装饰模式  适配器模式 将一个类的接口变换成客户端所期待的另一种接口，从而是原本因接口不匹配而无法在一起工作的两个类能够在一起工作。\n// 原有的接口，不能完全符合客户要求，但是我们有不能改 interface IOrigin{ public void deal(); } // 定义一个符合客户要求的新接口 interface ITarget{ public void newDeal(int type); } class Target implements ITarget{ private IOrigin origin; public void newDeal(int type){ if (type==0){ //这里调用原来的接口 origin.deal(); }else{ //满足新的需求 } } } public class TestAdapter { public void test(){ // 原来是IOrigin接口但是不符合我要求，所以用ITarget适配一下 // ITarget target = new Target(); target.newDeal(1); } }  代理模式 代理模式给某一个对象提供一个代理对象，并由代理对象控制对原对象的引用。通俗的来讲代理模式就是我们生活中常见的中介。\n// 一个顾客要买房 class Customer{ public void sellHouse(){ } } class Proxy { private Customer customer; public void buyHouse(){ customer.sellHouse(); } } public class TestProxy { public void test(){ // 一个买家要买房的话直接跟中介（代理）大交道就可以了 Proxy proxy = new Proxy(); proxy.buyHouse(); } }  spring AOP也使用了动态代理的模式。\n装饰模式 动态地给一个对象添加一些额外的职责。就增加功能来说，装饰模式比生成子类更为灵活。 装饰模式在Java中最经典的应用就是I/O流，回忆一下，当我们使用流式操作读取文件内容时，怎么实现呢？示例如下：\npublic static void main(String[] args) throws IOException { DataInputStream dis = null; try { dis = new DataInputStream( new BufferedInputStream( new FileInputStream(\u0026quot;E:/IOTest.txt\u0026quot;) ) ); byte[] bs = new byte[dis.available()]; dis.read(bs); System.out.println(\u0026quot;文件内容====\u0026gt;\u0026quot;+new String(bs)); } finally{ dis.close(); } }  FileInputStream对象就相当于被装饰的对象，而BufferedInputStream对象和DataInputStream对象则相当于装饰器。\n行为型模式 行为型模式(Behavioral Pattern)是对在不同的对象之间划分责任和算法的抽象化。 行为型模式不仅仅关注类和对象的结构，而且重点关注它们之间的相互作用。 通过行为型模式，可以更加清晰地划分类与对象的职责，并研究系统在运行时实例对象 之间的交互。在系统运行时，对象并不是孤立的，它们可以通过相互通信与协作完成某些复杂功能，一个对象在运行时也将影响到其他对象的运行。 这里我就写一种：\n观察者模式 建立一种对象与对象之间的依赖关系，一个对象发生改变时将自动通知其他对象，其他对象将相应做出反应。在此，发生改变的对象称为观察目标，而被通知的对象称为观察者，一个观察目标可以对应多个观察者，而且这些观察者之间没有相互联系，可以根据需要增加和删除观察者，使得系统更易于扩展，这就是观察者模式的模式动机。\n在我们实际使用中，观察者模式应该比较多。比如消息队列之类的，比较经典的有Kafka中的订阅以及发布。\n总结 Gof定义了23种设计模式，我这里只列了自己比较熟悉的几种，剩余的几种，比如迭代器，其实已经被java融合进jdk中，我们在开发中并不需要自己写。个人感觉设计模式的概念对于一些模块的重构和解耦帮助很大。学习不止！\n","id":37,"section":"posts","summary":"\u003cp\u003e在《设计模式》这本书里，GoF定义了23种设计模式，个人能力有限，在实际使用或者业余编码过程中，并没有完全接触完全。这里我罗列一下在java中几种常用的设计模式。\u003c/p\u003e","tags":["设计模式"],"title":"常用的几种设计模式","uri":"https://gggggravel.com/post/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%87%A0%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","year":"2018"},{"content":"Spring Boot 简介 Spring Boot(英文中是引导的意思)，是用来简化Spring应用的搭建到开发的过程。应用开箱即用，只要通过 just run（可能是 java -jar 或 tomcat 或 maven插件run 或 shell脚本），就可以启动项目。二者，Spring Boot 只要很少的Spring配置文件（例如那些xml，property）。 因为习惯优先于配置的原则，使得Spring Boot在快速开发应用和微服务架构实践中得到广泛应用。 Javaer装好JDK环境和Maven工具就可以开始学习Boot了~\nHello world 首先得有个maven基础项目，可以直接使用Maven骨架工程生成Maven骨架Web项目，即man archetype:generate命令：\nmvn archetype:generate -DgroupId=springboot -DartifactId=springboot-helloworld -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false  pom.xml配置 \u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;project xmlns=\u0026quot;http://maven.apache.org/POM/4.0.0\u0026quot; xmlns:xsi=\u0026quot;http://www.w3.org/2001/XMLSchema-instance\u0026quot; xsi:schemaLocation=\u0026quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026quot;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;springboot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springboot-helloworld\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;springboot-helloworld :: HelloWorld Demo\u0026lt;/name\u0026gt; \u0026lt;!-- Spring Boot 启动父依赖 --\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.3.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- Spring Boot web依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Junit --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.12\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt;  只要加入一个 Spring Boot 启动父依赖即可。\nController层 HelloWorldController的代码如下：\n/** * Spring Boot HelloWorld案例 * * Created by liao on 2018/7/12. */ @RestController public class HelloWorldController { @RequestMapping(\u0026quot;/\u0026quot;) public String sayHello() { return \u0026quot;Hello,World!\u0026quot;; } }  @RestController和@RequestMapping注解是来自SpringMVC的注解，它们不是SpringBoot的特定部分。 1. @RestController：提供实现了REST API，可以服务JSON,XML或者其他。这里是以String的形式渲染出结果。 2. @RequestMapping：提供路由信息，\u0026quot;/\u0026ldquo;路径的HTTP Request都会被映射到sayHello方法进行处理。\n启动应用类 和第一段描述一样，开箱即用。如下面Application类：\n/** * Spring Boot应用启动类 * * Created by liao on 2018/7/12. */ @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class,args); } }   @SpringBootApplication：Spring Boot 应用的标识 Application很简单，一个main函数作为主入口。SpringApplication引导应用，并将Application本身作为参数传递给run方法。具体run方法会启动嵌入式的Tomcat并初始化Spring环境及其各Spring组件。  运行 Just Run的宗旨，运行很简单，直接右键Run运行Application类。同样你也可以Debug Run。可以在控制台中看到：\nTomcat started on port(s): 8080 (http) Started Application in 5.986 seconds (JVM running for 7.398)  然后访问http://localhost:8080/,即可在页面中看到Spring Boot对你 say hello：\nHello,World！  配置文件 我在Spring Boot使用过程中，最直观的感受就是没有了原来自己整合Spring应用时繁多的XML配置内容，替代它的是在pom.xml中引入模块化的Starter POMs，其中各个模块都有自己的默认配置，所以如果不是特殊应用场景，就只需要在application.properties中完成一些属性配置就能开启各模块的应用。\n自定义属性与加载 在使用Spring Boot的时候，通常也需要定义一些自己使用的属性，可以如下方式直接定义：\ncom.gravel.name=李鳌 com.gravel.title=李鳌的文章  然后通过@Value(\u0026quot;${属性名}\u0026quot;)注解来加载对应的配置属性，具体如下：\n@Component public class gravelProperties { @Value(\u0026quot;${com.gravel.name}\u0026quot;) private String name; @Value(\u0026quot;${com.gravel.title}\u0026quot;) private String title; // 省略getter和setter }  可以通过单元测试来验证gravelProperties中的属性是否已经根据配置文件加载了。\n@RunWith(SpringJUnit4ClassRunner.class) @SpringApplicationConfiguration(Application.class) public class ApplicationTests { @Autowired private gravelProperties tProperties; @Test public void getHello() throws Exception { Assert.assertEquals(tProperties.getName(), \u0026quot;李鳌\u0026quot;); Assert.assertEquals(tProperties.getTitle(), \u0026quot;李鳌的文章\u0026quot;); } }  属性配置类 springboot还支持引入外部配置文件，这里举个例子。属性配置类 StaticProperties.class\n@Component public class StaticProperties { public static String CUSTOM_NAME; @Value(\u0026quot;${custom.name}\u0026quot;) public void setCustomName(String customName) { CUSTOM_NAME = customName; } }  Spring Boot 配置提示 resources/META-INF/spring-configuration-metadata.json\n{ \u0026quot;properties\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;custom.name\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;java.lang.String\u0026quot;, \u0026quot;sourceType\u0026quot;: \u0026quot;com.gravel.config.StaticProperties\u0026quot; } ] }  Spring Boot 配置 application.properties\ncustom.name=liao  至此，即可在 Spring Boot 全局任意引用 StaticProperties.CUSTOM_NAME来获取这个属性啦。\n参数间的引用 在application.properties中的各个参数之间也可以直接引用来使用，就像下面的设置：\ncom.gravel.name=李鳌 com.gravel.title=李鳌的文章 com.gravel.blog.desc=${com.gravel.name}正在努力写《${com.gravel.title}》  com.gravel.blog.desc参数引用了上文中定义的name和title属性，最后该属性的值就是李鳌正在努力写《李鳌的文章》。\n通过命令行设置属性值 相信使用过一段时间Spring Boot的用户，一定知道这条命令：java -jar xxx.jar --server.port=8888，通过使用—server.port属性来设置xxx.jar应用的端口为8888。\n在命令行运行时，连续的两个减号\u0026ndash;就是对application.properties中的属性值进行赋值的标识。所以，java -jar xxx.jar --server.port=8888命令，等价于我们在application.properties中添加属性server.port=8888，该设置在样例工程中可见，读者可通过删除该值或使用命令行来设置该值来验证。\n通过命令行来修改属性值固然提供了不错的便利性，但是通过命令行就能更改应用运行的参数，那岂不是很不安全？是的，所以Spring Boot也贴心的提供了屏蔽命令行访问属性的设置，只需要这句设置就能屏蔽：SpringApplication.setAddCommandLineProperties(false)。\n多环境配置 我们在开发Spring Boot应用时，通常同一套程序会被应用和安装到几个不同的环境，比如：开发、测试、生产等。其中每个环境的数据库地址、服务器端口等等配置都会不同，如果在为不同环境打包时都要频繁修改配置文件的话，那必将是个非常繁琐且容易发生错误的事。\n对于多环境的配置，各种项目构建工具或是框架的基本思路是一致的，通过配置多份不同环境的配置文件，再通过打包命令指定需要打包的内容之后进行区分打包，Spring Boot也不例外，或者说更加简单。\n在Spring Boot中多环境配置文件名需要满足application-{profile}.properties的格式，其中{profile}对应你的环境标识，比如：\n application-dev.properties：开发环境 application-test.properties：测试环境 application-prod.properties：生产环境  至于哪个具体的配置文件会被加载，需要在application.properties文件中通过spring.profiles.active属性来设置，其值对应{profile}值。 如：spring.profiles.active=test就会加载application-test.properties配置文件内容。` 下面，以不同环境配置不同的服务端口为例，进行样例实验。\n针对各环境新建不同的配置文件application-dev.properties、application-test.properties、application-prod.properties;\n在这三个文件均都设置不同的server.port属性，如：dev环境设置为1111，test环境设置为2222，prod环境设置为3333,\napplication.properties中设置spring.profiles.active=dev，就是说默认以dev环境设置\n测试不同配置的加载\n 执行java -jar xxx.jar，可以观察到服务端口被设置为1111，也就是默认的开发环境（dev） 执行java -jar xxx.jar --spring.profiles.active=test，可以观察到服务端口被设置为2222，也就是测试环境的配置（test） 执行java -jar xxx.jar --spring.profiles.active=prod，可以观察到服务端口被设置为3333，也就是生产环境的配置（prod） 按照上面的实验，可以如下总结多环境的配置思路：  application.properties中配置通用内容，并设置spring.profiles.active=dev，以开发环境为默认配置 application-{profile}.properties中配置各个环境不同的内容 通过命令行方式去激活不同环境的配置。\n","id":38,"section":"posts","summary":"\u003ch2 id=\"spring-boot-简介\"\u003eSpring Boot 简介\u003c/h2\u003e\n\u003cp\u003eSpring Boot(英文中是\u003ccode\u003e引导\u003c/code\u003e的意思)，是用来简化Spring应用的搭建到开发的过程。应用开箱即用，只要通过 \u003ccode\u003ejust run\u003c/code\u003e（可能是 java -jar 或 tomcat 或 maven插件run 或 shell脚本），就可以启动项目。二者，Spring Boot 只要很少的Spring配置文件（例如那些xml，property）。 因为\u003ccode\u003e习惯优先于配置\u003c/code\u003e的原则，使得Spring Boot在快速开发应用和微服务架构实践中得到广泛应用。   Javaer装好JDK环境和Maven工具就可以开始学习Boot了~\u003c/p\u003e","tags":["java","springboot"],"title":"springboot","uri":"https://gggggravel.com/post/springboot/","year":"2018"},{"content":"在大学时候买了《Think In java》这本书。最近开始重读，做一个笔记记录，并且谈谈我读这本书的感受。 这本书是由Bruce Eckel，这个人也许不熟悉，但是他的作品可是如雷贯耳啊，Bruce Eckel是MindView公司的总裁，这个公司提供一些软件资讯和培训。他是C++标准委员会拥有表决权的成员之一，拥有应用物理学学士和计算机工程硕士学位。Bruce Eckel从1984年至今，已经发表了超过150篇计算机技术文章，出版了6本书.他的《Thinking in C++》一本书在1995年被评为“最佳软件开发图书”，《Thinking in Java》被评为1999年Java World最受读者欢迎图书，并且赢得了编辑首选图书奖。\n第一章-对象导论 抽象过程 主要介绍oop的由来，计算机来源于机器，作者认为编程语言都提供抽象的机制来解决问题，置于抽象出来的东西就是类型了。\n抽象有两种方式，一种是针对计算机内部的结构，比如早期的basic、c语言等，另一种就是针对问题本身，这种方式又衍生出了面向对象的方式。而且oop又和计算机有联系，作者把这种解决问题的对象看成是一个微型计算机，因为它有状态又有操作，用户可以让对象执行这些操作。\njava的前生语言smalltalk，有五个基本特征：\n 万物皆对象  为什么这么说呢？作者认为：你可以把一个需要解决的问题，任何具有概念化的东东，都可以定义为对象。\n 程序就是一组对象的集合，对象之间通过发送消息和接收消息来相互通讯的  这个消息是啥呢？就是我对一个对象的方法进行调用，就相当于我对他发送了一个消息。在现实中，就像我对你说了一句话（发送消息），我得先喊你的名字，明确是对你说的呀！\n 每个对象都是由其他对象构成的  原文中，对于这个解释非常绕口，我就从我的角度说一下就行了，你也可以有其他的想法。作者的意思就是对象里面套对象，因此可以创建无线复杂的对象，当然这只是理论上\u0026hellip;\n 每个对象都有类型  这个相信大家都懂得，每个对象都是类型class的一个实例。有一点需要注意的是，类与类之间的区别就是“能够发送什么样的消息给它”（谨记）。\n 某一类型的所有对象可以接受同样的消息  这里有两层意思，第一所有对象都是这个类生出来的，所以可以发送相同的消息；另一种情况就是父类-子类概念，比如圆形的对象同时也是一个几何形，作者称之为可替代性（substitutablity）。\n最后booch更加简洁的描述了对象：就是状态、行为和标识，就是常说的属性、方法和内存地址（或者名字）。\n每个对象都有一个接口 首先作者把我们伟大的哲学家亚里士多德搬出来了，这大哲学家太聪明了，早就看出类型（type）的概念了。敬佩！\n作者认为，我们编程的过程就是创建新类型的过程，还有一点，程序都有内置的类型，比如浮点型，我们要面向实际问题中的类型，而不是计算机存储的数据类型。\noop的设计思想就是在问题空间和解空间之间寻找对象的映射关系（这句话比较抽象）。通俗一点解释：要解决问题，就是发生一系列的动作，而这些动作属于某一个对象，比如灯泡这个类型，有开灯这个动作，而这些动作集合就是接口。\n这个过程就是向某个对象发消息，比如灯泡这个对象，我可以对他请求开灯、关灯操作。\n最后说一下uml统一建模语言：\n它是一个支持模型化和软件系统开发的图形化语言，为软件开发的所有阶段提供模型化和可视化支持。UML规范用来描述建模的概念有，类（对象的）、对象、关联、职责、行为、接口、用例、包、顺序、协作，以及状态。\n每个对象都提供服务 如果要开发一个程序，就得把问题从表象抽取出来，什么样的对象能够解决我的问题，因此将对象看作是服务提供者，有助于提高对象的内聚性。\n被隐藏的具体实现 类创建者需要向程序员暴露必须的部分而隐藏其他的部分，需要隐藏的东西通常来说是一个对象脆弱的部分，容易被修改，并且这部分东西可以被类创建者随意修改，而不会对其他造成影响。\n还有重要的一点就是访问控制，允许类内部可以随意更改，而不会对累的使用造成影响，接口与实现相分离，访问控制词如下：\n复用具体实现 最简单的复用就是一个类中的成员包含另一个类的对象，使用现有的类合成新的类就叫组合（composition），如果这种组合是动态的就叫聚合（aggregation），是has-a的关系，比如汽车拥有引擎，URL图如下，\n继承 继承的UML图用一个空心的三角形表示 。\n使用继承主要是使基类和导出类产生差异，有两种方法，\n第一，直接在导出类中添加新方法；\n第二，覆盖（overriding）\n “是一个”。与“像是一个”关系 要明白一个概念“替代原则”：导出类覆盖基类的方法，拥有完全相同的接口，导出类对象可以完全替代基类对象，称之为“纯粹替代”。  伴随多态的可互换对象 这个小节说的很晦涩，大致意思就是，我们可以用导出类对象直接替换基类对象，但是实际执行的方法到最后运行的时候才能确定，编译期是不确定具体执行哪个对象的代码的。\n将导出类看成是基类成为“向上转型”（upcasting），这是“多态”的一种。\n单根继承结构 java所有的类型都继承自Object这个类，因此所有对象可以拥有共同的接口，这样操作起来就非常方便，比说垃圾回收器，在堆上创建对象。\n容器 下面这段话非常重要： 在解决某个问题时，不知道需要多少个对象，不知道对象存活多久，也不知道需要多少空间来存储这些对象，因为只有在运行时才能知道这些。 好的解决方案就是创建一个容器，比如数组，这个容器只有对所有对象的引用，为什么要选择不同的容器呢？ 第一，不同的容器有不同的接口和行为； 第二，不同的容器有些操作有不同的效率；\n 参数化类型 背景就是向下转型和运行时检查都是效率低下的，因为java1.5之前，所有的容器接受的对象都是object类，当从容器中取出某个对象时，就丢失了原来的类型信息，所以需要强制向下转型。 因此需要参数化类型这种机制。  对象的创建和生命期 java中对象是在堆上动态创建的，占用空间以及存活周期在编译期一无所知，只有在运行时才能却定； c++中，对象是在堆栈上手动创建的，占用空间以及存活周期在编译期就可以确定。\n异常处理：处理错误 异常也是一种对象，它在出错点就被抛出来，并被处理器所捕获，异常不会被忽略，因此一定会被处理。\n并发编程 线程的并发，以及锁\njava与internet  web是什么   客户/服务器技术 服务器提供信息，客户机消费信息 web就是一台巨型服务器   客户端编程 这里提到一个概念CGI通用网关接口（common gateway interface），服务器产生静态页面，浏览器进行解释，提交按钮，通过cgi来进行处理。cgi程序的响应时间依赖于发送的数据量、服务器和网络负载。 客户端提交页面，cgi处理完，如果有错误，会返回错误页面重新填写，这个过程不太优雅。 因此我们可以让浏览器做一些事情，因为运行浏览器的机器资源大部分会闲置，所以进行“客户端编程”（实际上就是在浏览器平台上编写程序）   插件 程序员下载一段代码，插入到浏览器，添加一些新的功能，因此他为专家级的程序员提供了一个“后门”，可以开发某种语言的扩展程序。 脚本语言 脚本语言可以直接嵌入到html页面中，还得需要能够解释这种脚本语言的插件，服务器收到请求时，可以被快速加载，但是缺点是任何人都可以看到脚本语言，不安全。 脚本语言更多的是用来创建更具交互性的页面 java 通过applet运行在客户端的小程序，作为网页的一部分自动下载，因此在提交表单之前，就可以对日期类型进行校验，从而不用发送到服务器，减少网络流量和服务器负载。 applet没有得到普及的根本原因在于，applet需要的java运行环境，所必须的10M带宽过于恐怖。 备选方案 flash .NET和C# .NET类似于JRE运行环境，C#相当于java，activeX相当于applet .NET只能运行在windows平台，并不是跨平台 internet和intranet   服务器端的编程 就是在服务器上运行程序，早起是通过perl、Python、C++编写cgi实现的  总结 什么是过程型语言？ 就是数据定义和函数调用\n好了，本章完结。\n","id":39,"section":"posts","summary":"\u003cp\u003e在大学时候买了《Think  In java》这本书。最近开始重读，做一个笔记记录，并且谈谈我读这本书的感受。\n这本书是由Bruce Eckel，这个人也许不熟悉，但是他的作品可是如雷贯耳啊，Bruce Eckel是MindView公司的总裁，这个公司提供一些软件资讯和培训。他是C++标准委员会拥有表决权的成员之一，拥有应用物理学学士和计算机工程硕士学位。Bruce Eckel从1984年至今，已经发表了超过150篇计算机技术文章，出版了6本书.他的《Thinking in C++》一本书在1995年被评为“最佳软件开发图书”，《Thinking in Java》被评为1999年Java World\u003ccode\u003e最受读者欢迎图书\u003c/code\u003e，并且赢得了编辑首选图书奖。\u003c/p\u003e","tags":["读书笔记","think_in_Java"],"title":"think-in-Java（第一章）","uri":"https://gggggravel.com/post/think_in_java%E7%AC%AC%E4%B8%80%E7%AB%A0/","year":"2018"},{"content":"在工作中，代码量不断提高，项目工程的体量不断增大，势必会给编码效率带来一定的负面影响。例如打开IDE变慢，保存大文件变慢问题。\n什么是SSD 固态硬盘（Solid State Drives），简称固盘，固态硬盘（Solid State Drive）用固态电子存储芯片阵列而制成的硬盘，由控制单元和存储单元（FLASH芯片、DRAM芯片）组成。\nSSD和HDD对比 读写速度 固态硬盘的读取速度普遍可以达到400M/s，在开机和数据的载入中，速度得到了有效的提升，大幅度的提高了电脑的运行能力。写入速度也可以达到130M/s以上，在写入大数据时，更加高效的储存能力大大缩短了办公时间。其读写速度是普通机械硬盘的3-5倍。\n抗震能力 在公司，大家能经常遇到调整工位的情况，在磕磕碰碰中，HDD如果出现高强度的震动，磁头与高速转动的盘片接触会造成盘片划伤和损坏，导致硬盘报废。但是SSD采用的是固态电子存储芯片阵列，焊接在电路板上，相比HDD有更加轻薄的机身和更好的抗震耐受力。\n功耗和噪音 这一点在中午午休的时候尤其能够感受到，大家工位上的机箱里发出呜呜的声音，这是由于HDD高速转动的盘片需要一个高功率的步进电机来驱动，而SSD不需要电机来驱动，所以HDD在功耗上就大了许多，工作时因电机的转动，会出现微小的震动和噪音，而固态硬盘是没有这些问题的。\n问题分析 软件切换卡顿 因为在我个人的开发习惯中，需要打开\n myEclipse开发 notepad++记录问题 Axure查看原型 Xshell配置启动服务端 word查看需求文档 excel编辑修改SMD sourceTree查看远端git代码状态 navicat运行SQL脚本 cocall联系同事 多开浏览器调试 foxmail查看邮件  这些都是常用的，且不会用完就关闭的软件，经常就是在切换软件的时候，电脑会出现明显的卡顿。\n大文件编辑保存无响应 在项目开发中，在编辑大文件的时候，类似某个web项目的web.xml，Myeclipse会出现无响应的状态。这是因为HDD读取大文件或者保存大文件的时候速度比较慢。\n开机以及软件启动缓慢 我在公司电脑WD10EZEX 7200转 HDD上和我自己的电脑SAMSUNG MZVLW 128G SSG上做了一个横向对比\n    SSD（SAMSUNG MZVLW128） HDD（WD10EZEX）     开机 4s 27s   IDEA 13s 43s   Myeclipse 9s 49s   photoShop 5s 36s   Hbuilder 4s 27s     由于公司电脑使用了一天，所以我在这个数据的基础上，适当的减少了一些数据。\n 由表格可以看出，在开机启动或者打开我们平时开发常用的软件时，SSD有着明显的速度优势。\n价格以及购买建议 第一档是Intel，浦科特，三星，美光，闪迪为主 浦科特的M8V、三星的860EVO、inter 545S，闪迪250G\n这三款都是250G，价格大概在600元左右\n第二档是东芝，金士顿，威刚，影驰等。 东芝 用的是和浦科特一样的马维尔主控，但无缓存，想来是对自家的闪存芯片十分自信吧。相对性能表现，价格算公道，家用挺不错的，售后不太了解。\n推荐型号:Q300 价格：500RMB\n金士顿 内存条行业的老大在SSD领域表现很一般，缺乏核心技术，基本是个组装厂而已。但考虑到十分可靠的售后，依然推荐。\n推荐型号:V300 价格：539RMB\n影驰 后起的品牌。但凭借其板卡建立起来的通路和售后，加之在第二档中最低的价格，不错的性能，性价比极高。 影驰 铁甲战将 240G 价格：325RMB\n第三档主要是国内的一些品牌，如金泰克，金胜什麽的。 国内的厂商价格普遍要便宜很多，但是我自己没有用过，所以不太清楚这一块。\n","id":40,"section":"posts","summary":"\u003cp\u003e在工作中，代码量不断提高，项目工程的体量不断增大，势必会给编码效率带来一定的负面影响。例如打开IDE变慢，保存大文件变慢问题。\u003c/p\u003e","tags":["SSD"],"title":"SSD优势分析","uri":"https://gggggravel.com/post/ssd%E5%88%86%E6%9E%90/","year":"2018"},{"content":"整理一下比较常见的几种排序算法\npackage com.gravel.sort; import java.util.Arrays; import java.util.Random; /** * Created by chen on 4/14/17. */ public class Sort { private static final int SIZE = 50; private static int[] array = new int[SIZE]; public static void init() { Random random = new Random(); for (int i = 0; i \u0026lt; SIZE; ++i) { array[i] = random.nextInt(100); } } private static void swap(int index1, int index2) { int temp = array[index1]; array[index1] = array[index2]; array[index2] = temp; } /** * 冒泡排序 * \u0026lt;p\u0026gt; * 下标小于 i 的元素都是已排好序的，内层 for 循环使小元素一步一步交换到前面 * \u0026lt;p\u0026gt; * \u0026lt;p\u0026gt; * 时间复杂度：O(n^2) * 空间复杂度：O(1) * * @param array */ public static void bubbleSort(int[] array) { if (array == null) { throw new IllegalArgumentException(\u0026quot;array can't be null\u0026quot;); } int len = array.length; for (int i = 0; i \u0026lt; len; ++i) { for (int j = len - 1; j \u0026gt; i; --j) { if (array[j - 1] \u0026gt; array[j]) { swap(j-1,j); } } } } /** * 选择排序 * \u0026lt;p\u0026gt; * 下标小于 i 的元素都是已排好序的， * 内层 for 循环寻找 [i,len) 之间最小的元素， * 然后将其与 下标为 i 的元素交换位置 * \u0026lt;p\u0026gt; * 时间复杂度：O(n^2) * 空间复杂度：O(1) * * @param array */ public static void selectSort(int[] array) { if (array == null) { throw new IllegalArgumentException(\u0026quot;array can't be null\u0026quot;); } int len = array.length; for (int i = 0; i \u0026lt; len; ++i) { int index = i; for (int j = i + 1; j \u0026lt; len; ++j) { if (array[index] \u0026gt; array[j]) { index = j; } } if (index != i) { swap(index, i); } } } /** * 插入排序 * \u0026lt;p\u0026gt; * 下标小于 i 的元素都是已排好序的， * 内层 while 循环寻找元素 i 适合插入的位置，并将大于 array[i] 的元素后移 * \u0026lt;p\u0026gt; * 时间复杂度：O(n^2) * 空间复杂度：O(1) * * @param array */ public static void insertSort(int[] array) { if (array == null) { throw new IllegalArgumentException(\u0026quot;array can't be null\u0026quot;); } int len = array.length; for (int i = 1; i \u0026lt; len; ++i) { int j = i - 1; int temp = array[i]; while (j \u0026gt; -1 \u0026amp;\u0026amp; temp \u0026lt; array[j]) { array[j + 1] = array[j]; --j; } array[j + 1] = temp; } } /** * * 快排 * * 选取最左侧的元素作为枢轴 * * 时间复杂度：O(nlogn) * 空间复杂度：O(logn) * * @param array */ public static void quickSort(int[] array) { if (array == null) { throw new IllegalArgumentException(\u0026quot;array can't be null\u0026quot;); } quickSort(array, 0, array.length - 1); } private static void quickSort(int[] array, int left, int right) { if (left \u0026lt; right) { int mid = partition(array, left, right); quickSort(array, left, mid - 1); quickSort(array, mid + 1, right); } } /** * 进行分区，返回枢轴所在下标。枢轴的左侧元素均比枢轴小，右侧元素均比枢轴大。 * * @param array * @param left * @param right * @return */ private static int partition(int[] array, int left, int right) { int leftIndex = left; // 左游标 int rightIndex = right; // 右游标 int pivot; // 枢轴下标 int midVal = array[leftIndex]; leftIndex++; while (true) { while (leftIndex \u0026lt; rightIndex \u0026amp;\u0026amp; midVal \u0026gt;= array[leftIndex]) { ++leftIndex; } while (leftIndex \u0026lt; rightIndex \u0026amp;\u0026amp; midVal \u0026lt;= array[rightIndex]) { --rightIndex; } if (leftIndex \u0026lt; rightIndex) { swap(leftIndex, rightIndex); } else { if (midVal \u0026gt; array[leftIndex]) { swap(left, leftIndex); pivot = leftIndex; } else { swap(left, leftIndex - 1); pivot = leftIndex - 1; } break; } } return pivot; } /** * 归并排序 * \u0026lt;p\u0026gt; * 使用递归的方式实现，比较简洁，已理解。 * \u0026lt;p\u0026gt; * 时间复杂度：O(nlogn) * 空间复杂度：O(n) * * @param array */ public static void mergeSort(int[] array) { if (array == null) { throw new IllegalArgumentException(\u0026quot;array can't be null\u0026quot;); } int[] temp = new int[SIZE]; mergeSort(array, temp, 0, array.length - 1); } private static void mergeSort(int[] array, int[] temp, int begin, int end) { if (begin \u0026lt; end) { int mid = (begin + end) / 2; // System.out.print(\u0026quot;begin: \u0026quot; + begin + \u0026quot; end: \u0026quot; + end); // System.out.println(\u0026quot; [\u0026quot; + begin +\u0026quot;, \u0026quot; + mid + \u0026quot;], [\u0026quot; + (mid+1) +\u0026quot;,\u0026quot; + end + \u0026quot;]\u0026quot;); mergeSort(array, temp, begin, mid); mergeSort(array, temp, mid + 1, end); merge(array, temp, begin, mid, end); } } /** * * 合并两个已排好序的数列，两个数列所在范围是 [begin, mid], [mid+1, end] * * @param array * @param temp * @param begin * @param mid * @param end */ private static void merge(int[] array, int[] temp, int begin, int mid, int end) { int i = begin; int j = mid + 1; int k = begin; while (i \u0026lt;= mid \u0026amp;\u0026amp; j \u0026lt;= end) { if (array[i] \u0026lt;= array[j]) { temp[k++] = array[i++]; } else { temp[k++] = array[j++]; } } while (j \u0026lt;= end) { temp[k++] = array[j++]; } while (i \u0026lt;= mid) { temp[k++] = array[i++]; } for (i = begin; i \u0026lt;= end; ++i) { array[i] = temp[i]; } // System.out.println(Arrays.toString(array)); } /** * 堆排序 * \u0026lt;p\u0026gt; * 基本思路： * 1. 构造最大堆 * 2. 将 array[0] 与 array[length-1] 交换，并将新的 array[0] 下沉恢复 [0,length-1) 的最大堆...一直到 恢复 [0,1) 的最大堆 * * @param array */ public static void heapSort(int[] array) { if (array == null) { throw new IllegalArgumentException(\u0026quot;array can't be null\u0026quot;); } // 构造最大堆 // [array.length/2 , array.length-1] 的元素都是叶子节点，不需要下沉 for (int i = array.length / 2 - 1, end = array.length - 1; i \u0026gt;= 0; --i) { down(array, i, end); } // 堆排序 for (int end = array.length - 1; end \u0026gt; 0; ) { swap(0, end--); down(array, 0, end); } } /** * * 将数组中下标为 root 的元素进行下沉，终结下标为 end(包含 end) * * @param array * @param root * @param end */ private static void down(int[] array, int root, int end) { int leaf = 2 * root + 1; while (leaf \u0026lt;= end) { if (leaf + 1 \u0026lt;= end \u0026amp;\u0026amp; array[leaf] \u0026lt; array[leaf + 1]) { leaf++; } if (array[root] \u0026gt; array[leaf]) { break; } swap(root, leaf); root = leaf; leaf = 2 * root + 1; } } public static void main(String[] args) { // System.out.println(-1 / 2); init(); System.out.println(Arrays.toString(array)); // bubbleSort(array); // selectSort(array); // insertSort(array); quickSort(array); // mergeSort(array); // heapSort(array); System.out.println(Arrays.toString(array)); } }  参考  各种排序算法总结 ","id":41,"section":"posts","summary":"\u003cp\u003e整理一下比较常见的几种排序算法\u003c/p\u003e","tags":["java","排序算法"],"title":"常见排序算法实现","uri":"https://gggggravel.com/post/%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/","year":"2018"},{"content":"今天启动tomcat项目的时候，tomcat抛出了下面这个异常：\nare only available on JDK 1.5 and higher  看源码是org.springframework.context.annotation.AnnotationConfigBeanDefinitionParser自动检测，jdk版本检测时需要jre1.5以上版本，但是JdkVersion只检查到了1.7，jre1.8 时不匹配任何jdk。\n想要解决这个错误，一般有两种办法：\n  将jdk8换成jdk7，重新启动项目就好了。\n  第二种手动修改spring的jar包，在org.springframework.core目录下，有一个JdkVersion.class，自己参照包路径，重新写一个JdkVersion.java，如下所示（一般不推荐使用这种方式，可能会导致其他的问题）：\n  package org.springframework.core; public class JdkVersion { public static final int JAVA_13 = 0; public static final int JAVA_14 = 1; public static final int JAVA_15 = 2; public static final int JAVA_16 = 3; public static final int JAVA_17 = 4; //for jre 1.8 public static final int JAVA_18 = 5; private static final String javaVersion = System.getProperty(\u0026quot;java.version\u0026quot;); private static final int majorJavaVersion; public static String getJavaVersion() { return javaVersion; } public static int getMajorJavaVersion() { return majorJavaVersion; } public static boolean isAtLeastJava14() { return true; } public static boolean isAtLeastJava15() { return getMajorJavaVersion() \u0026gt;= 2; } public static boolean isAtLeastJava16() { return getMajorJavaVersion() \u0026gt;= 3; } static { //for jre 1.8 if (javaVersion.indexOf(\u0026quot;1.8.\u0026quot;) != -1) { majorJavaVersion = 5; } else if (javaVersion.indexOf(\u0026quot;1.7.\u0026quot;) != -1) { majorJavaVersion = 4; } else if (javaVersion.indexOf(\u0026quot;1.6.\u0026quot;) != -1) { majorJavaVersion = 3; } else if (javaVersion.indexOf(\u0026quot;1.5.\u0026quot;) != -1) { majorJavaVersion = 2; } else { majorJavaVersion = 1; } } }  写好之后，编译成.class文件，放到spring的jar包中，替换项目jar包，重新启动，就好了。\n","id":42,"section":"posts","summary":"\u003cp\u003e今天启动tomcat项目的时候，tomcat抛出了下面这个异常：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eare only available on JDK 1.5 and higher\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e看源码是org.springframework.context.annotation.AnnotationConfigBeanDefinitionParser自动检测，jdk版本检测时需要jre1.5以上版本，但是JdkVersion只检查到了1.7，jre1.8 时不匹配任何jdk。\u003c/p\u003e","tags":["tomcat","问题笔记"],"title":"tomcat启动报错","uri":"https://gggggravel.com/post/tomcat_error/","year":"2018"},{"content":"最近在项目中维护某一张表的固定数据的时候，经常会用到postgreSQL的各种日期函数，所以简单整理一下。获取系统时间的函数 获取当前完整时间  通过now()获取的时间是最完整的时间，包括时区，秒也保留到了6位小数。  select now(); -- 得到如下结果 '2018-03-19 21:28:31.545145+08'   current_timestamp 效果是和now()一样的。  select current_timestamp效果是和now; -- 得到如下结果 '2018-03-19 21:29:31.545145+08'  获取当前时间  current_time 只显示当前的时间，不包括日期  select current_time; -- 得到的结果如下 21:29:31.545145+08'  获取当前日期  current_date 只显示当前的日期，不包括小时等信息  select current_date; -- 得到的结果如下 '2018-03-19'  日期计算函数 日期简单的加减  一年后  select now() + interval '1 years'; select now() + interval '1 year'; select now() + interval '1 y'; select now() + interval '2 Y'; select now() + interval '2Y';  这几种写法都OK的。 2. 一个月后\nselect now() + interval '1 month';  一周后  select now() + interval '1 week';  一天后  select now() + '1 day'  一分钟后  select now() + '1 min';  interval 可以不写，其值可以是：\n   Abbreviation Meaning     Y Years   M Months (in the date part)   W Weeks   D Days   H Hours   M Minutes (in the time part)   S Seconds    计算时间差 使用 age(timestamp, timestamp)计算时间差 函数描述：计算两个日期之间相隔多少天，单个参数时表示与当前日期(current_date)相比 参数：age(timestamp,timestamp),age(timestamp) 返回值：interval，两个日期之间的相隔天数\n示例：\nSelect age(timestamp '2001-04-10', timestamp '1957-06-13') Result: 43 years 9 mons 27 days  时间字段的截取 在开发的过程中，有时候经常会用到日期的年，月，日，小时等值，PostgreSQL给我们 提供了一个非常便利的EXTRACT函数。\nEXTRACT(field FROM source)  field 表示取的时间对象，source 表示取的日期来源，类型为 timestamp、time 或 interval。\n 取年份  select extract(year from now()); Result: 2018   取月份  select extract(month from now()); Result: 3 select extract(day from timestamp '1994-08-20'); Result: 8   查看今天是一年中的第几天  select extract(doy from now());   查看现在距1970-01-01 00:00:00 UTC 的秒数  select extract(epoch from now());   把epoch 值转换回时间戳  SELECT TIMESTAMP WITH TIME ZONE 'epoch' + 1369755555 * INTERVAL '1 second';  结语 以上是基本的PG时间/日期函数使用，有些函数因为下班了，家里电脑没环境，没跑结果出来，明天补上。（明日复明日。。明日何其多。。）\n详细用法请参考：PostgreSQL官方说明\n","id":43,"section":"posts","summary":"最近在项目中维护某一张表的固定数据的时候，经常会用到postgreSQL的各种日期函数，所以简单整理一下。获取系统时间的函数 获取当前完整时间","tags":["sql","pgsql"],"title":"postgreSQL 日期函数整理","uri":"https://gggggravel.com/post/postgresql-date-functions/","year":"2018"},{"content":"Gitment除了会产生大量无用的issue，这个插件使用起来，还是相当不错的。 作者的博客写得相当详细，我这里就不一一赘述使用方法了。\n","id":44,"section":"posts","summary":"Gitment除了会产生大量无用的issue，这个插件使用起来，还是相当不错的。 作者的博客写得相当详细，我这里就不一一赘述使用方法了。","tags":["gitment","github_page","issue"],"title":"使用Gitment作为博客评论插件","uri":"https://gggggravel.com/post/gitment/","year":"2018"},{"content":"整理一下关于String类的方法。\n  概览 继承结构  Serializable CharSequence Comparable   字符集简介 重要域成员 重要方法  代码点及代码单元 比较 搜索 提取子串 创建全大写/全小写副本   一些体会 参考   概览 String 类代表了字符串。所有类似于 \u0026quot;abc\u0026quot; 的字符串字面量都是该类的实例。\n字符串是常量，从创建后就不可更改。需要修改的字符串可以使用 StringBuffer。因为 String 实例不可变，所以他们可以安全的共享。一些例子：\nString str = \u0026quot;abc\u0026quot;; // 与上面一行代码效果相同 char data[] = {'a', 'b', 'c'}; String str = new String(data); System.out.println(\u0026quot;abc\u0026quot;); String cde = \u0026quot;cde\u0026quot;; System.out.println(\u0026quot;abc\u0026quot; + cde); String c = \u0026quot;abc\u0026quot;.substring(2,3); String d = cde.substring(1, 2);  String 类也包含了一些对单个字符的操作、比较、搜索、提取子串、创建全大写/全小写副本的方法。\nJava 语言为字符串连接操作符(+)添加了特殊支持。向左连接。\n// example 1 \u0026quot;The square root of 2 is \u0026quot; + Math.sqrt(2) | v \u0026quot;The square root of 2 is 1.4142135623730952\u0026quot; // example 2 1 + 2 + \u0026quot; fiddlers\u0026quot; | v \u0026quot;3 fiddlers\u0026quot; // example 3 \u0026quot;fiddlers \u0026quot; + 1 + 2 | v \u0026quot;fiddlers 12\u0026quot;  String 使用 UTF-16 来编码（一个字符两个字节或四个字节）。拓展字符用 surrogate pairs 来表示，占用四个字节。（PS：该术语是编码领域的，可以参考之前写的一篇笔记: Unicode 学习笔记）\nString 也提供了一些处理代码点(Unicode code points)和代码单元(Unicode code units)的方法(PS:这两个也是编码领域术语，可以参考：Unicode 学习笔记)。\nString 连接操作符的具体实现留给 Java 编译器来决定，只要编译器能够完全遵循 Java 语言规范即可。例如 javac 编译器可能用 StringBuffer、StringBuilder 或 java.lang.invoke.StringCOncatFactory 来实现。\n继承结构 Serializable 类通过实现 java.io.Serializable 接口来启用序列化能力。未实现该接口的类其状态将不会被序列化(抛出 NotSerializableException 异常)。该接口没有任何域或方法，只是表示可序列化的语义。\npublic static void serializableTest() throws IOException, ClassNotFoundException { String outputfile = \u0026quot;/Users/chen/Desktop/serializable\u0026quot;; ST instance = new ST(); ObjectOutputStream outputStream = new ObjectOutputStream(new FileOutputStream(outputfile)); outputStream.writeObject(instance); outputStream.close(); ObjectInputStream inputStream = new ObjectInputStream(new FileInputStream(outputfile)); ST newInstance = (ST) inputStream.readObject(); inputStream.close(); System.out.println(newInstance); System.out.println(instance.equals(newInstance)); // true System.out.println(instance == newInstance); //false } static class ST implements Serializable{ public int publicField = 1; protected int protectedField = 1; int defaultField = 1; private int privateField = 1; @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } ST st = (ST) o; return publicField == st.publicField \u0026amp;\u0026amp; protectedField == st.protectedField \u0026amp;\u0026amp; defaultField == st.defaultField \u0026amp;\u0026amp; privateField == st.privateField; } @Override public int hashCode() { return Objects.hash(publicField, protectedField, defaultField, privateField); } @Override public String toString() { return \u0026quot;ST{\u0026quot; + \u0026quot;publicField=\u0026quot; + publicField + \u0026quot;, protectedField=\u0026quot; + protectedField + \u0026quot;, defaultField=\u0026quot; + defaultField + \u0026quot;, privateField=\u0026quot; + privateField + '}'; } }  序列化的对象中引用的所有对象都必须实现了该接口，否则也会抛出 NotSerializableException 异常。\nCharSequence 一个 CharSequence 是一个只读的 char 序列。该接口为不同的实现提供了统一的只读访问。\n该接口并没有重新定义 equals() \u0026amp; hashCode() 方法，直接比较两个实现类的实例结果是未定义的。所以将 CharSequence 的实例作为 set 的元素或 map 的 key 是不合适的。\n主要的实现类：CharBuffer, Segment, String, StringBuffer, StringBuilder\nString 中也实现了与 CharSequence 实例进行比较、拼接等操作的函数。\nComparable 主要用于集合中元素排序，两个元素直接比较。\n字符集简介 String 类中用到了两种字符集 Latin1 \u0026amp; UTF-16. Latin1 拓展了 ASCII 编码，但是也是用一个字节来表示，UTF-16 使用两个或四个字节表示一个字符。简要介绍请看：Unicode 学习笔记\n/** 在构造一个 String 对象时，String 会尝试对传入的参数进行压缩。比如 String latin1 = new String(\u0026quot;latin1\u0026quot;.toCharArray()); String utf16 = new String(\u0026quot;使用 UTF-16 字符集\u0026quot;.toCharArray()); 入参是 char[]，java 中 char 是两个字节，byte 是一个字节，压缩后 latin1 的 value 字段是 6 个 byte，utf16 无法进行压缩，所以依旧是 26 个 byte。 下面是 java.lang.StringUTF16 中进行压缩的函数。 */ // compressedCopy char[] -\u0026gt; byte[] @HotSpotIntrinsicCandidate public static int compress(char[] src, int srcOff, byte[] dst, int dstOff, int len) { for (int i = 0; i \u0026lt; len; i++) { char c = src[srcOff]; if (c \u0026gt; 0xFF) { // 超出了 LATIN1 所能表示的范围，直接返回不再压缩 len = 0; break; } dst[dstOff] = (byte)c; srcOff++; dstOff++; } return len; }  重要域成员  private final byte[] value;  用来存储字符串的字节序列。   private final byte coder;  用来暗示 value 中的字节数组的编码方式。有 LATIN1 \u0026amp; UTF16 可选。 static final byte LATIN1 = 0; static final byte UTF16 = 1;   private int hash;  缓存字符串哈希值。默认是 0. 在 首次调用 hashCode() 方法时计算并缓存。   static final boolean COMPACT_STRINGS;  用来决定 value 是否进行压缩，默认是 true（压缩）。如果是 false 的话那么总是使用 UTF16 来编码字符串的字节流。在 String 类中，该域使用静态初始化块进行初始化。    重要方法  TIPS：本来计划中有这部分的内容，但是读过源码理解了字符集的概念和 String 的处理方式以后感觉这部分就不需要再写了，有兴趣可以自己看。  代码点及代码单元 比较 搜索 提取子串 创建全大写/全小写副本 一些体会 理解 String 类最重要的不是会用 String 的 API，而是对字符集本身的理解，字符集是什么，它解决了什么问题，字符是怎么编码的等等，只有很好的理解了字符集才能很好的理解 String 的行为。\n参考  java.lang.String 15.18.1. String Concatenation Operator + Serializable JAVA 对象序列化（一）——Serializable CharSequence ISO/IEC 8859-1  ","id":45,"section":"posts","summary":"整理一下关于String类的方法。 概览 继承结构 Serializable CharSequence Comparable 字符集简介 重要域成员 重要方法 代码点及代码单元 比较 搜索 提取子串 创建全大写/全小写副本 一些体","tags":["java","问题笔记"],"title":"【转载】java.lang.String","uri":"https://gggggravel.com/post/java.lang.string/","year":"2018"},{"content":"使用git的过程中，我们会初始化创建关联服务器的SSH key。\n1 设置用户名和邮箱 开发过程中，提交的时候会在log中显示用户名和密码，便于管理。\n$ git config --global user.name \u0026quot;gravel\u0026quot; $ git config --global user.email \u0026quot;leebroncc@gmail.com\u0026quot;  2 检查现有的SSH keys 在创建SSH keys之前，我们可以看看电脑内是否有SSH keys秘钥。\n打开Terminal输入如下命令。\n$ ls -al ~/.ssh  或输入\n$ ls ~/.ssh  如果看见如下文件，则代表SSH keys已创建好。\n id_dsa.pub id_ecdsa.pub id_ed25519.pub id_rsa.pub  查看已创建好的SSH key，使用如下命令。\n$ cat ~/.ssh/id_rsa.pub  3 生成新的SSH key 如果没创建SSH key，我们可以创建新的SSH key。\n1 设置电子邮件并创建对应的key\n$ ssh-keygen -t rsa -b 4096 -C \u0026quot;your_email@example.com\u0026quot; # Creates a new ssh key, using the provided email as a label Generating public/private rsa key pair.  2 设置文件存储位置，直接“回车”。\nEnter a file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter]  3 设置密码时，可设置空密码。\nEnter passphrase (empty for no passphrase): [Type a passphrase] Enter same passphrase again: [Type passphrase again]  4 添加SSH key到ssh-agent # start the ssh-agent in the background eval \u0026quot;$(ssh-agent -s)\u0026quot; Agent pid 59566 $ssh-add ~/.ssh/id_rsa  此时SSH key创建完毕。\n  Appendix Related Documentation Generating an SSH key\nCopyright CSDN：http://blog.csdn.net/y550918116j\n","id":46,"section":"posts","summary":"使用git的过程中，我们会初始化创建关联服务器的SSH key。 1 设置用户名和邮箱 开发过程中，提交的时候会在log中显示用户名和密码，便于管理","tags":["git"],"title":"git 生成SSH key","uri":"https://gggggravel.com/post/%E7%94%9F%E6%88%90ssh-key/","year":"2018"},{"content":"测试持续集成，再次测试\n","id":47,"section":"posts","summary":"测试持续集成，再次测试","tags":["hexo"],"title":"测试持续集成，明晚更新具体博客","uri":"https://gggggravel.com/post/hexo-ci/","year":"2018"},{"content":"最近在公司内部技术交流会上分享了mybatis相关的配置资料，现在整理下弄到博客上面。\nXML 映射配置文件 MyBatis 的配置文件包含了会深深影响 MyBatis 行为的设置（settings）和属性（properties）信息。文档的顶层结构如下：\n configuration 配置  properties 属性 settings 设置 typeAliases 类型别名 typeHandlers 类型处理器 objectFactory 对象工厂 plugins 插件 environments 环境  environment 环境变量  transactionManager 事务管理器 dataSource 数据源     databaseIdProvider 数据库厂商标识 mappers 映射器    properties 这些属性都是可外部配置且可动态替换的，既可以在典型的 Java 属性文件中配置，亦可通过 properties 元素的子元素来传递。例如：\n\u0026lt;properties resource=\u0026quot;org/mybatis/example/config.properties\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;username\u0026quot; value=\u0026quot;dev_user\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;password\u0026quot; value=\u0026quot;F2Fa3!33TYyg\u0026quot;/\u0026gt; \u0026lt;/properties\u0026gt;  其中的属性就可以在整个配置文件中使用来替换需要动态配置的属性值。比如:\n\u0026lt;dataSource type=\u0026quot;POOLED\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;driver\u0026quot; value=\u0026quot;${driver}\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;url\u0026quot; value=\u0026quot;${url}\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;username\u0026quot; value=\u0026quot;${username}\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;password\u0026quot; value=\u0026quot;${password}\u0026quot;/\u0026gt; \u0026lt;/dataSource\u0026gt;  这个例子中的 username 和 password 将会由 properties 元素中设置的相应值来替换。 driver 和 url 属性将会由 config.properties 文件中对应的值来替换。这样就为配置提供了诸多灵活选择。\n属性也可以被传递到 SqlSessionFactoryBuilder.build()方法中。例如：\nSqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, props); // ... or ... SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment, props);  如果属性在不只一个地方进行了配置，那么 MyBatis 将按照下面的顺序来加载：\n 在 properties 元素体内指定的属性首先被读取。 然后根据 properties 元素中的 resource 属性读取类路径下属性文件或根据 url 属性指定的路径读取属性文件，并覆盖已读取的同名属性。 最后读取作为方法参数传递的属性，并覆盖已读取的同名属性。  因此，通过方法参数传递的属性具有最高优先级，resource/url 属性中指定的配置文件次之，最低优先级的是 properties 属性中指定的属性。\n从MyBatis 3.4.2开始，你可以为占位符指定一个默认值。例如：\n\u0026lt;dataSource type=\u0026quot;POOLED\u0026quot;\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;property name=\u0026quot;username\u0026quot; value=\u0026quot;${username:ut_user}\u0026quot;/\u0026gt; \u0026lt;!-- If 'username' property not present, username become 'ut_user' --\u0026gt; \u0026lt;/dataSource\u0026gt;  这个特性默认是关闭的。如果你想为占位符指定一个默认值， 你应该添加一个指定的属性来开启这个特性。例如：\n\u0026lt;properties resource=\u0026quot;org/mybatis/example/config.properties\u0026quot;\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;property name=\u0026quot;org.apache.ibatis.parsing.PropertyParser.enable-default-value\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;!-- Enable this feature --\u0026gt; \u0026lt;/properties\u0026gt;  提示： 你可以使用 \u0026quot;:\u0026quot;作为属性键(e.g. db:username) 或者你也可以在sql定义中使用 OGNL 表达式的三元运算符(e.g. ${tableName != null ? tableName : \u0026lsquo;global_constants\u0026rsquo;})， 你应该通过增加一个指定的属性来改变分隔键和默认值的字符。例如：\n\u0026lt;properties resource=\u0026quot;org/mybatis/example/config.properties\u0026quot;\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;property name=\u0026quot;org.apache.ibatis.parsing.PropertyParser.default-value-separator\u0026quot; value=\u0026quot;?:\u0026quot;/\u0026gt; \u0026lt;!-- Change default value of separator --\u0026gt; \u0026lt;/properties\u0026gt;  \u0026lt;dataSource type=\u0026quot;POOLED\u0026quot;\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;property name=\u0026quot;username\u0026quot; value=\u0026quot;${db:username?:ut_user}\u0026quot;/\u0026gt; \u0026lt;/dataSource\u0026gt;  settings 这是 MyBatis 中极为重要的调整设置，它们会改变 MyBatis 的运行时行为。下表描述了设置中各项的意图、默认值等。\n   设置参数 描述 有效值 默认值     cacheEnabled 该配置影响的所有映射器中配置的缓存的全局开关。 true false   lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。特定关联关系中可通过设置fetchType属性来覆盖该项的开关状态。 true false   aggressiveLazyLoading 当启用时，带有延迟加载属性的对象的加载与否完全取决于对任意延迟属性的调用；反之，每种属性将会按需加载。 true false   multipleResultSetsEnabled 是否允许单一语句返回多结果集（需要兼容驱动）。 true false   useColumnLabel 使用列标签代替列名。不同的驱动在这方面会有不同的表现，具体可参考相关驱动文档或通过测试这两种不同的模式来观察所用驱动的结果。 true false   useGeneratedKeys 允许 JDBC 支持自动生成主键，需要驱动兼容。如果设置为 true 则这个设置强制使用自动生成主键，尽管一些驱动不能兼容但仍可正常工作（比如 Derby）。 true false   autoMappingBehavior 指定 MyBatis 是否以及如何自动映射指定的列到字段或属性。NONE 表示取消自动映射；PARTIAL 只会自动映射没有定义嵌套结果集映射的结果集。FULL 会自动映射任意复杂的结果集（包括嵌套和其他情况）。 NONE, PARTIAL, FULL PARTIAL   defaultExecutorType 配置默认的执行器。SIMPLE 就是普通的执行器；REUSE 执行器会重用预处理语句（prepared statements）；BATCH 执行器将重用语句并执行批量更新。 SIMPLE REUSE BATCH SIMPLE   defaultStatementTimeout 设置超时时间，它决定驱动等待数据库响应的秒数。 Any positive integer Not Set (null)   safeRowBoundsEnabled 允许在嵌套语句中使用行分界（RowBounds）。 true false   mapUnderscoreToCamelCase 是否开启自动驼峰命名规则（camel case）映射，即从经典数据库列名 A_COLUMN 到经典 Java 属性名 aColumn 的类似映射。 true false   localCacheScope MyBatis 利用本地缓存机制（Local Cache）防止循环引用（circular references）和加速重复嵌套查询。默认值为 SESSION，这种情况下会缓存一个会话中执行的所有查询。若设置值为 STATEMENT，本地会话仅用在语句执行上，对相同 SqlSession 的不同调用将不会共享数据。 SESSION STATEMENT   jdbcTypeForNull 当没有为参数提供特定的 JDBC 类型时，为空值指定 JDBC 类型。某些驱动需要指定列的 JDBC 类型，多数情况直接用一般类型即可，比如 NULL、VARCHAR 或 OTHER。 JdbcType enumeration. Most common are: NULL, VARCHAR and OTHER OTHER   lazyLoadTriggerMethods 指定哪个对象的方法触发一次延迟加载。 A method name list separated by commas equals,clone,hashCode,toString   defaultScriptingLanguage 指定动态 SQL 生成的默认语言。 A type alias or fully qualified class name. org.apache.ibatis.scripting.xmltags.XMLDynamicLanguageDriver   callSettersOnNulls 指定当结果集中值为 null 的时候是否调用映射对象的 setter（map 对象时为 put）方法，这对于有 Map.keySet() 依赖或 null 值初始化的时候是有用的。注意原始类型（int、boolean等）是不能设置成 null 的。 true false   logPrefix 指定 MyBatis 增加到日志名称的前缀。 Any String Not set   logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J LOG4J   proxyFactory 为 Mybatis 用来创建具有延迟加载能力的对象设置代理工具。 CGLIB JAVASSIST    一个配置完整的 settings 元素的示例如下：\n\u0026lt;settings\u0026gt; \u0026lt;setting name=\u0026quot;cacheEnabled\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;lazyLoadingEnabled\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;multipleResultSetsEnabled\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;useColumnLabel\u0026quot; value=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;useGeneratedKeys\u0026quot; value=\u0026quot;false\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;autoMappingBehavior\u0026quot; value=\u0026quot;PARTIAL\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;autoMappingUnknownColumnBehavior\u0026quot; value=\u0026quot;WARNING\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;defaultExecutorType\u0026quot; value=\u0026quot;SIMPLE\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;defaultStatementTimeout\u0026quot; value=\u0026quot;25\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;defaultFetchSize\u0026quot; value=\u0026quot;100\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;safeRowBoundsEnabled\u0026quot; value=\u0026quot;false\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;mapUnderscoreToCamelCase\u0026quot; value=\u0026quot;false\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;localCacheScope\u0026quot; value=\u0026quot;SESSION\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;jdbcTypeForNull\u0026quot; value=\u0026quot;OTHER\u0026quot;/\u0026gt; \u0026lt;setting name=\u0026quot;lazyLoadTriggerMethods\u0026quot; value=\u0026quot;equals,clone,hashCode,toString\u0026quot;/\u0026gt; \u0026lt;/settings\u0026gt;  typeAliases 类型别名是为 Java 类型设置一个短的名字。它只和 XML 配置有关，存在的意义仅在于用来减少类完全限定名的冗余。例如:\n\u0026lt;typeAliases\u0026gt; \u0026lt;typeAlias alias=\u0026quot;Author\u0026quot; type=\u0026quot;domain.blog.Author\u0026quot;/\u0026gt; \u0026lt;typeAlias alias=\u0026quot;Blog\u0026quot; type=\u0026quot;domain.blog.Blog\u0026quot;/\u0026gt; \u0026lt;typeAlias alias=\u0026quot;Comment\u0026quot; type=\u0026quot;domain.blog.Comment\u0026quot;/\u0026gt; \u0026lt;typeAlias alias=\u0026quot;Post\u0026quot; type=\u0026quot;domain.blog.Post\u0026quot;/\u0026gt; \u0026lt;typeAlias alias=\u0026quot;Section\u0026quot; type=\u0026quot;domain.blog.Section\u0026quot;/\u0026gt; \u0026lt;typeAlias alias=\u0026quot;Tag\u0026quot; type=\u0026quot;domain.blog.Tag\u0026quot;/\u0026gt; \u0026lt;/typeAliases\u0026gt;  当这样配置时，Blog可以用在任何使用domain.blog.Blog的地方。\n也可以指定一个包名，MyBatis 会在包名下面搜索需要的 Java Bean，比如:\n\u0026lt;typeAliases\u0026gt; \u0026lt;package name=\u0026quot;domain.blog\u0026quot;/\u0026gt; \u0026lt;/typeAliases\u0026gt;  每一个在包 domain.blog中的 Java Bean，在没有注解的情况下，会使用 Bean 的首字母小写的非限定类名来作为它的别名。 比如 domain.blog.Author的别名为 author；若有注解，则别名为其注解值。看下面的例子：\n@Alias(\u0026quot;author\u0026quot;) public class Author { ... }  已经为许多常见的 Java 类型内建了相应的类型别名。它们都是大小写不敏感的，需要注意的是由基本类型名称重复导致的特殊处理。\n   别名 映射的类型     _byte byte   _long long   _short short   _int int   _integer int   _double double   _float float   _boolean boolean   string String   byte Byte   long Long   short Short   int Integer   integer Integer   double Double   float Float   boolean Boolean   date Date   decimal BigDecimal   bigdecimal BigDecimal   object Object   map Map   hashmap HashMap   list List   arraylist ArrayList   collection Collection   iterator Iterator    typeHandlers 类型处理器的作用就是\n 查询时把数据库存储的值转换成java类型 修改是把java类型转换成数据库类型存储，处理 下面这个表格描述了默认的类型处理器。     类型处理器 Java 类型 JDBC 类型     BooleanTypeHandler java.lang.Boolean, boolean 数据库兼容的 BOOLEAN   ByteTypeHandler java.lang.Byte, byte 数据库兼容的 NUMERIC或 BYTE   ShortTypeHandler java.lang.Short, short 数据库兼容的 NUMERIC或 SHORT INTEGER   IntegerTypeHandler java.lang.Integer, int 数据库兼容的 NUMERIC或 INTEGER   LongTypeHandler java.lang.Long, long 数据库兼容的 NUMERIC或 LONG INTEGER   FloatTypeHandler java.lang.Float, float 数据库兼容的 NUMERIC或 FLOAT   DoubleTypeHandler java.lang.Double, double 数据库兼容的 NUMERIC或 DOUBLE   BigDecimalTypeHandler java.math.BigDecimal 数据库兼容的 NUMERIC或 DECIMAL   StringTypeHandler java.lang.String CHAR, VARCHAR   ClobReaderTypeHandler java.io.Reader -   ClobTypeHandler java.lang.String CLOB, LONGVARCHAR   NStringTypeHandler java.lang.String NVARCHAR, NCHAR   NClobTypeHandler java.lang.String NCLOB   BlobInputStreamTypeHandler java.io.InputStream -   ByteArrayTypeHandler byte[] 数据库兼容的字节流类型   BlobTypeHandler byte[] BLOB, LONGVARBINARY   DateTypeHandler java.util.Date TIMESTAMP   DateOnlyTypeHandler java.util.Date DATE   TimeOnlyTypeHandler java.util.Date TIME   SqlTimestampTypeHandler java.sql.Timestamp TIMESTAMP   SqlDateTypeHandler java.sql.Date DATE   SqlTimeTypeHandler java.sql.Time TIME   ObjectTypeHandler Any OTHER或未指定类型   EnumTypeHandler Enumeration Type VARCHAR-任何兼容的字符串类型，存储枚举的名称（而不是索引）   EnumOrdinalTypeHandler Enumeration Type 任何兼容的 NUMERIC或 DOUBLE类型，存储枚举的索引（而不是名称）。   InstantTypeHandler java.time.Instant TIMESTAMP   LocalDateTimeTypeHandler java.time.LocalDateTime TIMESTAMP   LocalDateTypeHandler java.time.LocalDate DATE   LocalTimeTypeHandler java.time.LocalTime TIME   OffsetDateTimeTypeHandler java.time.OffsetDateTime TIMESTAMP   OffsetTimeTypeHandler java.time.OffsetTime TIME   ZonedDateTimeTypeHandler java.time.ZonedDateTime TIMESTAMP   YearTypeHandler java.time.Year INTEGER   MonthTypeHandler java.time.Month INTEGER   YearMonthTypeHandler java.time.YearMonth VARCHARor LONGVARCHAR   JapaneseDateTypeHandler java.time.chrono.JapaneseDate DATE    你可以重写类型处理器或创建你自己的类型处理器来处理不支持的或非标准的类型。 具体做法为：实现 org.apache.ibatis.type.TypeHandler接口， 或继承一个很便利的类 org.apache.ibatis.type.BaseTypeHandler， 然后可以选择性地将它映射到一个 JDBC 类型。比如：\n// ExampleTypeHandler.java @MappedJdbcTypes(JdbcType.VARCHAR) public class ExampleTypeHandler extends BaseTypeHandler\u0026lt;String\u0026gt; { @Override public void setNonNullParameter(PreparedStatement ps, int i, String parameter, JdbcType jdbcType) throws SQLException { ps.setString(i, parameter); } @Override public String getNullableResult(ResultSet rs, String columnName) throws SQLException { return rs.getString(columnName); } @Override public String getNullableResult(ResultSet rs, int columnIndex) throws SQLException { return rs.getString(columnIndex); } @Override public String getNullableResult(CallableStatement cs, int columnIndex) throws SQLException { return cs.getString(columnIndex); } }  \u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;typeHandlers\u0026gt; \u0026lt;typeHandler handler=\u0026quot;org.mybatis.example.ExampleTypeHandler\u0026quot;/\u0026gt; \u0026lt;/typeHandlers\u0026gt;  使用这个的类型处理器将会覆盖已经存在的处理 Java 的 String 类型属性和 VARCHAR 参数及结果的类型处理器。 要注意 MyBatis 不会窥探数据库元信息来决定使用哪种类型，所以你必须在参数和结果映射中指明那是 VARCHAR 类型的字段， 以使其能够绑定到正确的类型处理器上。 这是因为：MyBatis 直到语句被执行才清楚数据类型。\n通过类型处理器的泛型，MyBatis 可以得知该类型处理器处理的 Java 类型，不过这种行为可以通过两种方法改变：\n 在类型处理器的配置元素（typeHandler element）上增加一个 javaType属性（比如：javaType=\u0026ldquo;String\u0026rdquo;）； 在类型处理器的类上（TypeHandler class）增加一个 @MappedTypes注解来指定与其关联的 Java 类型列表。 如果在 javaType属性中也同时指定，则注解方式将被忽略。  可以通过两种方式来指定被关联的 JDBC 类型：\n 在类型处理器的配置元素上增加一个 jdbcType属性（比如：jdbcType=\u0026ldquo;VARCHAR\u0026rdquo;）； 在类型处理器的类上（TypeHandler class）增加一个 @MappedJdbcTypes注解来指定与其关联的 JDBC 类型列表。 如果在 jdbcType属性中也同时指定，则注解方式将被忽略。  当决定在ResultMap中使用某一TypeHandler时，此时java类型是已知的（从结果类型中获得），但是JDBC类型是未知的。 因此Mybatis使用javaType=[TheJavaType], jdbcType=null的组合来选择一个TypeHandler。 这意味着使用@MappedJdbcTypes注解可以_限制_TypeHandler的范围，同时除非显示的设置，否则TypeHandler在ResultMap中将是无效的。 如果希望在ResultMap中使用TypeHandler，那么设置@MappedJdbcTypes注解的includeNullJdbcType=true即可。 然而从Mybatis 3.4.0开始，如果只有一个注册的TypeHandler来处理Java类型，那么它将是ResultMap使用Java类型时的默认值（即使没有includeNullJdbcType=true）。\n最后，可以让 MyBatis 为你查找类型处理器：\n\u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;typeHandlers\u0026gt; \u0026lt;package name=\u0026quot;org.mybatis.example\u0026quot;/\u0026gt; \u0026lt;/typeHandlers\u0026gt;  注意在使用自动检索（autodiscovery）功能的时候，只能通过注解方式来指定 JDBC 的类型。\n你能创建一个泛型类型处理器，它可以处理多于一个类。为达到此目的， 需要增加一个接收该类作为参数的构造器，这样在构造一个类型处理器的时候 MyBatis 就会传入一个具体的类。\n//GenericTypeHandler.java public class GenericTypeHandler\u0026lt;E extends MyObject\u0026gt; extends BaseTypeHandler\u0026lt;E\u0026gt; { private Class\u0026lt;E\u0026gt; type; public GenericTypeHandler(Class\u0026lt;E\u0026gt; type) { if (type == null) throw new IllegalArgumentException(\u0026quot;Type argument cannot be null\u0026quot;); this.type = type; } ...  EnumTypeHandler和 EnumOrdinalTypeHandler都是泛型类型处理器（generic TypeHandlers）， 我们将会在接下来的部分详细探讨。\n处理枚举类型 若想映射枚举类型 Enum，则需要从 EnumTypeHandler或者 EnumOrdinalTypeHandler中选一个来使用。\n比如说我们想存储取近似值时用到的舍入模式。默认情况下，MyBatis 会利用 EnumTypeHandler来把 Enum值转换成对应的名字。\n注意 EnumTypeHandler在某种意义上来说是比较特别的，其他的处理器只针对某个特定的类，而它不同，它会处理任意继承了 Enum的类。\n不过，我们可能不想存储名字，相反我们的 DBA 会坚持使用整形值代码。那也一样轻而易举： 在配置文件中把 EnumOrdinalTypeHandler加到 typeHandlers中即可， 这样每个 RoundingMode将通过他们的序数值来映射成对应的整形。\n\u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;typeHandlers\u0026gt; \u0026lt;typeHandler handler=\u0026quot;org.apache.ibatis.type.EnumOrdinalTypeHandler\u0026quot; javaType=\u0026quot;java.math.RoundingMode\u0026quot;/\u0026gt; \u0026lt;/typeHandlers\u0026gt;  但是怎样能将同样的 Enum既映射成字符串又映射成整形呢？\n自动映射器（auto-mapper）会自动地选用 EnumOrdinalTypeHandler来处理， 所以如果我们想用普通的 EnumTypeHandler，就非要为那些 SQL 语句显式地设置要用到的类型处理器不可。\n\u0026lt;!DOCTYPE mapper PUBLIC \u0026quot;-//mybatis.org//DTD Mapper 3.0//EN\u0026quot; \u0026quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026quot;\u0026gt; \u0026lt;mapper namespace=\u0026quot;org.apache.ibatis.submitted.rounding.Mapper\u0026quot;\u0026gt; \u0026lt;resultMap type=\u0026quot;org.apache.ibatis.submitted.rounding.User\u0026quot; id=\u0026quot;usermap\u0026quot;\u0026gt; \u0026lt;id column=\u0026quot;id\u0026quot; property=\u0026quot;id\u0026quot;/\u0026gt; \u0026lt;result column=\u0026quot;name\u0026quot; property=\u0026quot;name\u0026quot;/\u0026gt; \u0026lt;result column=\u0026quot;funkyNumber\u0026quot; property=\u0026quot;funkyNumber\u0026quot;/\u0026gt; \u0026lt;result column=\u0026quot;roundingMode\u0026quot; property=\u0026quot;roundingMode\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026quot;getUser\u0026quot; resultMap=\u0026quot;usermap\u0026quot;\u0026gt; select * from users \u0026lt;/select\u0026gt; \u0026lt;insert id=\u0026quot;insert\u0026quot;\u0026gt; insert into users (id, name, funkyNumber, roundingMode) values ( #{id}, #{name}, #{funkyNumber}, #{roundingMode} ) \u0026lt;/insert\u0026gt; \u0026lt;resultMap type=\u0026quot;org.apache.ibatis.submitted.rounding.User\u0026quot; id=\u0026quot;usermap2\u0026quot;\u0026gt; \u0026lt;id column=\u0026quot;id\u0026quot; property=\u0026quot;id\u0026quot;/\u0026gt; \u0026lt;result column=\u0026quot;name\u0026quot; property=\u0026quot;name\u0026quot;/\u0026gt; \u0026lt;result column=\u0026quot;funkyNumber\u0026quot; property=\u0026quot;funkyNumber\u0026quot;/\u0026gt; \u0026lt;result column=\u0026quot;roundingMode\u0026quot; property=\u0026quot;roundingMode\u0026quot; typeHandler=\u0026quot;org.apache.ibatis.type.EnumTypeHandler\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026quot;getUser2\u0026quot; resultMap=\u0026quot;usermap2\u0026quot;\u0026gt; select * from users2 \u0026lt;/select\u0026gt; \u0026lt;insert id=\u0026quot;insert2\u0026quot;\u0026gt; insert into users2 (id, name, funkyNumber, roundingMode) values ( #{id}, #{name}, #{funkyNumber}, #{roundingMode, typeHandler=org.apache.ibatis.type.EnumTypeHandler} ) \u0026lt;/insert\u0026gt; \u0026lt;/mapper\u0026gt;  注意，这里的 select 语句强制使用 resultMap来代替 resultType。\n对象工厂（objectFactory） MyBatis 每次创建结果对象的新实例时，它都会使用一个对象工厂（ObjectFactory）实例来完成。 默认的对象工厂需要做的仅仅是实例化目标类，要么通过默认构造方法，要么在参数映射存在的时候通过参数构造方法来实例化。 如果想覆盖对象工厂的默认行为，则可以通过创建自己的对象工厂来实现。比如：\n// ExampleObjectFactory.java public class ExampleObjectFactory extends DefaultObjectFactory { public Object create(Class type) { return super.create(type); } public Object create(Class type, List\u0026lt;Class\u0026gt; constructorArgTypes, List\u0026lt;Object\u0026gt; constructorArgs) { return super.create(type, constructorArgTypes, constructorArgs); } public void setProperties(Properties properties) { super.setProperties(properties); } public \u0026lt;T\u0026gt; boolean isCollection(Class\u0026lt;T\u0026gt; type) { return Collection.class.isAssignableFrom(type); }}  \u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;objectFactory type=\u0026quot;org.mybatis.example.ExampleObjectFactory\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;someProperty\u0026quot; value=\u0026quot;100\u0026quot;/\u0026gt; \u0026lt;/objectFactory\u0026gt;  ObjectFactory 接口很简单，它包含两个创建用的方法，一个是处理默认构造方法的，另外一个是处理带参数的构造方法的。 最后，setProperties 方法可以被用来配置 ObjectFactory，在初始化你的 ObjectFactory 实例后， objectFactory 元素体中定义的属性会被传递给 setProperties 方法。\n插件（plugins） MyBatis 允许你在已映射语句执行过程中的某一点进行拦截调用。默认情况下，MyBatis 允许使用插件来拦截的方法调用包括：\n Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters) StatementHandler (prepare, parameterize, batch, update, query)  这些类中方法的细节可以通过查看每个方法的签名来发现，或者直接查看 MyBatis 的发行包中的源代码。 假设你想做的不仅仅是监控方法的调用，那么你应该很好的了解正在重写的方法的行为。 因为如果在试图修改或重写已有方法的行为的时候，你很可能在破坏 MyBatis 的核心模块。 这些都是更低层的类和方法，所以使用插件的时候要特别当心。\n通过 MyBatis 提供的强大机制，使用插件是非常简单的，只需实现 Interceptor 接口，并指定了想要拦截的方法签名即可。\n@Intercepts({ @Signature(type = StatementHandler.class, method = \u0026quot;prepare\u0026quot;, args = { Connection.class, Integer.class}) }) public class SQLStatsInterceptor implements Interceptor { private final Logger logger = Logger.getLogger(SQLStatsInterceptor.class); @Override public Object intercept(Invocation invocation) throws Throwable { StatementHandler statementHandler = (StatementHandler) invocation.getTarget(); BoundSql boundSql = statementHandler.getBoundSql(); String sql = boundSql.getSql(); logger.info(\u0026quot;mybatis intercept sql:{\u0026quot;+sql+\u0026quot;}\u0026quot;); return invocation.proceed(); } @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } @Override public void setProperties(Properties properties) { String dialect = properties.getProperty(\u0026quot;dialect\u0026quot;); logger.info(\u0026quot;mybatis intercept dialect:{\u0026quot;+dialect+\u0026quot;}\u0026quot;); } }  \u0026lt;!-- mybatis-config.xml --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026quot;com.gravel.plugins.SQLStatsInterceptor\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;dialect\u0026quot; value=\u0026quot;mysql\u0026quot; /\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt;  上面的插件将会拦截在 Executor 实例中所有的 “update” 方法调用， 这里的 Executor 是负责执行低层映射语句的内部对象。\nNOTE 覆盖配置类\n除了用插件来修改 MyBatis 核心行为之外，还可以通过完全覆盖配置类来达到目的。只需继承后覆盖其中的每个方法，再把它传递到 SqlSessionFactoryBuilder.build(myConfig) 方法即可。再次重申，这可能会严重影响 MyBatis 的行为，务请慎之又慎。\n配置环境（environments） MyBatis 可以配置成适应多种环境，这种机制有助于将 SQL 映射应用于多种数据库之中， 现实情况下有多种理由需要这么做。例如，开发、测试和生产环境需要有不同的配置；或者共享相同 Schema 的多个生产数据库， 想使用相同的 SQL 映射。许多类似的用例。\n不过要记住：尽管可以配置多个环境，每个 SqlSessionFactory 实例只能选择其一。\n所以，如果你想连接两个数据库，就需要创建两个 SqlSessionFactory 实例，每个数据库对应一个。而如果是三个数据库，就需要三个实例，依此类推，记起来很简单：\n 每个数据库对应一个 SqlSessionFactory 实例  为了指定创建哪种环境，只要将它作为可选的参数传递给 SqlSessionFactoryBuilder 即可。可以接受环境配置的两个方法签名是：\nSqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment); SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader, environment,properties);  如果忽略了环境参数，那么默认环境将会被加载，如下所示：\nSqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader); SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader,properties);  环境元素定义了如何配置环境。\n\u0026lt;environments default=\u0026quot;development\u0026quot;\u0026gt; \u0026lt;environment id=\u0026quot;development\u0026quot;\u0026gt; \u0026lt;transactionManager type=\u0026quot;JDBC\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;...\u0026quot; value=\u0026quot;...\u0026quot;/\u0026gt; \u0026lt;/transactionManager\u0026gt; \u0026lt;dataSource type=\u0026quot;POOLED\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;driver\u0026quot; value=\u0026quot;${driver}\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;url\u0026quot; value=\u0026quot;${url}\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;username\u0026quot; value=\u0026quot;${username}\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;password\u0026quot; value=\u0026quot;${password}\u0026quot;/\u0026gt; \u0026lt;/dataSource\u0026gt; \u0026lt;/environment\u0026gt; \u0026lt;/environments\u0026gt;  注意这里的关键点:\n 默认的环境 ID（比如:default=”development”）。 每个 environment 元素定义的环境 ID（比如:id=”development”）。 事务管理器的配置（比如:type=”JDBC”）。 数据源的配置（比如:type=”POOLED”）。  默认的环境和环境 ID 是一目了然的。随你怎么命名，只要保证默认环境要匹配其中一个环境ID。\n事务管理器（transactionManager）\n在 MyBatis 中有两种类型的事务管理器（也就是 type=”[JDBC|MANAGED]”）：\n  JDBC – 这个配置就是直接使用了 JDBC 的提交和回滚设置，它依赖于从数据源得到的连接来管理事务作用域。\n  MANAGED – 这个配置几乎没做什么。它从来不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接，然而一些容器并不希望这样，因此需要将 closeConnection 属性设置为 false 来阻止它默认的关闭行为。例如:\n\u0026lt;transactionManager type=\u0026quot;MANAGED\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;closeConnection\u0026quot; value=\u0026quot;false\u0026quot;/\u0026gt; \u0026lt;/transactionManager\u0026gt;    NOTE如果你正在使用 Spring + MyBatis，则没有必要配置事务管理器， 因为 Spring 模块会使用自带的管理器来覆盖前面的配置。\n这两种事务管理器类型都不需要任何属性。它们不过是类型别名，换句话说，你可以使用 TransactionFactory 接口的实现类的完全限定名或类型别名代替它们。\npublic interface TransactionFactory { void setProperties(Properties props); Transaction newTransaction(Connection conn); Transaction newTransaction(DataSource dataSource, TransactionIsolationLevel level, boolean autoCommit); }  任何在 XML 中配置的属性在实例化之后将会被传递给 setProperties() 方法。你也需要创建一个 Transaction 接口的实现类，这个接口也很简单：\npublic interface Transaction { Connection getConnection() throws SQLException; void commit() throws SQLException; void rollback() throws SQLException; void close() throws SQLException; Integer getTimeout() throws SQLException; }  使用这两个接口，你可以完全自定义 MyBatis 对事务的处理。\n数据源（dataSource）\ndataSource 元素使用标准的 JDBC 数据源接口来配置 JDBC 连接对象的资源。\n 许多 MyBatis 的应用程序将会按示例中的例子来配置数据源。然而它并不是必须的。要知道为了方便使用延迟加载，数据源才是必须的。  有三种内建的数据源类型（也就是 type=”[UNPOOLED|POOLED|JNDI]”）：\nUNPOOLED– 这个数据源的实现只是每次被请求时打开和关闭连接。虽然一点慢，它对在及时可用连接方面没有性能要求的简单应用程序是一个很好的选择。 不同的数据库在这方面表现也是不一样的，所以对某些数据库来说使用连接池并不重要，这个配置也是理想的。UNPOOLED 类型的数据源仅仅需要配置以下 5 种属性：\n driver– 这是 JDBC 驱动的 Java 类的完全限定名（并不是JDBC驱动中可能包含的数据源类）。 url– 这是数据库的 JDBC URL 地址。 username– 登录数据库的用户名。 password– 登录数据库的密码。 defaultTransactionIsolationLevel– 默认的连接事务隔离级别。  作为可选项，你也可以传递属性给数据库驱动。要这样做，属性的前缀为“driver.”，例如：\n driver.encoding=UTF8  这将通过DriverManager.getConnection(url,driverProperties)方法传递值为 UTF8的 encoding属性给数据库驱动。\nPOOLED– 这种数据源的实现利用“池”的概念将 JDBC 连接对象组织起来，避免了创建新的连接实例时所必需的初始化和认证时间。 这是一种使得并发 Web 应用快速响应请求的流行处理方式。\n除了上述提到 UNPOOLED 下的属性外，会有更多属性用来配置 POOLED 的数据源：\n poolMaximumActiveConnections– 在任意时间可以存在的活动（也就是正在使用）连接数量，默认值：10 poolMaximumIdleConnections– 任意时间可能存在的空闲连接数。 poolMaximumCheckoutTime– 在被强制返回之前，池中连接被检出（checked out）时间，默认值：20000 毫秒（即 20 秒） poolTimeToWait– 这是一个底层设置，如果获取连接花费的相当长的时间，它会给连接池打印状态日志并重新尝试获取一个连接（避免在误配置的情况下一直安静的失败），默认值：20000 毫秒（即 20 秒）。 poolMaximumLocalBadConnectionTolerance– 这是一个关于坏连接容忍度的底层设置， 作用于每一个尝试从缓存池获取连接的线程. 如果这个线程获取到的是一个坏的连接，那么这个数据源允许这 个线程尝试重新获取一个新的连接，但是这个重新尝试的次数不应该超过 poolMaximumIdleConnections与 poolMaximumLocalBadConnectionTolerance之和。 默认值：3 (Since: 3.4.5) poolPingQuery– 发送到数据库的侦测查询，用来检验连接是否处在正常工作秩序中并准备接受请求。默认是“NO PING QUERY SET”，这会导致多数数据库驱动失败时带有一个恰当的错误消息。 poolPingEnabled– 是否启用侦测查询。若开启，也必须使用一个可执行的 SQL 语句设置 poolPingQuery属性（最好是一个非常快的 SQL），默认值：false。 poolPingConnectionsNotUsedFor– 配置 poolPingQuery 的使用频度。这可以被设置成匹配具体的数据库连接超时时间，来避免不必要的侦测，默认值：0（即所有连接每一时刻都被侦测 — 当然仅当 poolPingEnabled 为 true 时适用）。  JNDI– 这个数据源的实现是为了能在如 EJB 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的引用。这种数据源配置只需要两个属性：\n initial_context– 这个属性用来在 InitialContext 中寻找上下文（即，initialContext.lookup(initial_context)）。这是个可选属性，如果忽略，那么 data_source 属性将会直接从 InitialContext 中寻找。 data_source– 这是引用数据源实例位置的上下文的路径。提供了 initial_context 配置时会在其返回的上下文中进行查找，没有提供时则直接在 InitialContext 中查找。  和其他数据源配置类似，可以通过添加前缀“env.”直接把属性传递给初始上下文。比如：\n env.encoding=UTF8  这就会在初始上下文（InitialContext）实例化时往它的构造方法传递值为 UTF8的 encoding属性。\n通过需要实现接口 org.apache.ibatis.datasource.DataSourceFactory， 也可使用任何第三方数据源，：\npublic interface DataSourceFactory { void setProperties(Properties props); DataSource getDataSource(); }  org.apache.ibatis.datasource.unpooled.UnpooledDataSourceFactory可被用作父类来构建新的数据源适配器，比如下面这段插入 C3P0 数据源所必需的代码：\nimport org.apache.ibatis.datasource.unpooled.UnpooledDataSourceFactory; import com.mchange.v2.c3p0.ComboPooledDataSource; public class C3P0DataSourceFactory extends UnpooledDataSourceFactory { public C3P0DataSourceFactory() { this.dataSource = new ComboPooledDataSource(); } }  为了令其工作，为每个需要 MyBatis 调用的 setter 方法中增加一个属性。下面是一个可以连接至 PostgreSQL 数据库的例子：\n\u0026lt;dataSource type=\u0026quot;org.myproject.C3P0DataSourceFactory\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;driver\u0026quot; value=\u0026quot;org.postgresql.Driver\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;url\u0026quot; value=\u0026quot;jdbc:postgresql:mydb\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;username\u0026quot; value=\u0026quot;postgres\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;password\u0026quot; value=\u0026quot;root\u0026quot;/\u0026gt; \u0026lt;/dataSource\u0026gt;  databaseIdProvider MyBatis 可以根据不同的数据库厂商执行不同的语句，这种多厂商的支持是基于映射语句中的 databaseId属性。 MyBatis 会加载不带 databaseId属性和带有匹配当前数据库 databaseId属性的所有语句。 如果同时找到带有 databaseId和不带 databaseId的相同语句，则后者会被舍弃。 为支持多厂商特性只要像下面这样在 mybatis-config.xml 文件中加入 databaseIdProvider即可：\n\u0026lt;databaseIdProvider type=\u0026quot;DB_VENDOR\u0026quot; /\u0026gt;  这里的 DB_VENDOR 会通过 DatabaseMetaData#getDatabaseProductName()返回的字符串进行设置。 由于通常情况下这个字符串都非常长而且相同产品的不同版本会返回不同的值，所以最好通过设置属性别名来使其变短，如下：\n\u0026lt;databaseIdProvider type=\u0026quot;DB_VENDOR\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;SQL Server\u0026quot; value=\u0026quot;sqlserver\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;DB2\u0026quot; value=\u0026quot;db2\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;Oracle\u0026quot; value=\u0026quot;oracle\u0026quot; /\u0026gt; \u0026lt;/databaseIdProvider\u0026gt;  在有 properties 时，DB_VENDOR databaseIdProvider 的将被设置为第一个能匹配数据库产品名称的属性键对应的值，如果没有匹配的属性将会设置为 “null”。 在这个例子中，如果 getDatabaseProductName()返回“Oracle (DataDirect)”，databaseId 将被设置为“oracle”。\n你可以通过实现接口 org.apache.ibatis.mapping.DatabaseIdProvider并在 mybatis-config.xml 中注册来构建自己的 DatabaseIdProvider：\npublic interface DatabaseIdProvider { void setProperties(Properties p); String getDatabaseId(DataSource dataSource) throws SQLException; }  映射器（mappers） 既然 MyBatis 的行为已经由上述元素配置完了，我们现在就要定义 SQL 映射语句了。但是首先我们需要告诉 MyBatis 到哪里去找到这些语句。 Java 在自动查找这方面没有提供一个很好的方法，所以最佳的方式是告诉 MyBatis 到哪里去找映射文件。你可以使用相对于类路径的资源引用， 或完全限定资源定位符（包括 file:///的 URL），或类名和包名等。例如：\n\u0026lt;!-- Using classpath relative resources --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper resource=\u0026quot;org/mybatis/builder/AuthorMapper.xml\u0026quot;/\u0026gt; \u0026lt;mapper resource=\u0026quot;org/mybatis/builder/BlogMapper.xml\u0026quot;/\u0026gt; \u0026lt;mapper resource=\u0026quot;org/mybatis/builder/PostMapper.xml\u0026quot;/\u0026gt; \u0026lt;/mappers\u0026gt;  \u0026lt;!-- Using url fully qualified paths --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper url=\u0026quot;file:///var/mappers/AuthorMapper.xml\u0026quot;/\u0026gt; \u0026lt;mapper url=\u0026quot;file:///var/mappers/BlogMapper.xml\u0026quot;/\u0026gt; \u0026lt;mapper url=\u0026quot;file:///var/mappers/PostMapper.xml\u0026quot;/\u0026gt; \u0026lt;/mappers\u0026gt;  \u0026lt;!-- Using mapper interface classes --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;mapper class=\u0026quot;org.mybatis.builder.AuthorMapper\u0026quot;/\u0026gt; \u0026lt;mapper class=\u0026quot;org.mybatis.builder.BlogMapper\u0026quot;/\u0026gt; \u0026lt;mapper class=\u0026quot;org.mybatis.builder.PostMapper\u0026quot;/\u0026gt; \u0026lt;/mappers\u0026gt;  \u0026lt;!-- Register all interfaces in a package as mappers --\u0026gt; \u0026lt;mappers\u0026gt; \u0026lt;package name=\u0026quot;org.mybatis.builder\u0026quot;/\u0026gt; \u0026lt;/mappers\u0026gt;  这些配置会告诉了 MyBatis 去哪里找映射文件.\nMapper XML 文件 MyBatis 的真正强大在于它的映射语句，也是它的魔力所在。由于它的异常强大，映射器的 XML 文件就显得相对简单。如果拿它跟具有相同功能的 JDBC 代码进行对比，你会立即发现省掉了将近 95% 的代码。MyBatis 就是针对 SQL 构建的，并且比普通的方法做的更好。\nSQL 映射文件有很少的几个顶级元素（按照它们应该被定义的顺序）：\n cache– 给定命名空间的缓存配置。 cache-ref– 其他命名空间缓存配置的引用。 resultMap– 是最复杂也是最强大的元素，用来描述如何从数据库结果集中来加载对象。 parameterMap– 已废弃！老式风格的参数映射。内联参数是首选,这个元素可能在将来被移除，这里不会记录。 sql– 可被其他语句引用的可重用语句块。 insert– 映射插入语句 update– 映射更新语句 delete– 映射删除语句 select– 映射查询语句  下一部分将从语句本身开始来描述每个元素的细节。\nselect 查询语句是 MyBatis 中最常用的元素之一，光能把数据存到数据库中价值并不大，如果还能重新取出来才有用，多数应用也都是查询比修改要频繁。对每个插入、更新或删除操作，通常对应多个查询操作。这是 MyBatis 的基本原则之一，也是将焦点和努力放到查询和结果映射的原因。简单查询的 select 元素是非常简单的。比如：\n\u0026lt;select id=\u0026quot;selectPerson\u0026quot; parameterType=\u0026quot;int\u0026quot; resultType=\u0026quot;hashmap\u0026quot;\u0026gt; SELECT * FROM PERSON WHERE ID = #{id} \u0026lt;/select\u0026gt;  这个语句被称作 selectPerson，接受一个 int（或 Integer）类型的参数，并返回一个 HashMap 类型的对象，其中的键是列名，值便是结果行中的对应值。\n注意参数符号：\n#{id}  这就告诉 MyBatis 创建一个预处理语句参数，通过 JDBC，这样的一个参数在 SQL 中会由一个“?”来标识，并被传递到一个新的预处理语句中，就像这样：\n// Similar JDBC code, NOT MyBatis… String selectPerson = \u0026quot;SELECT * FROM PERSON WHERE ID=?\u0026quot;; PreparedStatement ps = conn.prepareStatement(selectPerson); ps.setInt(1,id);  当然，这需要很多单独的 JDBC 的代码来提取结果并将它们映射到对象实例中，这就是 MyBatis 节省你时间的地方。我们需要深入了解参数和结果映射，细节部分我们下面来了解。\nselect 元素有很多属性允许你配置，来决定每条语句的作用细节。\n\u0026lt;select \u0026lt;!-- 1. id （必须配置） id是命名空间中的唯一标识符，可被用来代表这条语句。 一个命名空间（namespace） 对应一个dao接口, 这个id也应该对应dao里面的某个方法（相当于方法的实现），因此id 应该与方法名一致 --\u0026gt; id=\u0026quot;selectPerson\u0026quot; \u0026lt;!-- 2. parameterType （可选配置, 默认为mybatis自动选择处理） 将要传入语句的参数的完全限定类名或别名， 如果不配置，mybatis会通过ParameterHandler 根据参数类型默认选择合适的typeHandler进行处理 parameterType 主要指定参数类型，可以是int, short, long, string等类型，也可以是复杂类型（如对象） --\u0026gt; parameterType=\u0026quot;int\u0026quot; \u0026lt;!-- 3. resultType (resultType 与 resultMap 二选一配置) resultType用以指定返回类型，指定的类型可以是基本类型，可以是java容器，也可以是javabean --\u0026gt; resultType=\u0026quot;hashmap\u0026quot; \u0026lt;!-- 4. resultMap (resultType 与 resultMap 二选一配置) resultMap用于引用我们通过 resultMap标签定义的映射类型，这也是mybatis组件高级复杂映射的关键 --\u0026gt; resultMap=\u0026quot;personResultMap\u0026quot; \u0026lt;!-- 5. flushCache (可选配置) 将其设置为 true，任何时候只要语句被调用，都会导致本地缓存和二级缓存都会被清空，默认值：false --\u0026gt; flushCache=\u0026quot;false\u0026quot; \u0026lt;!-- 6. useCache (可选配置) 将其设置为 true，将会导致本条语句的结果被二级缓存，默认值：对 select 元素为 true --\u0026gt; useCache=\u0026quot;true\u0026quot; \u0026lt;!-- 7. timeout (可选配置) 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为 unset（依赖驱动）--\u0026gt; timeout=\u0026quot;10000\u0026quot; \u0026lt;!-- 8. fetchSize (可选配置) 这是尝试影响驱动程序每次批量返回的结果行数和这个设置值相等。默认值为 unset（依赖驱动)--\u0026gt; fetchSize=\u0026quot;256\u0026quot; \u0026lt;!-- 9. statementType (可选配置) STATEMENT，PREPARED 或 CALLABLE 的一个。这会让 MyBatis 分别使用 Statement，PreparedStatement 或 CallableStatement，默认值：PREPARED--\u0026gt; statementType=\u0026quot;PREPARED\u0026quot; \u0026lt;!-- 10. resultSetType (可选配置) FORWARD_ONLY，SCROLL_SENSITIVE 或 SCROLL_INSENSITIVE 中的一个，默认值为 unset （依赖驱动）--\u0026gt; resultSetType=\u0026quot;FORWARD_ONLY\u0026quot;\u0026gt;  配置看起来总是这么多，不过实际常用的配置也就那么几个， 根据自己的需要，上面都已注明是否必须配置。\ninsert, update 和 delete 数据变更语句 insert，update 和 delete 的实现非常接近：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026quot;-//ibatis.apache.org//DTD Mapper 3.0//EN\u0026quot; \u0026quot;http://ibatis.apache.org/dtd/ibatis-3-mapper.dtd\u0026quot;\u0026gt; \u0026lt;!-- mapper 为根元素节点， 一个namespace对应一个dao --\u0026gt; \u0026lt;mapper namespace=\u0026quot;com.dy.dao.UserDao\u0026quot;\u0026gt; \u0026lt;insert \u0026lt;!-- 1. id （必须配置） id是命名空间中的唯一标识符，可被用来代表这条语句。 一个命名空间（namespace） 对应一个dao接口, 这个id也应该对应dao里面的某个方法（相当于方法的实现），因此id 应该与方法名一致 --\u0026gt; id=\u0026quot;insertUser\u0026quot; \u0026lt;!-- 2. parameterType （可选配置, 默认为mybatis自动选择处理） 将要传入语句的参数的完全限定类名或别名， 如果不配置，mybatis会通过ParameterHandler 根据参数类型默认选择合适的typeHandler进行处理 parameterType 主要指定参数类型，可以是int, short, long, string等类型，也可以是复杂类型（如对象） --\u0026gt; parameterType=\u0026quot;com.demo.User\u0026quot; \u0026lt;!-- 3. flushCache （可选配置，默认配置为true） 将其设置为 true，任何时候只要语句被调用，都会导致本地缓存和二级缓存都会被清空，默认值：true（对应插入、更新和删除语句） --\u0026gt; flushCache=\u0026quot;true\u0026quot; \u0026lt;!-- 4. statementType （可选配置，默认配置为PREPARED） STATEMENT，PREPARED 或 CALLABLE 的一个。这会让 MyBatis 分别使用 Statement，PreparedStatement 或 CallableStatement，默认值：PREPARED。 --\u0026gt; statementType=\u0026quot;PREPARED\u0026quot; \u0026lt;!-- 5. keyProperty (可选配置， 默认为unset) （仅对 insert 和 update 有用）唯一标记一个属性，MyBatis 会通过 getGeneratedKeys 的返回值或者通过 insert 语句的 selectKey 子元素设置它的键值，默认：unset。如果希望得到多个生成的列，也可以是逗号分隔的属性名称列表。 --\u0026gt; keyProperty=\u0026quot;\u0026quot; \u0026lt;!-- 6. keyColumn (可选配置) （仅对 insert 和 update 有用）通过生成的键值设置表中的列名，这个设置仅在某些数据库（像 PostgreSQL）是必须的，当主键列不是表中的第一列的时候需要设置。如果希望得到多个生成的列，也可以是逗号分隔的属性名称列表。 --\u0026gt; keyColumn=\u0026quot;\u0026quot; \u0026lt;!-- 7. useGeneratedKeys (可选配置， 默认为false) （仅对 insert 和 update 有用）这会令 MyBatis 使用 JDBC 的 getGeneratedKeys 方法来取出由数据库内部生成的主键（比如：像 MySQL 和 SQL Server 这样的关系数据库管理系统的自动递增字段），默认值：false。 --\u0026gt; useGeneratedKeys=\u0026quot;false\u0026quot; \u0026lt;!-- 8. timeout (可选配置， 默认为unset, 依赖驱动) 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为 unset（依赖驱动）。 --\u0026gt; timeout=\u0026quot;20\u0026quot;\u0026gt; \u0026lt;update id=\u0026quot;updateUser\u0026quot; parameterType=\u0026quot;com.demo.User\u0026quot; flushCache=\u0026quot;true\u0026quot; statementType=\u0026quot;PREPARED\u0026quot; timeout=\u0026quot;20\u0026quot;\u0026gt; \u0026lt;delete id=\u0026quot;deleteUser\u0026quot; parameterType=\u0026quot;com.demo.User\u0026quot; flushCache=\u0026quot;true\u0026quot; statementType=\u0026quot;PREPARED\u0026quot; timeout=\u0026quot;20\u0026quot;\u0026gt; \u0026lt;/mapper\u0026gt;  下面就是 insert，update 和 delete 语句的示例：\n\u0026lt;insert id=\u0026quot;insertAuthor\u0026quot;\u0026gt; insert into Author (id,username,password,email,bio) values (#{id},#{username},#{password},#{email},#{bio}) \u0026lt;/insert\u0026gt; \u0026lt;update id=\u0026quot;updateAuthor\u0026quot;\u0026gt; update Author set username = #{username}, password = #{password}, email = #{email}, bio = #{bio} where id = #{id} \u0026lt;/update\u0026gt; \u0026lt;delete id=\u0026quot;deleteAuthor\u0026quot;\u0026gt; delete from Author where id = #{id} \u0026lt;/delete\u0026gt;  如前所述，插入语句的配置规则更加丰富，在插入语句里面有一些额外的属性和子元素用来处理主键的生成，而且有多种生成方式。\n首先，如果你的数据库支持自动生成主键的字段（比如 MySQL 和 SQL Server），那么你可以设置 useGeneratedKeys=”true”，然后再把 keyProperty 设置到目标属性上就OK了。例如，如果上面的 Author 表已经对 id 使用了自动生成的列类型，那么语句可以修改为:\n\u0026lt;insert id=\u0026quot;insertAuthor\u0026quot; useGeneratedKeys=\u0026quot;true\u0026quot; keyProperty=\u0026quot;id\u0026quot;\u0026gt; insert into Author (username,password,email,bio) values (#{username},#{password},#{email},#{bio}) \u0026lt;/insert\u0026gt;  如果你的数据库还支持多行插入, 你也可以传入一个Authors数组或集合，并返回自动生成的主键。\n\u0026lt;insert id=\u0026quot;insertAuthor\u0026quot; useGeneratedKeys=\u0026quot;true\u0026quot; keyProperty=\u0026quot;id\u0026quot;\u0026gt; insert into Author (username, password, email, bio) values \u0026lt;foreach item=\u0026quot;item\u0026quot; collection=\u0026quot;list\u0026quot; separator=\u0026quot;,\u0026quot;\u0026gt; (#{item.username}, #{item.password}, #{item.email}, #{item.bio}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt;  对于不支持自动生成类型的数据库或可能不支持自动生成主键 JDBC 驱动来说，MyBatis 有另外一种方法来生成主键。\n这里有一个简单（甚至很傻）的示例，它可以生成一个随机 ID（你最好不要这么做，但这里展示了 MyBatis 处理问题的灵活性及其所关心的广度）：\n\u0026lt;insert id=\u0026quot;insertAuthor\u0026quot;\u0026gt; \u0026lt;selectKey keyProperty=\u0026quot;id\u0026quot; resultType=\u0026quot;int\u0026quot; order=\u0026quot;BEFORE\u0026quot;\u0026gt; select CAST(RANDOM()*1000000 as INTEGER) a from SYSIBM.SYSDUMMY1 \u0026lt;/selectKey\u0026gt; insert into Author (id, username, password, email,bio, favourite_section) values (#{id}, #{username}, #{password}, #{email}, #{bio}, #{favouriteSection,jdbcType=VARCHAR}) \u0026lt;/insert\u0026gt;  同理，如果我们在使用mysql的时候，想在数据插入后返回插入的id, 我们也可以使用 selectKey 这个元素：\n\u0026lt;!-- 对应userDao中的insertUser方法， --\u0026gt; \u0026lt;insert id=\u0026quot;insertUser\u0026quot; parameterType=\u0026quot;com.dy.entity.User\u0026quot;\u0026gt; \u0026lt;!-- oracle等不支持id自增长的，可根据其id生成策略，先获取id \u0026lt;selectKey resultType=\u0026quot;int\u0026quot; order=\u0026quot;BEFORE\u0026quot; keyProperty=\u0026quot;id\u0026quot;\u0026gt; select seq_user_id.nextval as id from dual \u0026lt;/selectKey\u0026gt; --\u0026gt; \u0026lt;!-- mysql插入数据后，获取id --\u0026gt; \u0026lt;selectKey keyProperty=\u0026quot;id\u0026quot; resultType=\u0026quot;int\u0026quot; order=\u0026quot;AFTER\u0026quot; \u0026gt; SELECT LAST_INSERT_ID() as id \u0026lt;/selectKey\u0026gt; insert into user(id, name, age) values(#{id}, #{name} #{age}) \u0026lt;/insert\u0026gt;  在上面的示例中，selectKey 元素将会首先运行，Author 的 id 会被设置，然后插入语句会被调用。这给你了一个和数据库中来处理自动生成的主键类似的行为，避免了使 Java 代码变得复杂。\nselectKey 元素描述如下：\n\u0026lt;selectKey \u0026lt;!-- selectKey 语句结果应该被设置的目标属性。如果希望得到多个生成的列，也可以是逗号分隔的属性名称列表。 --\u0026gt; keyProperty=\u0026quot;id\u0026quot; \u0026lt;!-- 结果的类型。MyBatis 通常可以推算出来，但是为了更加确定写上也不会有什么问题。MyBatis 允许任何简单类型用作主键的类型，包括字符串。如果希望作用于多个生成的列，则可以使用一个包含期望属性的 Object 或一个 Map。 --\u0026gt; resultType=\u0026quot;int\u0026quot; \u0026lt;!-- 这可以被设置为 BEFORE 或 AFTER。如果设置为 BEFORE，那么它会首先选择主键，设置 keyProperty 然后执行插入语句。如果设置为 AFTER，那么先执行插入语句，然后是 selectKey 元素 - 这和像 Oracle 的数据库相似，在插入语句内部可能有嵌入索引调用。 --\u0026gt; order=\u0026quot;BEFORE\u0026quot; \u0026lt;!-- 与前面相同，MyBatis 支持 STATEMENT，PREPARED 和 CALLABLE 语句的映射类型，分别代表 PreparedStatement 和 CallableStatement 类型。 --\u0026gt; statementType=\u0026quot;PREPARED\u0026quot;\u0026gt;  参数（Parameters） 前面的所有语句中你所见到的都是简单参数的例子，实际上参数是 MyBatis 非常强大的元素，对于简单的做法，大概 90% 的情况参数都很少，比如：\n\u0026lt;select id=\u0026quot;selectUsers\u0026quot; resultType=\u0026quot;User\u0026quot;\u0026gt; select id, username, password from users where id = #{id} \u0026lt;/select\u0026gt;  上面的这个示例说明了一个非常简单的命名参数映射。参数类型被设置为 int，这样这个参数就可以被设置成任何内容。原生的类型或简单数据类型（比如整型和字符串）因为没有相关属性，它会完全用参数值来替代。然而，如果传入一个复杂的对象，行为就会有一点不同了。比如：\n\u0026lt;insert id=\u0026quot;insertUser\u0026quot; parameterType=\u0026quot;User\u0026quot;\u0026gt; insert into users (id, username, password) values (#{id}, #{username}, #{password}) \u0026lt;/insert\u0026gt;  如果 User 类型的参数对象传递到了语句中，id、username 和 password 属性将会被查找，然后将它们的值传入预处理语句的参数中。\n这点对于向语句中传参是比较好的而且又简单，不过参数映射的功能远不止于此。\n首先，像 MyBatis 的其他部分一样，参数也可以指定一个特殊的数据类型。\n#{property,javaType=int,jdbcType=NUMERIC}  像 MyBatis 的剩余部分一样，javaType 通常可以从参数对象中来去确定，前提是只要对象不是一个 HashMap。那么 javaType 应该被确定来保证使用正确类型处理器。\nNOTE 如果 null 被当作值来传递，对于所有可能为空的列，JDBC Type 是需要的。你可以自己通过阅读预处理语句的 setNull() 方法的 JavaDocs 文档来研究这种情况。\n为了以后定制类型处理方式，你也可以指定一个特殊的类型处理器类（或别名），比如：\n#{age,javaType=int,jdbcType=NUMERIC,typeHandler=MyTypeHandler}  尽管看起来配置变得越来越繁琐，但实际上是很少去设置它们。\n对于数值类型，还有一个小数保留位数的设置，来确定小数点后保留的位数。\n#{height,javaType=double,jdbcType=NUMERIC,numericScale=2}  最后，mode 属性允许你指定 IN，OUT 或 INOUT 参数。如果参数为 OUT 或 INOUT，参数对象属性的真实值将会被改变，就像你在获取输出参数时所期望的那样。如果 mode 为 OUT（或 INOUT），而且 jdbcType 为 CURSOR(也就是 Oracle 的 REFCURSOR)，你必须指定一个 resultMap 来映射结果集到参数类型。要注意这里的 javaType 属性是可选的，如果左边的空白是 jdbcType 的 CURSOR 类型，它会自动地被设置为结果集。\n#{department, mode=OUT, jdbcType=CURSOR, javaType=ResultSet, resultMap=departmentResultMap}  MyBatis 也支持很多高级的数据类型，比如结构体，但是当注册 out 参数时你必须告诉它语句类型名称。比如（再次提示，在实际中要像这样不能换行）：\n#{middleInitial, mode=OUT, jdbcType=STRUCT, jdbcTypeName=MY_TYPE, resultMap=departmentResultMap}  尽管所有这些强大的选项很多时候你只简单指定属性名，其他的事情 MyBatis 会自己去推断，最多你需要为可能为空的列名指定 jdbcType。\n#{firstName} #{middleInitial,jdbcType=VARCHAR} #{lastName}  字符串替换 默认情况下,使用#{}格式的语法会导致 MyBatis 创建预处理语句属性并安全地设置值（比如?）。这样做更安全，更迅速，通常也是首选做法，不过有时你只是想直接在 SQL 语句中插入一个不改变的字符串。比如，像 ORDER BY，你可以这样来使用：\nORDER BY ${columnName}  这里 MyBatis 不会修改或转义字符串。\nNOTE 以这种方式接受从用户输出的内容并提供给语句中不变的字符串是不安全的，会导致潜在的 SQL 注入攻击，因此要么不允许用户输入这些字段，要么自行转义并检验。\nResult Maps resultMap 元素是 MyBatis 中最重要最强大的元素。它就是让你远离 90%的需要从结果 集中取出数据的 JDBC 代码的那个东西, 而且在一些情形下允许你做一些 JDBC 不支持的事 情。 事实上, 编写相似于对复杂语句联合映射这些等同的代码, 也许可以跨过上千行的代码。 ResultMap 的设计就是简单语句不需要明确的结果映射,而很多复杂语句确实需要描述它们 的关系。\n你已经看到简单映射语句的示例了,但没有明确的 resultMap。比如:\n\u0026lt;select id=\u0026quot;selectUsers\u0026quot; resultType=\u0026quot;map\u0026quot;\u0026gt; select id, username, hashedPassword from some_table where id = #{id} \u0026lt;/select\u0026gt;  这样一个语句简单作用于所有列被自动映射到 HashMap 的键上,这由 resultType 属性 指定。这在很多情况下是有用的,但是 HashMap 不能很好描述一个领域模型。那样你的应 用程序将会使用 JavaBeans 或 POJOs(Plain Old Java Objects,普通 Java 对象)来作为领域 模型。MyBatis 对两者都支持。看看下面这个 JavaBean:\npackage com.someapp.model; public class User { private int id; private String username; private String hashedPassword; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getHashedPassword() { return hashedPassword; } public void setHashedPassword(String hashedPassword) { this.hashedPassword = hashedPassword; } }  基于 JavaBean 的规范,上面这个类有 3 个属性:id,username 和 hashedPassword。这些 在 select 语句中会精确匹配到列名。\n这样的一个 JavaBean 可以被映射到结果集,就像映射到 HashMap 一样简单。\n\u0026lt;select id=\u0026quot;selectUsers\u0026quot; resultType=\u0026quot;com.someapp.model.User\u0026quot;\u0026gt; select id, username, hashedPassword from some_table where id = #{id} \u0026lt;/select\u0026gt;  要记住类型别名是你的伙伴。使用它们你可以不用输入类的全路径。比如:\n\u0026lt;!-- In mybatis-config.xml file --\u0026gt; \u0026lt;typeAlias type=\u0026quot;com.someapp.model.User\u0026quot; alias=\u0026quot;User\u0026quot;/\u0026gt; \u0026lt;!-- In SQL Mapping XML file --\u0026gt; \u0026lt;select id=\u0026quot;selectUsers\u0026quot; resultType=\u0026quot;User\u0026quot;\u0026gt; select id, username, hashedPassword from some_table where id = #{id} \u0026lt;/select\u0026gt;  这些情况下,MyBatis 会在幕后自动创建一个 ResultMap,基于属性名来映射列到 JavaBean 的属性上。如果列名没有精确匹配,你可以在列名上使用 select 字句的别名(一个 基本的 SQL 特性)来匹配标签。比如:\n\u0026lt;select id=\u0026quot;selectUsers\u0026quot; resultType=\u0026quot;User\u0026quot;\u0026gt; select user_id as \u0026quot;id\u0026quot;, user_name as \u0026quot;userName\u0026quot;, hashed_password as \u0026quot;hashedPassword\u0026quot; from some_table where id = #{id} \u0026lt;/select\u0026gt;  ResultMap 最优秀的地方你已经了解了很多了,但是你还没有真正的看到一个。这些简 单的示例不需要比你看到的更多东西。 只是出于示例的原因, 让我们来看看最后一个示例中 外部的 resultMap 是什么样子的,这也是解决列名不匹配的另外一种方式。\n\u0026lt;resultMap id=\u0026quot;userResultMap\u0026quot; type=\u0026quot;User\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;user_id\u0026quot; /\u0026gt; \u0026lt;result property=\u0026quot;username\u0026quot; column=\u0026quot;user_name\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;password\u0026quot; column=\u0026quot;hashed_password\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt;  引用它的语句使用 resultMap 属性就行了(注意我们去掉了 resultType 属性)。比如:\n\u0026lt;select id=\u0026quot;selectUsers\u0026quot; resultMap=\u0026quot;userResultMap\u0026quot;\u0026gt; select user_id, user_name, hashed_password from some_table where id = #{id} \u0026lt;/select\u0026gt;  如果世界总是这么简单就好了。\n高级结果映射 MyBatis 创建的一个想法:数据库不用永远是你想要的或需要它们是什么样的。而我们 最喜欢的数据库最好是第三范式或 BCNF 模式,但它们有时不是。如果可能有一个单独的 数据库映射,所有应用程序都可以使用它,这是非常好的,但有时也不是。结果映射就是 MyBatis 提供处理这个问题的答案。\n1.首先，我们先看看一个常见的博客页面的组成，如下：\na.页面上能够展示的部分：正文，标题，日期，作者，评论正文，评论时间，评论人等等\nb.页面之外的部分：用户名，用户id，用户密码，用户基本信息（电话，邮箱，地址，兴趣，特长，等等）\n2.将我们页面上的信息从数据库中查出来的SQL语句转化为Mapper文件中的语句，可能是如下内容：\n \u0026lt;select id=\u0026quot;selectBlogDetails\u0026quot; resultMap=\u0026quot;detailedBlogResultMap\u0026quot;\u0026gt; select B.id as blog_id, B.title as blog_title, B.author_id as blog_author_id, A.id as author_id, A.username as author_username, A.password as author_password, A.email as author_email, A.bio as author_bio, A.favourite_section as author_favourite_section, P.id as post_id, P.blog_id as post_blog_id, P.author_id as post_author_id, P.created_on as post_created_on, P.section as post_section, P.subject as post_subject, P.draft as draft, P.body as post_body, C.id as comment_id, C.post_id as comment_post_id, C.name as comment_name, C.comment as comment_text, T.id as tag_id, T.name as tag_name from Blog B left outer join Author A on B.author_id = A.id left outer join Post P on B.id = P.blog_id left outer join Comment C on P.id = C.post_id left outer join Post_Tag PT on PT.post_id = P.id left outer join Tag T on PT.tag_id = T.id where B.id = #{id} \u0026lt;/select\u0026gt;  其对应着非常复杂的结果集合，Mapper文件可能长这个样子，如下：\n \u0026lt;!-- Very Complex Result Map --\u0026gt; \u0026lt;resultMap id=\u0026quot;detailedBlogResultMap\u0026quot; type=\u0026quot;Blog\u0026quot;\u0026gt; \u0026lt;constructor\u0026gt; \u0026lt;idArg column=\u0026quot;blog_id\u0026quot; javaType=\u0026quot;int\u0026quot;/\u0026gt; \u0026lt;/constructor\u0026gt; \u0026lt;result property=\u0026quot;title\u0026quot; column=\u0026quot;blog_title\u0026quot;/\u0026gt; \u0026lt;association property=\u0026quot;author\u0026quot; javaType=\u0026quot;Author\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;author_id\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;username\u0026quot; column=\u0026quot;author_username\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;password\u0026quot; column=\u0026quot;author_password\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;email\u0026quot; column=\u0026quot;author_email\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;bio\u0026quot; column=\u0026quot;author_bio\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;favouriteSection\u0026quot; column=\u0026quot;author_favourite_section\u0026quot;/\u0026gt; \u0026lt;/association\u0026gt; \u0026lt;collection property=\u0026quot;posts\u0026quot; ofType=\u0026quot;Post\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;post_id\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;subject\u0026quot; column=\u0026quot;post_subject\u0026quot;/\u0026gt; \u0026lt;association property=\u0026quot;author\u0026quot; javaType=\u0026quot;Author\u0026quot;/\u0026gt; \u0026lt;collection property=\u0026quot;comments\u0026quot; ofType=\u0026quot;Comment\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;comment_id\u0026quot;/\u0026gt; \u0026lt;/collection\u0026gt; \u0026lt;collection property=\u0026quot;tags\u0026quot; ofType=\u0026quot;Tag\u0026quot; \u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;tag_id\u0026quot;/\u0026gt; \u0026lt;/collection\u0026gt; \u0026lt;discriminator javaType=\u0026quot;int\u0026quot; column=\u0026quot;draft\u0026quot;\u0026gt; \u0026lt;case value=\u0026quot;1\u0026quot; resultType=\u0026quot;DraftPost\u0026quot;/\u0026gt; \u0026lt;/discriminator\u0026gt; \u0026lt;/collection\u0026gt; . \u0026lt;/resultMap\u0026gt;  对于初学者而言，看到这样的一份XML文件，我想内心一定是崩溃的！但是，不要担心，我们日常开发，很少能够遇到这样的场景，并且，相信通过我们一步一步的解释这个配置文档，以后各位也能够运用自如。\n在上面的resultMap中存在很多的子元素，下面我们来逐一解释：\n“constructor”:类在实例化时，用来注入结果到构造方法中。\n“idArg”：ID参数，标记结果作为ID，可以帮助提高整体的效率。\n“arg”：注入到构造方法的一个不同结果。\n“id”：这个id，类似于数据库的主键，能够帮助提高整体的效率 “result”：即结果字段，其中包括Java对象的属性值，和数据库列名\n“association”：复杂类型的结果关联，结果映射能够关联自身，或者关联另一个结果集\n“collection”：复杂类型的集合，结果映射自身，或者映射结果集\n“discriminator”：使用结果值来决定使用哪个结果映射\n“case”：基于某些值的结果映射。嵌入结果映射，这种情形也映射到它本身，因此，能够包含相同的元素，或者参照一个外部的结果映射。\n对于resultMap标签，上文的基础用法中我们已经介绍了他的属性含义。但，在此之外，还有一个属性值为：\n“autoMapping”：如果出现此配置，Mybatis将会启用或者禁用自动匹配resultMap的功能，这个属性将会在全局范围内覆盖自动匹配机制。默认情况下是没有这个配置的，因此，如果需要，请保持慎重。\n下面，我们开始详细说明每一个元素，如果有心急的读者想使用前面增改删查功能，请读者一定按照单元测试的方法推进，千万不要一次性配置大量属性，以免影响学习兴趣。\na.构造方法\n \u0026lt;constructor\u0026gt; \u0026lt;idArg column=\u0026quot;id\u0026quot; javaType=\u0026quot;int\u0026quot;/\u0026gt; \u0026lt;arg column=\u0026quot;username\u0026quot; javaType=\u0026quot;String\u0026quot;/\u0026gt; \u0026lt;/constructor\u0026gt;  尽管对于大部分的DTO对象，以及我们的domain模型，属性值都是能够起到相应的作用，但是，在某些情况下如我们想使用一些固定的类。如：通常情况下的表格中包括一些仅供浏览的数据或者很少改变的数据。Mybatis的构造函数注入功能允许我们在类初始化时就设置某些值，而不暴露其中的public方法。同时Mybatis也支持私有的属性与私有的JavaBeans属性来实现这个目的，尽管这样，一些开发者还是更愿意使用构造函数注入的方式。\n例如，程序中我们存在这样一个实体类，如下：\n1. public class User { 2. //... 3. public User(int id, String username) { 4. //... 5. } 6. //... 7. }  在Mybatis中，为了向这个构造方法中注入结果，Mybatis需要通过它的参数的类型来表示构造方法。java中，没有反射参数名称的方法，因此，当创建一个构造方法的元素是，必须保证参数是按照顺序排列的，而且，数据类型也必须匹配！\nb.关联\n2. \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;author_id\u0026quot;/\u0026gt; 3. \u0026lt;result property=\u0026quot;username\u0026quot; column=\u0026quot;author_username\u0026quot;/\u0026gt; 4. \u0026lt;/association\u0026gt;  关联元素用来处理数据模型中的“has-one”关系。如我们上文示例的一个博客有一个用户。关联映射大部分是基于这种应用场景。使用时，我们制定目标属性，可以选用javaType，jdbcType，typeHandler等属性来覆盖结果集合。\n关联查询的不同之处是，我们必须告诉告诉Mybatis如何加载关联关系，这里有两种供我们选择的方法：\n嵌套查询：即通过执行另一个预期返回复杂类型的SQL语句。\n嵌套结果：使用嵌套结果映射来处理联合结果中重复的子集。 在正式的使用之前，我们先来看看这个的属性配置的具体含义，注意，这里的属性配置跟前文基本增改删查中的区别：\nproperty : 映射到列结果的字段或属性。如果匹配的是存在的,和给定名称相同的 property JavaBeans 的属性, 那么就会使用。 否则 MyBatis 将会寻找给定名称的字段。 这两种情形你可以使用通常点式的复杂属性导航。比如,可以这样映射 :“ username ”, 或 者 映 射 到 一 些 复 杂 的属性 : “address.street.number” 。\njavaType : 一个 Java 类的完全限定名,或一个类型别名(参考上面内建类型别名的列 表) 。如果你映射到一个 JavaBean,MyBatis 通常可以断定类型。然而,如 javaType 果你映射到的是 HashMap,那么你应该明确地指定 javaType 来保证所需的行为。 jdbcType : 在这个表格之前的所支持的 JDBC 类型列表中的类型。JDBC 类型是仅仅 需要对插入, 更新和删除操作可能为空的列进行处理。这是 JDBC 的需要, jdbcType 而不是 MyBatis 的。如果你直接使用 JDBC 编程,你需要指定这个类型-但 仅仅对可能为空的值。 typeHandler : 我们在前面讨论过默认的类型处理器。使用这个属性,你可以覆盖默认的 typeHandler 类型处理器。 这个属性值是类的完全限定名或者是一个类型处理器的实现, 或者是类型别名。\n 现在正式的介绍这两种方式：\n1.嵌套查询 column : 这是来自数据库的类名,或重命名的列标签的值作为一个输入参数传递给嵌套语句，这和通常传递给 resultSet.getString(columnName)方法的字符串是相同的。 注 意 : 要 处 理 复 合 主 键 , 你 可 以 指 定 多 个 列 名 通 过 column= ” {prop1=col1,prop2=col2} ” 这种语法来传递给嵌套查询语 句。这会引起 prop1 和 prop2 以参数对象形式来设置给目标嵌套查询语句 select : 另外一个映射语句的 ID,将会按照属性的映射来加载复杂类型。获取的在列属性中指定的列的值将被传递给目标 select 语句作为参数。表格后面 有一个详细的示例。 注 意 : 要 处 理 复 合 主 键 , 可 以 通 过使用 column= ” {prop1=col1,prop2=col2} ” 这种语法指定多个列名传递给嵌套查询语句。这会导致 prop1 和 prop2 以参数对象形式来设置给目标嵌套查询语句。 fetchType : 可选的，他的有效值是lazy，eager。如果存在的话，他将在当前映射关系中取代全局变量lazyLoadingEnabled。\n \u0026lt;resultMap id=\u0026quot;blogResult\u0026quot; type=\u0026quot;Blog\u0026quot;\u0026gt; \u0026lt;association property=\u0026quot;author\u0026quot; column=\u0026quot;author_id\u0026quot; javaType=\u0026quot;Author\u0026quot; select=\u0026quot;selectAuthor\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;select id=\u0026quot;selectBlog\u0026quot; resultMap=\u0026quot;blogResult\u0026quot;\u0026gt; SELECT * FROM BLOG WHERE ID = #{id} \u0026lt;/select\u0026gt; \u0026lt;select id=\u0026quot;selectAuthor\u0026quot; resultType=\u0026quot;Author\u0026quot;\u0026gt; SELECT * FROM AUTHOR WHERE ID = #{id} \u0026lt;/select\u0026gt;  我们有两个查询语句:一个来加载博客,另外一个来加载作者,而且博客的结果映射描 述了“selectAuthor”语句应该被用来加载它的 author 属性。\n其他所有的属性将会被自动加载,前提假设它们的列和属性名相匹配。\n这种方式很简单, 但是对于大型数据集合和列表将不会表现很好。 问题就是我们熟知的 “N+1 查询问题”。概括地讲,N+1 查询问题可以是这样引起的:\n 执行了一个单独的 SQL 语句来获取结果列表(就是“+1”)。 对返回的每条记录,执行了一个查询语句来为每个加载细节(就是“N”)。  这个问题会导致成百上千的 SQL 语句被执行。这通常不是期望的。\nMyBatis 能延迟加载这样的查询就是一个好处,因此你可以分散这些语句同时运行的消耗。然而,如果你加载一个列表,之后迅速迭代来访问嵌套的数据,你会调用所有的延迟加载,这样的行为可能是很糟糕的。\n所以还有另外一种方法。\n2.嵌套结果： 首先，我们先来看看有哪些属性能够供我们使用：\nresultMap : 这是结果映射的 ID,可以映射关联的嵌套结果到一个合适的对象图中。这是一种替代方法来调用另外一个查询语句。这允许你联合多个表来合成到 resultMap 一个单独的结果集。这样的结果集可能包含需要被分解的相同的，重复的数据组并且合理映射到一个嵌套的对象图。为了使它变得容易,MyBatis 让你“链接”结果映射,来处理嵌套结果。下面给予一个很容易来仿照例子。 columnPrefix : 当连接多个表时，你最好使用列的别名来避免在一个结果集合中出现的名称重复。对于制定的前缀，Mybatis允许我们映射列到外部集合中，具体用法请参照后面的例子 notNullColumn : 只有在至少有一个非空列映射到子对象的属性时，才创建一个默认的子对象。通过这个属性，我们可以设置哪一个列必须有值来改变这个行为，此时的Mybatis就会按照这个非空设置来创建一个子对象。多个列存在时，可以通过逗号作为分割符。默认情况下，该属性是不会被设置的，即unset autoMapping : 如果存在此属性的话，Mybatis会在映射到对应属性时启用或者禁用自动映射的功能。这个属性将会在全局范围内覆盖自动映射的功能。 注意：该属性没有对外部结果集造成影响。因此，在select或者结果集合中使用是没有意义的。默认情况下，它是不设置的，即unset\n上面的内容是不是让各位已经头晕目眩了？不要急，我们马上就给大家展示一个非常简单的例子来说明上面各个属性是怎么工作的。\n \u0026lt;select id=\u0026quot;selectBlog\u0026quot; resultMap=\u0026quot;blogResult\u0026quot;\u0026gt; select B.id as blog_id, B.title as blog_title, B.author_id as blog_author_id, A.id as author_id, A.username as author_username, A.password as author_password, A.email as author_email, A.bio as author_bio from Blog B left outer join Author A on B.author_id = A.id where B.id = #{id} \u0026lt;/select\u0026gt;  仔细观察这个联合查询，以及采用的保护方法确保了所有结果被唯一的，清晰的命名。这样使得我们的映射非常的简单。\n现在，我们来看看如何映射这个结果\n \u0026lt;resultMap id=\u0026quot;blogResult\u0026quot; type=\u0026quot;Blog\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;blog_id\u0026quot; /\u0026gt; \u0026lt;result property=\u0026quot;title\u0026quot; column=\u0026quot;blog_title\u0026quot;/\u0026gt; \u0026lt;association property=\u0026quot;author\u0026quot; resultMap=\u0026quot;authorResult\u0026quot; /\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;resultMap id=\u0026quot;authorResult\u0026quot; type=\u0026quot;Author\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;author_id\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;username\u0026quot; column=\u0026quot;author_username\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;password\u0026quot; column=\u0026quot;author_password\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;email\u0026quot; column=\u0026quot;author_email\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;bio\u0026quot; column=\u0026quot;author_bio\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt;  在上面的这个例子中，我们已经观察到博客的“author”关联另外一个“resultMap”结果映射，来加载“Author”实例\n特别注意的是：在嵌套结果映射中，元素“id”扮演了一个非常重要的角色。我们应该特别指明一个或者多个属性来唯一的标识这个结果。在实际应用中，如果不指定这个“id”，Mybatis仍然能够继续运行，但是会产生很大的性能消耗。但是，也需要尽可能的少的选择这些属性，数据库的主键显然是一个非常好的选择！\n上面的例子使用了外部结果集元素来映射关联。这样的做法，使得id为“Authot”的结果集能够被不断的重用。但是，假如我们没有重用的需求，或者，我们只是想简单的把我们的结果映射到一个单独描述的结果集合当中的话，就不再需要上面的方式书写了，直接嵌套关联结果映射就好。具体的做法如下：\n \u0026lt;resultMap id=\u0026quot;blogResult\u0026quot; type=\u0026quot;Blog\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;blog_id\u0026quot; /\u0026gt; \u0026lt;result property=\u0026quot;title\u0026quot; column=\u0026quot;blog_title\u0026quot;/\u0026gt; \u0026lt;association property=\u0026quot;author\u0026quot; javaType=\u0026quot;Author\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;author_id\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;username\u0026quot; column=\u0026quot;author_username\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;password\u0026quot; column=\u0026quot;author_password\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;email\u0026quot; column=\u0026quot;author_email\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;bio\u0026quot; column=\u0026quot;author_bio\u0026quot;/\u0026gt; \u0026lt;/association\u0026gt; \u0026lt;/resultMap\u0026gt;  针对上面的例子，加入这篇博客存在一个“联合作者”又该怎么办呢？具体的做法如下：\n \u0026lt;select id=\u0026quot;selectBlog\u0026quot; resultMap=\u0026quot;blogResult\u0026quot;\u0026gt; select B.id as blog_id, B.title as blog_title, A.id as author_id, A.username as author_username, A.password as author_password, A.email as author_email, A.bio as author_bio, CA.id as co_author_id, CA.username as co_author_username, CA.password as co_author_password, CA.email as co_author_email, CA.bio as co_author_bio from Blog B left outer join Author A on B.author_id = A.id left outer join Author CA on B.co_author_id = CA.id where B.id = #{id} \u0026lt;/select\u0026gt;   \u0026lt;resultMap id=\u0026quot;authorResult\u0026quot; type=\u0026quot;Author\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;author_id\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;username\u0026quot; column=\u0026quot;author_username\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;password\u0026quot; column=\u0026quot;author_password\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;email\u0026quot; column=\u0026quot;author_email\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;bio\u0026quot; column=\u0026quot;author_bio\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt;  由于结果集当中的列名与查询结果当中列名不一致，我们需要使用明确指定“columnPrefix”来重用这个结果集，以此来映射“联合作者”的查询结果。具体写法如下：\n \u0026lt;resultMap id=\u0026quot;blogResult\u0026quot; type=\u0026quot;Blog\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;blog_id\u0026quot; /\u0026gt; \u0026lt;result property=\u0026quot;title\u0026quot; column=\u0026quot;blog_title\u0026quot;/\u0026gt; \u0026lt;association property=\u0026quot;author\u0026quot; resultMap=\u0026quot;authorResult\u0026quot; /\u0026gt; \u0026lt;association property=\u0026quot;coAuthor\u0026quot; resultMap=\u0026quot;authorResult\u0026quot; columnPrefix=\u0026quot;co_\u0026quot; /\u0026gt; \u0026lt;/resultMap\u0026gt;  多结果集关联 |column :当时用多结果集的这个属性来指定被逗号分隔的列时，将会使得该列与foreignColumn相关联，从而确定了关联列之间的父子关系 foreignColumn : 标识出包含foreing keys的列的名称。这个foreing keys的值将会和父类型中指定的列属性的值相匹配\nresultSet : 标识这个将会从哪里加载的复杂类型数据的结果集合的名称 |\n从3.2.3版本开始，Mybatis提供了另外一种方式来解决“N+1”问题\n某些数据库允许在存储过程中返回多个结果集，或者同时执行多个语句并且每一个都返回一个结果集合。这就使得我们可以只用访问数据库一次，且不用使用join，就返回存在关联的数据。\n举个例子，执行下面的语句将会返回两个结果集合。第一个返回博客文章的结果集合，第二个返回作者的结果集合\n SELECT * FROM BLOG WHERE ID = #{id} SELECT * FROM AUTHOR WHERE ID = #{id}  我们必须给予每一个结果集合一个指定的名称。方式是：在结果集合中增加一个resultSets属性，来映射语句中被逗号分隔的名称。\n \u0026lt;select id=\u0026quot;selectBlog\u0026quot; resultSets=\u0026quot;blogs,authors\u0026quot; resultMap=\u0026quot;blogResult\u0026quot; statementType=\u0026quot;CALLABLE\u0026quot;\u0026gt; {call getBlogsAndAuthors(#{id,jdbcType=INTEGER,mode=IN})} \u0026lt;/select\u0026gt;  现在，我们来指定：数据填充的“author”的集合包含在“authors”的结果集中\n\u0026lt;resultMap id=\u0026quot;blogResult\u0026quot; type=\u0026quot;Blog\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;id\u0026quot; /\u0026gt; \u0026lt;result property=\u0026quot;title\u0026quot; column=\u0026quot;title\u0026quot;/\u0026gt; \u0026lt;association property=\u0026quot;author\u0026quot; javaType=\u0026quot;Author\u0026quot; resultSet=\u0026quot;authors\u0026quot; column=\u0026quot;author_id\u0026quot; foreignColumn=\u0026quot;id\u0026quot;\u0026gt; \u0026lt;id property=\u0026quot;id\u0026quot; column=\u0026quot;id\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;username\u0026quot; column=\u0026quot;username\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;password\u0026quot; column=\u0026quot;password\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;email\u0026quot; column=\u0026quot;email\u0026quot;/\u0026gt; \u0026lt;result property=\u0026quot;bio\u0026quot; column=\u0026quot;bio\u0026quot;/\u0026gt; \u0026lt;/association\u0026gt; \u0026lt;/resultMap\u0026gt;  上面所属的这些内容，解决了我们“has-one”的问题。\n 自动映射 正如你在前面一节看到的，在简单的场景下，MyBatis可以替你自动映射查询结果。 如果遇到复杂的场景，你需要构建一个result map。 但是在本节你将看到，你也可以混合使用这两种策略。 让我们到深一点的层面上看看自动映射是怎样工作的。\n当自动映射查询结果时，MyBatis会获取sql返回的列名并在java类中查找相同名字的属性（忽略大小写）。 这意味着如果Mybatis发现了_ID_列和_id_属性，Mybatis会将_ID_的值赋给_id_。\n通常数据库列使用大写单词命名，单词间用下划线分隔；而java属性一般遵循驼峰命名法。 为了在这两种命名方式之间启用自动映射，需要将 mapUnderscoreToCamelCase设置为true。\n自动映射甚至在特定的result map下也能工作。在这种情况下，对于每一个result map,所有的ResultSet提供的列， 如果没有被手工映射，则将被自动映射。自动映射处理完毕后手工映射才会被处理。 在接下来的例子中， id 和 _userName_列将被自动映射， hashed_password 列将根据配置映射。\n\u0026lt;select id=\u0026quot;selectUsers\u0026quot; resultMap=\u0026quot;userResultMap\u0026quot;\u0026gt; select user_id as \u0026quot;id\u0026quot;, user_name as \u0026quot;userName\u0026quot;, hashed_password from some_table where id = #{id} \u0026lt;/select\u0026gt;  \u0026lt;resultMap id=\u0026quot;userResultMap\u0026quot; type=\u0026quot;User\u0026quot;\u0026gt; \u0026lt;result property=\u0026quot;password\u0026quot; column=\u0026quot;hashed_password\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt;  有三种自动映射等级：\n NONE- 禁用自动映射。仅设置手动映射属性。 PARTIAL- 将自动映射结果除了那些有内部定义内嵌结果映射的(joins). FULL- 自动映射所有。  默认值是PARTIAL，这是有原因的。当使用FULL时，自动映射会在处理join结果时执行，并且join取得若干相同行的不同实体数据，因此这可能导致非预期的映射。下面的例子将展示这种风险：\n\u0026lt;select id=\u0026quot;selectBlog\u0026quot; resultMap=\u0026quot;blogResult\u0026quot;\u0026gt; select B.id, B.title, A.username, from Blog B left outer join Author A on B.author_id = A.id where B.id = #{id} \u0026lt;/select\u0026gt;  \u0026lt;resultMap id=\u0026quot;blogResult\u0026quot; type=\u0026quot;Blog\u0026quot;\u0026gt; \u0026lt;association property=\u0026quot;author\u0026quot; resultMap=\u0026quot;authorResult\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt; \u0026lt;resultMap id=\u0026quot;authorResult\u0026quot; type=\u0026quot;Author\u0026quot;\u0026gt; \u0026lt;result property=\u0026quot;username\u0026quot; column=\u0026quot;author_username\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt;  在结果中_Blog_和_Author_均将自动映射。但是注意_Author_有一个_id_属性，在ResultSet中有一个列名为_id_， 所以Author的id将被填充为Blog的id，这不是你所期待的。所以需要谨慎使用FULL。\n通过添加autoMapping属性可以忽略自动映射等级配置，你可以启用或者禁用自动映射指定的ResultMap。\n\u0026lt;resultMap id=\u0026quot;userResultMap\u0026quot; type=\u0026quot;User\u0026quot; autoMapping=\u0026quot;false\u0026quot;\u0026gt; \u0026lt;result property=\u0026quot;password\u0026quot; column=\u0026quot;hashed_password\u0026quot;/\u0026gt; \u0026lt;/resultMap\u0026gt;  缓存 MyBatis 包含一个非常强大的查询缓存特性,它可以非常方便地配置和定制。MyBatis 3 中的缓存实现的很多改进都已经实现了,使得它更加强大而且易于配置。\n默认情况下是没有开启缓存的,除了局部的 session 缓存,可以增强变现而且处理循环 依赖也是必须的。要开启二级缓存,你需要在你的 SQL 映射文件中添加一行:\n\u0026lt;cache/\u0026gt;  字面上看就是这样。这个简单语句的效果如下:\n 映射语句文件中的所有 select 语句将会被缓存。 映射语句文件中的所有 insert,update 和 delete 语句会刷新缓存。 缓存会使用 Least Recently Used(LRU,最近最少使用的)算法来收回。 根据时间表(比如 no Flush Interval,没有刷新间隔), 缓存不会以任何时间顺序 来刷新。 缓存会存储列表集合或对象(无论查询方法返回什么)的 1024 个引用。 缓存会被视为是 read/write(可读/可写)的缓存,意味着对象检索不是共享的,而 且可以安全地被调用者修改,而不干扰其他调用者或线程所做的潜在修改。  所有的这些属性都可以通过缓存元素的属性来修改。比如:\n\u0026lt;cache eviction=\u0026quot;FIFO\u0026quot; flushInterval=\u0026quot;60000\u0026quot; size=\u0026quot;512\u0026quot; readOnly=\u0026quot;true\u0026quot;/\u0026gt;  这个更高级的配置创建了一个 FIFO 缓存,并每隔 60 秒刷新,存数结果对象或列表的 512 个引用,而且返回的对象被认为是只读的,因此在不同线程中的调用者之间修改它们会 导致冲突。\n可用的收回策略有:\n LRU– 最近最少使用的:移除最长时间不被使用的对象。 FIFO– 先进先出:按对象进入缓存的顺序来移除它们。 SOFT– 软引用:移除基于垃圾回收器状态和软引用规则的对象。 WEAK– 弱引用:更积极地移除基于垃圾收集器状态和弱引用规则的对象。  默认的是 LRU。\nflushInterval(刷新间隔)可以被设置为任意的正整数,而且它们代表一个合理的毫秒 形式的时间段。默认情况是不设置,也就是没有刷新间隔,缓存仅仅调用语句时刷新。\nsize(引用数目)可以被设置为任意正整数,要记住你缓存的对象数目和你运行环境的 可用内存资源数目。默认值是 1024。\nreadOnly(只读)属性可以被设置为 true 或 false。只读的缓存会给所有调用者返回缓 存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。可读写的缓存 会返回缓存对象的拷贝(通过序列化) 。这会慢一些,但是安全,因此默认是 false。\n使用自定义缓存 除了这些自定义缓存的方式, 你也可以通过实现你自己的缓存或为其他第三方缓存方案 创建适配器来完全覆盖缓存行为。\n\u0026lt;cache type=\u0026quot;com.domain.something.MyCustomCache\u0026quot;/\u0026gt;  这个示 例展 示了 如何 使用 一个 自定义 的缓 存实 现。type 属 性指 定的 类必 须实现 org.mybatis.cache.Cache 接口。这个接口是 MyBatis 框架中很多复杂的接口之一,但是简单 给定它做什么就行。\npublic interface Cache { String getId(); int getSize(); void putObject(Object key, Object value); Object getObject(Object key); boolean hasKey(Object key); Object removeObject(Object key); void clear(); }  要配置你的缓存, 简单和公有的 JavaBeans 属性来配置你的缓存实现, 而且是通过 cache 元素来传递属性, 比如, 下面代码会在你的缓存实现中调用一个称为 “setCacheFile(String file)” 的方法:\n\u0026lt;cache type=\u0026quot;com.domain.something.MyCustomCache\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;cacheFile\u0026quot; value=\u0026quot;/tmp/my-custom-cache.tmp\u0026quot;/\u0026gt; \u0026lt;/cache\u0026gt;  你可以使用所有简单类型作为 JavaBeans 的属性,MyBatis 会进行转换。 And you can specify a placeholder(e.g. ${cache.file}) to replace value defined at configuration properties.\n从3.4.2版本开始，MyBatis已经支持在所有属性设置完毕以后可以调用一个初始化方法。如果你想要使用这个特性，请在你的自定义缓存类里实现 org.apache.ibatis.builder.InitializingObject接口。\npublic interface InitializingObject { void initialize() throws Exception; }  记得缓存配置和缓存实例是绑定在 SQL 映射文件的命名空间是很重要的。因此,所有 在相同命名空间的语句正如绑定的缓存一样。 语句可以修改和缓存交互的方式, 或在语句的 语句的基础上使用两种简单的属性来完全排除它们。默认情况下,语句可以这样来配置:\n\u0026lt;select ... flushCache=\u0026quot;false\u0026quot; useCache=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;insert ... flushCache=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;update ... flushCache=\u0026quot;true\u0026quot;/\u0026gt; \u0026lt;delete ... flushCache=\u0026quot;true\u0026quot;/\u0026gt;  因为那些是默认的,你明显不能明确地以这种方式来配置一条语句。相反,如果你想改 变默认的行为,只能设置 flushCache 和 useCache 属性。比如,在一些情况下你也许想排除 从缓存中查询特定语句结果,或者你也许想要一个查询语句来刷新缓存。相似地,你也许有 一些更新语句依靠执行而不需要刷新缓存。\n参照缓存 回想一下上一节内容, 这个特殊命名空间的唯一缓存会被使用或者刷新相同命名空间内 的语句。也许将来的某个时候,你会想在命名空间中共享相同的缓存配置和实例。在这样的 情况下你可以使用 cache-ref 元素来引用另外一个缓存。\n\u0026lt;cache-ref namespace=\u0026quot;com.someone.application.data.SomeMapper\u0026quot;/\u0026gt;  结束 谢谢各位。\n","id":48,"section":"posts","summary":"\u003cp\u003e最近在公司内部技术交流会上分享了mybatis相关的配置资料，现在整理下弄到博客上面。\u003c/p\u003e","tags":["mybatis"],"title":"mybatisXML配置以及XML映射文件","uri":"https://gggggravel.com/post/mybatisxml%E9%85%8D%E7%BD%AE%E4%BB%A5%E5%8F%8Axml%E6%98%A0%E5%B0%84%E6%96%87%E4%BB%B6/","year":"2017"},{"content":"很久之前就想搭建一个自己的个人博客，甚至想过自己的毕业设计的题目就选择这个。但因为种种原因(懒)，直到上个星期才通过hexo完成博客的搭建。为了方便大家(装逼)也不至于让我这里变得冷清，我决定还是写一个简单平快的教程出来。文笔拙劣，还请赐教。\n正文 由于我没有mac，所以本教程只针对windows用户哟。\n配置环境 安装git Git是一个开源的分布式版本控制系统，用以有效、高速的处理从很小到非常大的项目版本管理。Git 是大神Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。在这里我们主要用它来实现把本地的hexo内容提交到github也就是我们的博客上去。你可以选择git官网或者git国内下载站下载\n安装Node.js 由于hexo是基于Node.js的博客程序，所以安装Node.js是必须的。可以参考此教程来安装。\n安装hexo 完成以上步骤之后，可以开始我们的hexo安装。在此我建议新建一个文件夹blog来存放关于博客相关的内容和hexo装文件。在这个文件夹下右键git bash，用以下命令安装hexo.\n$ npm install hexo-cli -g  在blog文件夹下面创建hexo文件夹，在这使用以下命令初始化博客搭建所需的所有文件\n$ hexo init  安装依赖包\n$ npm install  在当前文件夹执行以下命令\n$ hexo g $ hexo s  如果一切顺利的话，在浏览器输入http://localhost:4000/,就可以看到hexo生成的本地博客，hexo的默认主题是landscape，知乎上有人总结hexo的许多好看的主题，有兴趣的可以下载替换。\n注册Github 如果你已经有github账号，可以跳过此步骤。\n创建repository repository是你的个人仓库，你可以往里面放你的项目代码，在这里我们新建一个repository。如图所示 红框处的项目名必须为username.github.io这种格式，如我的github用户名为L-Gravel,那么这个项目名就是L-Gravel.github.io,这样可以方便github解析你的博客地址。之后点击箭头所指的按钮生成repository.\n连接本地git与github 配置Git\\ 首先在本地创建ssh key；\nssh-keygen -t rsa -C \u0026quot;your_email@youremail.com\u0026quot;  后面的your_email@youremail.com改为你的邮箱，之后会要求确认路径和输入密码，我们这使用默认的一路回车就行。成功的话会在~/下生成.ssh文件夹，进去，打开id_rsa.pub，复制里面的key。\n回到github，进入Settings 左边选择SSH Keys，new SSH Key,title随便填，粘贴key。为了验证是否成功，右键git bash输入：\n$ ssh -T git@github.com  如果是第一次的会提示是否continue，输入yes就会看到：You’ve successfully authenticated, but GitHub does not provide shell access。这就表示已成功连上github。 接下来我们要做的就是把本地仓库传到github上去，在此之前还需要设置username和email，因为github每次commit都会记录他们。\n$ git config --global user.name \u0026quot;your name\u0026quot; $ git config --global user.email \u0026quot;your_email@youremail.com\u0026quot;  在这里填写你们的github邮箱就好。\n将本地博客文件上传到github 在上一步，我们创建了博客代码所需的仓库，并且建立了本地git和github的链接。现在当然是要把本地的博客代码上传到仓库里面。编辑hexo文件夹路径下的_config.yml文件。在这个文件末尾添加以下代码：\n# Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: type: git repository: git@github.com:L-Gravel/L-Gravel.github.io.git branch: master  注意，L-Gravel应该替换为你自己的用户名。配置好_config.yml并保存后，执行以下命令部署到Github上。\n$ hexo g $ hexo d  如果这个时候出现ERROR Deployer not found : github,可以试试输入以下代码：\n$ npm install hexo-deployer-git --save $ hexo g $ hexo d  执行完以上步骤之后，如果一切顺利的话，博客就应该已经顺利的发布在github上了，可以通过username.github.io直接访问。\n发布一篇文章 1.在Git Bash执行命令：\n$ hexo new \u0026quot;my new post\u0026quot;  2.在hexo\\source_post中打开my-new-post.md，建议使用notepad++或editplus。 hexo中写文章使用的是Markdown，没接触过的可以看下Markdown相关教程。\ntitle: my new post #可以改成中文或者其他的，如“第一篇博客” date: 2016-04-22 19:33:40 #发表日期，一般不改动 categories: blog #文章文类 tags: [博客，文章] #文章标签，不同主题对于不同的标签的分类不太一样，这一点我正在研究 --- #这里是正文，用markdown写，你可以选择写一段显示在首页的简介后，加上 \u0026lt;!--more--\u0026gt;，在\u0026lt;!--more--\u0026gt;之前的内容会显示在首页，之后的内容会被隐藏，当游客点击Read more才能看到。  总结 至此为止，我们已经完成了基础hexo的博客搭建，关于域名绑定这一块我之后会写另外一篇博客来说明。如果你参考此文遇到了什么问题，欢迎点击右边图标链接或是在下方留言与我联系。\n","id":49,"section":"posts","summary":"\u003cp\u003e很久之前就想搭建一个自己的个人博客，甚至想过自己的毕业设计的题目就选择这个。但因为种种原因(\u003ccode\u003e懒\u003c/code\u003e)，直到上个星期才通过hexo完成博客的搭建。为了方便大家\u003ccode\u003e(装逼\u003c/code\u003e)也不至于让我这里变得冷清，我决定还是写一个简单平快的教程出来。文笔拙劣，还请赐教。\u003c/p\u003e","tags":["hexo"],"title":"HEXO+Github,搭建个人博客","uri":"https://gggggravel.com/post/hexo-blog/","year":"2016"}],"tags":[{"title":"alpine","uri":"https://gggggravel.com/tags/alpine/"},{"title":"Andorid","uri":"https://gggggravel.com/tags/andorid/"},{"title":"azkaban","uri":"https://gggggravel.com/tags/azkaban/"},{"title":"Base64","uri":"https://gggggravel.com/tags/base64/"},{"title":"bfg","uri":"https://gggggravel.com/tags/bfg/"},{"title":"bugfix","uri":"https://gggggravel.com/tags/bugfix/"},{"title":"cache","uri":"https://gggggravel.com/tags/cache/"},{"title":"CI","uri":"https://gggggravel.com/tags/ci/"},{"title":"docker","uri":"https://gggggravel.com/tags/docker/"},{"title":"docker-compose","uri":"https://gggggravel.com/tags/docker-compose/"},{"title":"dubbo","uri":"https://gggggravel.com/tags/dubbo/"},{"title":"git","uri":"https://gggggravel.com/tags/git/"},{"title":"github","uri":"https://gggggravel.com/tags/github/"},{"title":"github_page","uri":"https://gggggravel.com/tags/github_page/"},{"title":"gitlab","uri":"https://gggggravel.com/tags/gitlab/"},{"title":"gitlab-CI","uri":"https://gggggravel.com/tags/gitlab-ci/"},{"title":"gitment","uri":"https://gggggravel.com/tags/gitment/"},{"title":"guava","uri":"https://gggggravel.com/tags/guava/"},{"title":"hexo","uri":"https://gggggravel.com/tags/hexo/"},{"title":"idea","uri":"https://gggggravel.com/tags/idea/"},{"title":"issue","uri":"https://gggggravel.com/tags/issue/"},{"title":"java","uri":"https://gggggravel.com/tags/java/"},{"title":"Jenkins","uri":"https://gggggravel.com/tags/jenkins/"},{"title":"k8s","uri":"https://gggggravel.com/tags/k8s/"},{"title":"linux","uri":"https://gggggravel.com/tags/linux/"},{"title":"minio","uri":"https://gggggravel.com/tags/minio/"},{"title":"mybatis","uri":"https://gggggravel.com/tags/mybatis/"},{"title":"pgsql","uri":"https://gggggravel.com/tags/pgsql/"},{"title":"python","uri":"https://gggggravel.com/tags/python/"},{"title":"redis","uri":"https://gggggravel.com/tags/redis/"},{"title":"spring","uri":"https://gggggravel.com/tags/spring/"},{"title":"springboot","uri":"https://gggggravel.com/tags/springboot/"},{"title":"springcloud","uri":"https://gggggravel.com/tags/springcloud/"},{"title":"sql","uri":"https://gggggravel.com/tags/sql/"},{"title":"SSD","uri":"https://gggggravel.com/tags/ssd/"},{"title":"think_in_Java","uri":"https://gggggravel.com/tags/think_in_java/"},{"title":"tomcat","uri":"https://gggggravel.com/tags/tomcat/"},{"title":"zabbix","uri":"https://gggggravel.com/tags/zabbix/"},{"title":"刷机","uri":"https://gggggravel.com/tags/%E5%88%B7%E6%9C%BA/"},{"title":"字符串","uri":"https://gggggravel.com/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"title":"排序算法","uri":"https://gggggravel.com/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"title":"数据分析","uri":"https://gggggravel.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"title":"设计模式","uri":"https://gggggravel.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"title":"读书笔记","uri":"https://gggggravel.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"title":"调度","uri":"https://gggggravel.com/tags/%E8%B0%83%E5%BA%A6/"},{"title":"问题笔记","uri":"https://gggggravel.com/tags/%E9%97%AE%E9%A2%98%E7%AC%94%E8%AE%B0/"}]}